working alternator driving not a silly way everybody's working am driving that's why we at try work out metre driving is that number that in same number of 1.35 million road traffic that's for your right the taxi that's going to bring this number down it's not normal driver assistance system that's gonna bring that number down because if you didn't have your driver assistance system that number would be 3 times as high we have reached is we need to that's her problem if it was easy with the colonel for you anything to not have sold them how we're gonna solve that problem when you are the generation of future not idiots that are going to have to solve this problem there's something missing right and I just took you know like me you all in the in the middle of the action so you've seen a lot of other the Lexus IS in the Toyotas you can buy today or very soon this is like the ones that are prototype level 4 level 5 starting cars that you might have seen around already before on the road they all look cool now right notice see bucket on the top those before different way when little difference is that nothing on top lights very expensive very fancy live darts Wright what's the people that series level 4 level 5 and doing it right in Safeway we had for a little bit of black dancer on our cars in work out to Elsa something else robust repossession from visiting rights all these cars that you know right they're today's cars days vision these radar these GPS the lies that you would see in the suffering for 8 hours today that's missing really to make the connection between the most advanced level for Prototype to see today today's cars the question is one big part of what we're doing a try can we get Robot 3 perception from why so supervised sodalite are is directions for focusing on to actually address that question recent papers that we've made on that topic R&R rapper who has heard about sidr lighter cancel that destination is the same thing it's just one is trendy Elon Musk for the right address so so it's basically the same thing it's almost it's the same thing because it's just like once you have a perfect soul guess what you have a point of we want we want to do in this problem is take a single RGB image l monitor network and conditional network and produce that's right turn the camera into arrange sensor yt Ryan and Toyota we believe we can solve that problem then tackle that problem saying it's because of the data rights car manufacturer in the world we have 100000000 cars on the road today we sell 10 million new cars look at like very we know text we have basically the largest dash Cam in the world you can see this this is like terms of petabytes of data per day which is like an order of magnitude of YouTube is not the relay today right just like we're not getting turned up it about today right to your data is safe where it is in your toilet we're working on algorithms and and their big plans are being set in Motion what is as much data as we need eventually to solve that problem right challenge what do you do with that by the way this this little bubble changes that we have to deal is like is like the Wharf in YouTube Sky and many of the challenges we have to face 3 times but it's also bigger pretty and this is there many many many papers you know it's big data deep learning all the hype etc right so there is always like a little kernel of truth in the height plenty of research ever including 2011 so like one year before the whole Imogen Revolution the longest story of so this is not just the hype one thing that's been clear now with the Criminal Evidence we've been acquiring a recent years is that if you compare performance will not of data improve with with data windows from my PhD because you are having what your sister and your handcraft features that features are not learning deep learning learning everything so it skills bed Adidas scales with labels right that's where the height starts right where all the people that we here because they have so much raw data they are going to win the race they want definitely not the race to zero fatalities it's with labelled data and labelled data right now it means you look get it right images is that even if Toyota was in saving all of humanity's to click on pixel for us so we have to invent some some new ideas rights and and do research on that problem what's the working on self supervised learning dream of unsupervised learning of the initial dream my twin smiley revenda supplies Ernie which was returned from raw data and I have five-year-old daughter I don't let her watch YouTube every day and then I hope she gets into stand for is there a structure in the data right it's just not unlabelled Roddy doll academedia straight and so have you ever just rhetoric questionnaires we have a lot of data but we don't have supervision tell again like you know like there's no free lunch theorem isn't everything so we can't like the very generous so I'm going to be specific in Maesteg 4 computers unlabelled but structured camera bad strategies good we want to only require unlabelled writing video data because majority the amount of bits we have white settler in particular I forget were focusing lighter is inverted cars so you have some cars that have light all that you can commercially by or very soon this typically like range dances like you have probably all in your robots in I like your one night I'll accept here we have really just like not not good for driving we live in arts which had only if you know the sort of that does like very very advanced lighters with like a crazy range of light 150m 1550nm range what's the cars like that you can see out the rooftops like of our cars are prototypes around the valley you will see the like notice it back and it's very expensive in India to have a camera with that prices not something I think it's even if he's with you ok with to stay provide they reach asthmatic and geometric sensing and really now that you can buy they all have cameras radars and like a failure and you know with a b with all these advanced safety features tens of millions of cars now for that is there any I assume you all know about supervisor learning but it's very simple is he get the data fusion tomorrow make predictions play Lost by comparing two labels given to you by an oracle typically assume Ryvita easy to acquire expensive difficult to acquire just looking at saying I don't like easy expensive hard expensive the magic trick writes is psyche sync incorporate panels that's that's the thing you have to to to to pay off this year I'll make a paper called super depth which was really understand that multi-coloured definite works or two light the idea is the following and we will assume we have stereotype network inference time you can work on a parole monocular videos let's assume for the a stereo camera whoever left and right image from the parallel we know the Bassline monocular depth network steps for pixel actually we can know the baseline and you know that we know the mapping of pixels from one frame to the is it going to Houston's dentist you can walk one frame onto the other the weather after walking the pixels have the same colour right it's your work correctly this pixel should line they call it should be the same call the photometric loss and that's busy at the hearts of all the Celts improvised geometric methods you would see there again so it's like a lost over picks between the image and the target image and the word started multiple these is that really provision that's right this is not a human provided label this is a geometry provided label what's the dimension in before it basically you can pay it off the road later directly sweet add some additional terms to make a better because there some photometric and duties like a whitewall all the pixels on the white wall invalid there's plenty of that deal the same 0LA regularization terms cancel that basically was like an electric started this kind of idea you can do that to predict that from a single image by not requiring any supervision started baby circa 2016 after my garden and oldest it was when you do driving you want to see far ahead when you go fast she wants into sea bass in advance so you need to do for a head thing for a head with cameras mean operating at a high resolution so you have as many pixels and as possible number for head you try these ideas initially to see if they would actually work be on the research paper directly on our high resolution is that results were actually significantly better than the research report having it happens to you when you try to reproduce the paper and you got better results what was the other way around and so here we are really wondering what was going on the train on the tests do not like his usual stuff then and actually didn't tomorrow what we found and we can reproduce because again we're walking a frame onto another and then were comparing the pixels and I mentioned this white wall effect white wool from a fire everything looks white so any wrong matching wheels zero last you're not back propagating you don't learn really close you would see there some some ideas are some details they actually year the little bit of a loss right that would resolve some photometric and high-resolution imaging Italia sing out unit during the tiny details that help recover they might be very uniform on the downpour resolution but at a higher resolution you would see these irregularities that enable you to learn proper matching naturally well can we go beyond you know and actually do super-resolution this Whitwick standard network like the distant architecture which is a unit architecture with like a convolutional layers they convolutional layers skip connections we added subpixel convolution blocks which are typical operations that are there to try to hallucinate details when you learn super-resolution networks the last writer to think you can press the signal you lost who is you're trying to learn way sarcastic patterns that says all I've seen is going to things it typically actually corresponds to a high-resolution single like this I'm going to go quickly overdose results because we had newer results but we improved our state-of-the-art quantitatively or qualitatively you should ask as robot talk about that especially computer vision people like me that are not roboticists you should say show me a point that I don't know what it play unscaled it's not on skills tissue paper is actually yard because their point clubs so details of the video on YouTube you can have a look at this of this point cloud alright order collision avoidance of this point out but it's starting to look like it's going somewhere let's go further let's take a step back what if we don't have cereal training time what if we have just videos we assume we know the baseline is front of parallel times of the world Estate another very simple geometric relation take a frame you move the world changes it take another for the singer we have Praia do we use in our Loss For Soup that's that's the that's today's Cars right that's the data we get today and that we have to train at scale from recently extended this work into a new work sfm so the woman archive is the under review the idea was the following his remember we had the stereo so left image image now we have instead a pair of Friends which stereo parallettes is there as you don't know the 6 degrees transformation series of freedom transformation on the camera right they can move in an interior space new about the dynamic objects architecture that we have like this promotion interview revision are you have the same target image sensor typically you when you try new training on the humidity and then you had my contacts images like 2 - 1 and 2 + 1 here we see the target are new and electric architecture that we propose specifically for that task we also have to have a Bose network which is a good network that and tries to make the transformation action of the camera musically translation and then you can do this using this right you know that you know the image cremation you can walk you can apply the same principle of using scissors static assuming that the dynamic objects are and your wife so invited your wife the minority of pixels that's the under line hypothesis that the system is doing when it's learning that we added if you know most robots and cars definitely know that what's been there going they don't know precisely how the cameras movie in 3D space but they know they haven't got them they know like a wheel encoder whatever they know it which speed you're going right if you know that you can actually add something strange to your translation vector the magnitude of your translation back hurts and one thing that's really interesting is that all that promotion from the other scale and would like we could all be like and that room with the tiny room would you class the same Duty you have to resolve it with some measure of scale at SAT test I'm right so when you need to do something that tells you how is root scale you're everything to metric space with this approach and you can trainer translation magnet velocity this is scale the network should be scaled also in the Solar overall approach is scaled and metrically actor you don't need to know your scale the network what is the national scale an example video I I won't played in it's entirety but you will you can find it again online direct me to give to the car park which is the points out Ranger men's rights of the visualisation that all the people in comision no in love so hear what you're saying at the top 20 this is the image he gets better or network on it or help put the scales death it's supposed to write the date of the post of the camera so we can actually do dance for construction what is the point of coloured by the pixels right that you get from Barnet results against look at this online videos on YouTube is light so look at it in details and what you'll see if we can even see difference in the height for The Kerb at the very high resolution our network also is able to have like a very fine-grained ocean of BBC drama tree dance 3D in German cool things you can see in this video is that garbage cool things about unsupervised learning and surprise earning is if you didn't think that you should model garbage cans in your update detector and suddenly there's a gorgeous girl on the road anyway I know what it is if you've seen garbage cans in actually 10 just like a light-hearted what you would see in this video you will see that very often we have actually on on weird categories that actually addiction team has never sorted actually point of Enterprises is going beyond Grand National meeting that's in the world so the secret sauce in details because I think one of the key contributions in that paper it was really the Architecture there's a goalkeeper Google brain and co-authors they show the something that's in hindsight obvious but was not obvious until this paper which is is tasks right which which notional salsa version which geometry property or Priory you using Trinity with a network architecture are things that deep learning is how do you design this network architecture 30 l how many legs do I put 64 channels without layer do I do a skip connection there search that's going on right now is like like just like this I already have a good network please give me one more percent by it's feeling a little bit with the parameters around right that's how it were sound is that we use again our prior in designing the network and one of the things that was important was do you not talk to you before is we take the full image correlation downsampling collusion downsampling collusion downsampling evolution of Samsung calusarii solution is very important why are we method of destroying all the process information and trying to reinvent it right is technical debt because these networks were designs for image Coda Coda is because the encoders are imaging network to classify an image by saying that different people they got images of people so you want to collapse all the pixels all on you write to a single class hey instead of like taking those networks that exist that are designed for application of the great special information a lot and I'm trying very hard to hallucinating details back not degraded information it's just not destroyed in the first place instead of Max pooling is the same thing as for compression rate image compression you can imagine that he would be Motors instead of like decimating the signal we're learning to compress a transformation that says the noise remove that part I consider this as noise and really preserved information content that I need what's the metric lost who is Whelan blocks intuition that learn to compress do a lossy compression of the single as in something we learn to answer learning a Kodak decking blocks is like when you do Max pulling and you do upsampling you're basically just like turning gotten into a pixel and you're turning a pixel into a document that says you're blowing things out right or decimating play what we do is we take the whole signal who dislike that's like intuition that came from super resolution like in this shape right be chw right so be is the best size of letter you just have one image please one channels right or Wednesday colour image of 3 channels but further down it's your size of your presentation during the present text with the width in pixels the things you can see if you can say what it is you just as a tensor actually research tensor destructor to pixels in different ways and reinterpret basically that tenses it's very simple operation that basically just says hey I want to reduce my resolution hnw by effect what do I do with the rest of the remaining pixels right like so much pulling just throw them just packed them into the channels musically a to b Orange sync with the max replace this two by two 4 latest episode of Empire torture is a retard everything you're doing witches you said I traded special detail alarm to compress that featurespace into a lower dimensional feature space you're doing an expansion and contraction there be spaces probably not a very good features Facebook cover translation invariance you're taking spatial details back and my longer channel you're just really hurting them so it might not be very easily learnable so we expand them into higher dimensional feature space where convolutions make more sense so that's why we use a free convolution and then we packed them and the fact that it has is a basically expense vastly the receptive what is a key problem in computer vision is like convolutions to write a conclusion based on the 3 by 3 pixels a lot of those if you want to reason across the scene to say like all that's a really big so that's the road pixel yeah I know because they're close right are you basically have some kind of like a tiling in that network you to say I don't care that all these pieces are really really close to each the same weight on things that are very very close right is like a waste of energy waste of time m it's basically doing some kind of tiling Lakeland right to say hey if I want to see further I need to trade off some of the redundant thing less attention to things that are redundant and said I can spread my pension a little bit further with the same number furnitures is this a similar between the rivers operation scaling dimension before this is just to show you some results that I think it's pretty cool you have a face transition I love face transition so that compressed sensing and all that has let me know one of the papers that I like the most about closest mathematic which is about compressed sense I look for faith and Vision in things and and hear one thing that was super cool is this velocity supervision right that says we constrain the magnitude of our emotion estimator that basically like it takes a while to learn the scale intrinsic scale and then very quickly catches up onto the intrinsic scale this is just like to show you some evidence that you don't need you can learn it through the network and basically just latches onto that global option we be the saviour and I'm not gonna go through all these numbers just like a big one of numbers to scare you to show you that it takes a lot of efforts to show that it work how to do this when your scientists you can just claim were the best look up or stuff awesome YouTube set alarm 10-minutes although is the numbers that I highlighted is not just that we we got the best results in terms of by improving a lot of this is like Astra H this basically tell you when is the absolute relative error you make respect to lighter in terms of flight distance one thing that's very is that for the first time add claim to try to see if people would disprove me so far nobody has this proves me even myself trying to find the literature first time supervised learning actually works better than supervisor are supervised methods where where they do is instead of paying his photometric Latino using geometry as a source of supervision play well let's just learn from sequences where I have recorded image and lighter at the same time printer calibration so I can projected point load onto the image formulated as a regression tiger death given to me by letter message for supervisor sad about this because this is on Kitty is standard benchmark in ultimate driving in the richest comedian is very big and so he would say what Peter very big network you are so overfitting where we show that this network original is better network on and other date the possible right and the reason is because again we capture a better prior right we have more structure bacon to our network and in Harlow what temperatures we can learn better and some results that show this so this is like basically trying on city and then we extend its tune is intent collative to Delight our network deployable as the side Arkwright lighter sensor good conditions you put it on a car in Singapore you put in the car in Tokyo you putting car in us it will give you that no I don't trust the Tokyo version of the light are no no you know it's it's it's it's not like it's a bastard sensor that hallucinating performance is a key aspect of being able to make any claim about the usefulness of supervisor if you take existing architectures which are generally architectures resnet that are designed for image classification like state-of-the-art in that we improve on that are really good is whey commencal new scenes is a new dataset as made by the new Tamagotchi switch then and Singapore can do with karlsruhe Germany which is Kitty pencil until really that was very encouraging it again forces that if you have a good primer if you have a good structure in your learning you're generous networks and get with your eyes better turn on smart light we improve with data the other thing is turning a whole point of surprise running is not to train on I have this again 10 TB of data on that and is it better than if I have 1 petabytes of data is better than if I have 100 networks that scale with data when was the labelling bread made with it they don't count to 4 minutes so we show that we do Sky ask for pointers method scale with data very few papers immigration you can look at the bed but we're better on fine thanks tractors we're again better than the best self-supervised better than the best semi-supervised offaly supervised letter points in The Cloud so that Linda in Disguise so you have some issues with that right so that's also one reason TV CPR you information like that that spell the field is cray datel computing so it's all about the Architecture it's all about Yorkshire it's all about the loss I think that super call is you can look at you know you have like when you do it on his driving and you work in the bay area and those construction all different you have to my account especially with you again like fancy letters sensors that work out like 250mls impulse really and then you had his fruit affect the services I'm going right next to you that crazy we learn from we learn from Robert are you see cos you know you use there static object to move the round then you capture the 3D structure you can relate how cold looks like what is in 3D space are the cool things is science is pole straight so things that are very thin structures if you do it at a reduced resolution if you do it like 5-ft 10 and 32 by 32 resolution operating at a very high resolution preserving find details enable you to capture things in structures like poles Liverpool it's fensure but you don't want to go out with winner when I saw this I said I don't care it just goes into the paper this figure it goes into the paper paper fences there is a fencing we can detect the same bike parts structures of the fence and right depth behind them is really like an example of set alarm for another date I just better with the data that's cool you're better I highlighted that yes and yes it gets better so there's still research to be done so we hadn't a paper and making a workshop on software learning where is showing Kitty that's great let's try to use 1 million of frames from our logs right just wondering like imagenet size roughly and see if that improves the result the answer is yes interesting aside to summarise this for you is is is that dataset which is often Germany right so very close to TV manually created 85mm is better than 1 mm from Random in random images is that a quantity of data source about quality of data here is we don't know how to measure distributions in that space space of pixels in Enzo very open question of what data is what data with Diversity with quality with relevance to sell active Learning doesn't work here because destination 2 promotion set off the depth and emotion network and they're trying together but then you know so far should like and oppose network is thrown out in Visual geometry is somewhere important than and robot cancel here we actually went there there and if we just focusing on this setting up a coral and paper in we just go to stream networks for supervising motion estimation or we tried to this time the network architecture design for the network so well we tried them together I don't think that audience I need to justify that it's important and and and especially help me improve on a tree with a visual imagery of data what's the network architecture again I told you before the main thing the main source of improvement before was was designing a network analyst that Factors in structural sanction you know that hold to be true because have a to stream network which is typically used in Action recognition were you having an appearance streaming in motion streams of residues RGB and optical flow and combine them together we're basically just saying what actually if you know the structure of the sea you can basically do a geometric registration right like you can localise that's why ladders are so much more accurate for stream network that has a structure stream that takes the depth and then combine them to get a better estimate stuff after pose that that improves papers online you can check it out and we can talk the Coral if you're there easy kind of like creature walls and like a literally going down into you know like getting your hands dirty and and making this deployable because actually having a positive impact on the wall with this in the real world far from being the global technology how do accelerated diploma before like a very fancy that are when you when you have a research leader prototype for free or in certain cars in the future we had his for moonlight are so what if we do have some light our phones sometimes can we leverage that treating work again that will presenting as an Oral at coral my surprised when I tell her destination with her protector distance self-supervised purists and just learnt from raw data but in the real world if you care about actually making this you know getting to this 99 summative eyes is obviously the way send we have a lot of data that enables some data that is labelled is how you do with unlabeled data for that's why we focus on self-supervised but in the real world supervision so how do we leverage this because in interest of time and if you don't have time for questions at the one thing that that basically this says is from the same regression progressing riders Rider which is play Don pixel on column values right before the metric multi-task learning and you just say oh bananas and I've lost that Compares sheep does losses doesn't work so well these two losses compatible cancel here is switch on all lights please here supervise networks then just don't need all the rest right they just need like get me the depth and I have the Grand Theft Auto from that what we doing is a lot of different things because we started obviously were naive and we said our cool provide network state-of-the-art self-supervised network them have babies and these babies will be beautiful you was not beautiful is there a y with this approach worked the thing is that again you have a lot of the data label give some data that's labour traditional way to do it is like do some free training on the unlabeled data in the load of fine tuning on the labelled data so basically with the little difference that we maintain all for the self-supervised Lost in the second stage so you do sell supplies free training fine tuning with the supervisor projected supervised loss and supervised loss projected loss illustration of the projected loss which is the main contribution in the paper ring the supervisor distances between 3D points and including space comparing other 3D completely we found is is that we're basically reprojecting distances a distance between pics paralyzing these two losses such that is better behaved in America yes like mostly numerical optimisation consideration to be better behaved at train time benefits by the way of using this supervision that I haven't mentioned is that you catch a scale metric scale in your network my tractor so it works great the video things that we investigated is so hear what you're saying is your thing that image of your single point out so this is the point Cloud so if you're with the kitty that user velodyne vlp-16 light off and they accumulate the scans over a bit of time to identify the point out right until you're seeing this the heightmap the point clouds that are red and green accent the lighter networked a single image of the time pixel to 3D rights and their use in Uganda stand for construction that I was trying before superimpose in with the ladder to see that the light our network is metric scale please skill so this is accurate you could cancel here what you're going to see is cannula could be point cloud right so if you're fully supervised you the full point cloud you say every pixel is that close enough to a lighter point I'm going to use that supervision thing is instead of 64 games you have where did you go for the cheaper building model will be 32c for instance maybe add sitting rooms like the v16 Witch Stanford Avenue on 4 m which is the continental type like for being late alright I found in the paper is that when you train with supervision that's the greater number of Beams to train with 54 games or 232 or 20 or 16 or 28 or 10 with 4 accuracy is like degrading very slow robots 22 louder or using a very cheap lighter I will make one additional work with done is obviously to have a robot that can interact with the Worlds it's not just about 3D right it's not just about understanding geometry so we do also a lot of work on semantic segmentation and protection orders where is the relationship between semantics and and geometry and otherwise are monitored at work they would not work right picture of 18 and you say you can tell the only reason I can tell how far you are is because relationship between smaller Facebook if you have big faces and Small Faces in the world Traders all kinds of faces but you don't have a 2 m face and 2 cm face from not rinsing all your face it before I can tell how far you are even if I take a photograph and I was looking at the photograph bright that's why relationship between semantics and that otherwise I couldn't work how about we leverage that semantic relationship a little bit more explicitly that is paper under review semantically guided representation this is how it works my supervisor right because the reason I see two eyes and you can have things that because people called is a face right that doesn't matter I mean in my labelling system It's Like ID 77 any labelling Rachel wants to stay in the subway setting so let's assume you have as many things network that's free do you have it is part of your on the Vegan label data said you don't have something network result supervise definite work in the same way described before nothing when additional structure you can input into your c say what actually for Death to be accurate to have that feature with symantec again the size of the chair and the size of your faces have nothing to do with each other but if I see many tears and many faces and I know that their chairs and faces I can relate her distance with their appearance very soon babe actually Coolpix like that conclusion used features that are extracted in the competition at your write your representation that you're gonna learn they have to have play features and we learn that additional guidance for regularizer wall of numbers boom where does it work better is a couple of examples differences this tree how to see you see your like dynamic height and big problem right and I'll doors and hear you see how this black tree and you have this Shadow and you have this shaded building really hard to like from prospective right to tell that that part of the pole is actually not part of the building having a cement in guidance enables you to recover the awkward death on this same same exact problem with the no sign no speed limit here same thing like an amazing problem that could dynamic range problem is like there is no better and that just coming across you know right here no no you're fine here just with s because features that are designed to be learned mean variance to laugh ultimate because that's how I tell relationship the matching right like a record and in many other instances of very fine grain structures silver all classes in winter nudist you can basically start to do and combine those and so basically this is just wrong play network the Lawrence network for Death the point cloud you get from so the points out to get from intense the point out with the somatic straight and you start to be able to have cameras that start to good sensor for full 3D semantic understanding in the world an additional last stage of our mission take Infinite we're basically one of the cool things geometry white like from perspective-taking exercise think about and you have a dynamic object that moves that exactly the same speed as you move right so my hands here like always the same distance from my eyes is that you can reproject this accurately from a photometric standpoint is like the hand is moving at the same speed as I'm leaving infinitely big at Infinity navigate closer means that they must be at internet is there infinity they must be infinitely because they just that much this is Alice make a solution to your photo m contact we see this cars that have like you know walked into infinite space that carletti see here or here there isn't in the distance because they travel you know when you're on the road when you follow leave vehicle your typically not like you know unless you're bad driver but you're typically going out the same speed we propose in this paper also Tuesdays training method which is completely automatic and labels and we're basically suddenly saying like all that that he thought was infinity it's actually just riding from your nose concept supervisor at Sue Ryder or binoculars the real reason is we went wrong from Vision what is a queue up when you hear people say perception is solved sure is rubbish reception solved really robustness that cost 0 million dollar even more human lives unusable internally military Force terrible self-supervision that's basically kind of like the key message structure structure structure if you've been and I clear that deep learning conference no structure and now everybody saying how do I put structure in my tea is is that is really the key stereolab super death and sickness also again you combine glasses make sure you're not comparing bananas and and and chips and one cool quotes really nice it's come from in interview vision of yourself closest the Revolution will not be supervised robot scanner scary rides a LEGO robots are not supervisors they know like my advisor give me this robot is going to crash and like fall through the stairs and oh my god and and and when think about the plug into real-world system that you can imagine how we freak out on a daily basis so you have to to really be bold in but safe at the same time really were trying to do and the key here is there an automatic right at science is actually a lot of geometry I listen geometry book is a structure that you wanted what are the data is also mostly on mostly and questions skip what is spelt was down there set timers so so in the paper we compare two which is a state-of-the-art supervised network amazing work like really really cool actually you can see here improve resolution work work just as well with a resolution so that's another key thing and so what we having a bit of a show is that if you increase the resolution of a method separate they can't deal with the details are designed to work at low resolution we call medium resolution at high resolution doesn't bring them a minute that's good I need a resolution and then we improve with high-resolution and then when you're supervised is limited to your light are go beyond provide in terms of resolution so that's also an interesting advantage to be able to really leverage high-resolution and that's designer for this work absolutely scary do that there's no better than that I brush over you can look at what is the news question in regards to the cameras because I don't have the cameras anyway so you would have to retrain the whole network zooming we know the entrance 6 with your swimming That's All Our Data is with the same camera that's a very very very biggest there is really it's necessary to get some good result at this stage now that we get good results we actually how to go beyond that and 1 ways to this to Ghana different about camera model where you actually have insurance that are printable so can learn addict work that so dark I think I need that Google was looking into being like not really agnostic what are the appointments at scale you know the entrance if you have a pretty darn good calibration but it's not the lesson interesting ASOS you're really good television and read this like well you're on your answer at this end go back to your last point on yms images of training on perfect weather conditions tested against like you know night for the next question to get to be all smart or like an orange so yes that's a very sexy domain right now obviously has Jennifer light but one of the things we have tested in his reign that's one of the big brushes that actually convince people to say let's try to make likely research on division 2 really like we need it is this right answer right so the 1550 NM range to reason that it has better like arranged in in depth perception is because of the 1550 NM range you are absorbing the laser pulse fast I say fat tyre pushing lever Bywater better you have you know this big also when did motorcycles end of the robot you know like we have to tell the land so that you know or have ultrasonics and so that you don't have Rangers because you're raindrops a big blind spot in Vision raindrops noise you can still see it's just added some nice so what we found is a DS nurses are very robust to rain because if you train with rain if you collect rainy day happened to much but we have an office in Ann Arbor we do have reindeer so one of the things that t-shirt Olympics so that number one sponsor and we're going to have a fleet of cars that have confuse operation in for like 30 days think about it is it double the motivation to get vision to be really good I said light also has very similar problems and this vision because it can be as good as your data has failed later play something different I am you should be able to yes absolutely the centrifuging right there bus nessuno Byzantine generals problem multiple sensory need multiple systems need to use them together and now there's interesting new ways to she's things right profusion you think I'm and my boss is right so and so obviously there's all that literature right search with a new emerging literature which is around beating a residual networks right if you have a really good initialisation for your bows and you just done a residual from it it's like almost like learning a noise model like now you've made a connection with carbon filters etc and now people are saying Oh Actually I can backprop through the common questions or actually I can backdrop even through my particle filter there is really this kind of adjusted geometry and deep learning whether we're going to see the same problems took robotics and deep learning starring to merge together and dislike new ways to the centrifuge driven way that's yeah so that's I'm very sad for that like there's a lot of research to be done also people that says it's all an engineering problem-solving execution working for different think they're working on something that is a rubber taxi in an area that is full HD map and I can always oh dear that's that's one problem autonomous in the open world things really like and then do research generalized model you passed the quality of question test again question representation vs mixture of expert play do you want to talk to model do you want a princess one thing with the driver recently I can tell you about this traffic light an area you can't some robotaxi company I knocked my company that's doing taxi that wants to become a taxi do a sentence Cisco within the hour burning red light right YouTube video like you want to be like it it's really hard you have to be really really really really what's in the US traffic lights are like this traffic lights are like wait traffic lights have states that are according to the US traffic thing that tells you literally you can go nowhere to really insulin in your life so lets you structure and let's use a state machine and all we can actually learnt at state machine and all that learn transitions etc you go to Tokyo garage how specialised vs how much do you say i a I assume nothing I was just learning from data which was going to be very slow research in again it has to be on a case-by-case basis I believe on a general note on this is that station learning right a car is a car certain things are look the same or are the same certain behaviours or shared because we're all here gravity is there and all this is a common bottleneck there's a really good paper based on The Separation principle for control in the age of deep learn on the information-theoretic side of things which is this notion of information bottom States is a summary state of what is common for your particular my specialisation everybody's doing multi-task learning right so like you provision you see as a common backbone and multiple heads what is cherub say that is terrible and then depending on that if you share a lot you can have a single multitask if you share very little you can have separate Mouse and in-between you can have some form of mixture of experts that can be due local localised you can switch you're going through conditional architectures as ago here take the Tokyo branch little opening on a case-by-case 