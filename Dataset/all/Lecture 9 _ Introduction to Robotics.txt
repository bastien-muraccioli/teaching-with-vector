this presentation is delivered by the Stanford centre for professional development ok let's get started so today Hits radio a great opportunity for all of us to have gastric sleeve one of the leaders in robotics Vision Gregory hager from Johns Hopkins who will be giving this gas lecture end on Monday I wanted to mention that on Wednesday we have the meat room in class tonight and tomorrow we have the review sessions so I think everyone has signed on for door sessions and the next Wednesday the lecture will be given by a former students from Stanford University who will be giving the lecture on victories and inverse kinematics so welcome so it is a pleasure to be here today and thank you so much for inviting me so Osama told me he'd like me too stand electric bike about Vision and is it my guess it's a bit of a challenge last countdown there were a few over 1000 paper in computer vision impaired reviewed conferences and journals last year so summarising all those in one lecture is a bit more than I can manage to do but what I thought it would do is try to focus specifically on in areas that I've been interested in for really quite a long time name what is the perception in sensing you need to really build a system that has both manipulation and mobility capability answer really this whole workshop has been designed to give you a taste of what I think the main components are and also to give you a sense of what the current state of the art and again it's obviously with the number of paper is used every year defining the state of the art is difficult but give you a sense of how to evaluate the work that out there and how you able to use it in a robotic environment until really I wanna think of it as answering just a few questions or looking and have perception could answer a few questions the simplest question you might imagine trying to answer is where am I relative to the things around turn the robot on it has to figure out where it is and in particular be able to move without running into things able to perform potentially some useful test involves mobility the next step up when she decided where things are is it actually like to be able to identify where you are and what two things are in The Informer clearly the first step towards being able to do something useful and Environment is understanding the things around you and what you might be able to do it the third question once I know what the things are how do I interact with there's a big difference between being able to walk around in that bump into thing and being able to explain safely reach out and touch something and be able to manipulate it and some interesting way and then really the last question which I'm not going to talk about today how do I actually think about solving new problems that in some sense were unforeseen buy the original design of the sea that's one thing to build a materials handling robot where you programmed it to deal with the five objects that you can imagine coming down the convertible it's another thing to put a robot down in the middle of a kitchen and say here the table clear the table including China dinnerware glasses boxes things that in potential is never seen before it needs to be able to manipulate safe that I think is a problem mate I won't touch on today but we start I'll give some suggestions as to where the problems lie they should say I'm again I'm going to really breathe through a lot of material quickly but at the same time this is a class obviously if you're interested in something if you have a question I buy mumbling in you can understand me just stop and we'll go back and talking more depth about whatever I just so with that the topics are chosen today really in many ways from bottom if you will to talk from low-level capabilities to higher a conversational stereo a way of getting the geometry the environment around you feature detection and matching with starting to identify objects and identify where you are and motion tracking and visual feedback how do you actually use information from vision to manipulate the world and again I think the applications of those particular modules are fully obby traumatic ability and manipulate so again let me just dive right in I know actually how many people have taken or are taking the computer Vision 15five ok so a few people for you this will be review I you can I hopefully going up for the mid-term whenever that and hope I don't say anything that disagrees with anything that the Jana has touched button so what is capitation on stereo computational stereo quite simply is phenomenal that you're all virtue no you're with it's the fact if you have two light sensing devices eyes camera I and you view the same physical point in space and there's a physical separation between those few points you can now so I'll be triangulation problem I can determine how far is something you from the viewing sensor by finding this point in both images and then simply solving a geometric triangulation simp iron in fact you know there's a lot of stereo going on in this room pretty much everybody Gary auto hardly about 10% of the population is stereophonic from one reason or another so turns out in this room there are probably 3 or 4 of you to actually don't do stereo but you compensate in other ways even so I having stereo takeaway in a robotic system would be a huge step for sorry for the covers didn't realise it is transpose so when you're solving a stereo problem in computer Vision they're really three-quarter problems First Promise one of calibration in order to solve the triangulation problem I need to know where the sensor is are in space related to each other a matching problem so remember in stereo would I'm presented with a pair of images now there's images can vary in many different ways hopefully they contain common contents but I need to do is to find the common content even though there is variation between the images and finally reconstruction once I've actually performed the match now I can reconstruct the three dimension space that I'm surrounded by and I'll talk just briefly about all three of them so first and calibration so again why do we calibrate where we calibrate Brackley number free most important is that we have to occur tries.to sensing device in particular if you think about an image you're getting information in pixel so if you say there is some point in an image it's got a pixel location it's just a set of numbers add a particular location which are interested in ultimately is computing distance to something in the world well pixels are one unit distances are different will you need to be able to convert between us so typically the camera there are four important numbers that we use to convert between them to scale factor convert from pixels to mm and TUPE two numbers that characterizes cinema projection in the so the good news for you is that there are a number of good took it out of that which you do this calibre which characterize with call the intrinsic internal parameters of the camera in addition we need to know the relationship of the two cameras to each other that's often called the extrinsic or external calibre that's also something that you can get very good joke dissolve there's a Toolkit for MATLAB info that salsa quite well so calibration really is just getting the geometry the system so we're setup and we're ready to go now forearm the current purposes let's assume that we have never very special charm so our special geometry is going to be a pair of cameras that are parallel to each other and the image planes are coplanar and vac the scanlines are perfectly aligned with each other so if I work at a point in the left image if I wanted to find the same corresponding point in the right image of some physical point in world it's going to be on the same row in fact that's going to be true for all the roads so it's a really convenient way to the think about cameras for the sell for a camera system like that solving the stereo problem really the geometric centre quite so what did I say I've got a point on One camera minor got a point in another camera the other cameras same line what I can do is effectively solve triangulation by Computing the difference in the coordinates between those two points again now to go into great detail but I can write down the equations of perspective projection which I've done here pretty camera for what I call now the x-coordinate so in fact and this last Friday I forgot to put it out but I can use the coordinates system in Factory this took which ex going to the right why going down in the image and I guess most of you should be able to figure out which direction Z goes once I've told you those two things right ouigo how to camera so he is heading straight out of the camera that's a corner system going to be dealing with things that we can find through easily and some sense of the X and Y the the Unknown is busy so whenever I say that you can think of I'm trying to compute disease I can write down perspective projection for a left Cameron right camera which have done here there are offset by some baseline which I've called be I've also got the white projection but it turns out to be the same for both cameras because it's can wind them so I've got three number xlx r&y I've got three rounds x y and z a little algebra allows us to solve for the adaptor as a function of disparity which again is the difference between the two coordinates the baseline of the camera and the center and the scaling Factor which allows us to go from pixels to mm just a couple things to notice about this devdas inversely proportional to disparity so the larger the disparity the smaller the make sense I get closer at my eyes have to keep going like this more and more and more and be able to see something proportional to baseline I could pull my eyes out of my head and spread my part I could better accuracy and it's also proportional to the resolution of the image insist so if you put all that together you can start to actually think about designing stereo systems from very small vivarium the operator different distances in with different actress the other thing to point out here is that I'm getting inversely proportional to the spirit he means that close to the camera where to get very good depth resolution as we get further and further away our ability to resolve depth by disparity goes down to ask you see I hear you a distance of 10 m wonder spirit levels already hands maybe even hundreds of centimetres of this so scary was actually good in here it is very hard at in fact anybody happening now the human stereo system would it optimal operating pointers we had a class to talk about that tray back here by 18 inches from your nose writing this point you have great stereo cube getting here in your eyes start to her you get out here passed about an army and it just turns off you actually don't use stereo at 1 it's really just using it in this Workspace in a Corsa makes trying to manipulate right a strong assumption about the cameras I said that they had is very special drama I'm back in the good old days when I was young I'm either good days by the way just so you're all where's that back you're in the good days right now enjoy them back in the good old days we actually used to try to build camera start an hardest geometry because if you start to change that geometry you no longer get this nice can Minecraft soundtrack if I rotate the camera in word if I start to look at the relationship between corresponding I start to get these rays coming out sofa pick a point here the wine is now some slanted wine well it turns out locally when are the things that really been nailed down in the last decade is there dead as a man we can always take a stereo pair that looks like this and we can reset all the images so it's a stereo pair that looks like that in fact by doing this calibration process we get it so the good news is I can almost always think about the cameras being these very special Scanlon wine can so everything I'm going to say from now on is going to I'm pretty much relying the fact that I've done the circle rectification process so again a very nice abstract I just point out again enough to talk and what about it and the relationship that I just described so how do I save a point in One camera how do I know the line to look for it on second camera two functions of the relationship the rotation in the translation between the two cameras and it turns out is it against something that really been nailed down in the last couple of decades I can estimate this from image so in fact I could wait away take a pair of cameras put them in this room do some work and I could figure out the geometric relationship without having any special apparatus whatsoever but it also means is instead of doing stereo I could get away just take a video camera and walk Like This process the video images in effectively do stereo from a single camera using the video and that's because I can estimate this matrix be in that relationship up there which if we worked out within was it turns out the container rotation and translation between the two cameras and once I know that I can do my reputation and I can do stairs so actually stereo is very special case in some sense taking a video in processing it to get motion and structure so again that's a whole vector we won't go in there suffice to say the from the geometric point of view we can actually deal with cameras now in a very general way with relatively little of the assumption Ben Holly start ok so geometry calibration is done and I want to but to do reconstruction I need to do matcha I need to work a pair of images and say hey there's a point here in that same point is over there and I want to solve the triangulation set a 2-minutes in region-based matching so feature-based obviously pants in feet I could run an edge detector in this room I could find messages chairs the edge of people the four America trading match these features between images and alpha every feature I'm going to get that so if you do there you end up with these cannibal stick figure type cartoons Soho Theatre at a book shows in this is the result of running a feature stereo algorithm and on the one hand it's actually giving you the right representation right the major structures here the shelves in it's finding the shelf do you know that you don't get any others you just getting those features that having a pull out of the image so the other approaches to say forget about features let me try to find a match for every pixel in the end it's so cold dance step every pixels gotta have some matching pictures or at least up to some occlusion relationship so let's just work 4 min try to find enter this is so cold region matching matter I'm going to actually pick a pixel plus IT support region how to find a matching region in another room and this is better Cottage industry for a very long time and so people pick your favourite ways of matching your favourite algorithms to apply to those matches and so on and so for so again at a huge literature in doing that you're a few few match Matrix which have come to be used very widely tell me the most common one is something called the song about differences it's right up there or generally I get something called 0 min si dia some of that and that's probably the most widely used algorithms the least of which because it's very easy implement hard and it's very fast so you take a region you take the difference take a region take a region take a different sticker apps with value some those and assume if they match that difference is going to be small if they don't match it's going to all the other metrics I have a pure I really different variations on that theme is take this region take that region compare them and try to minimise and maximise sun so if I have a match measure now I can work it correspondence again I get to use the fact that things are scan when the wind so when I pick a point in the left my teacher picks on the last day I know I'm just going to work on one single line and the right image not the whole women so simple album for every row for every column for every disparity cell for every distance then going to consider essentially and now going to complete my maths method in some window I recorded if it happens to be better than the bed Nat I found for this pixel art sorry if it's better than the best mattifying for the pixel recorder if not I just go around and try the next two spirit so you work this out with how much computing are you doing well every pixel rows and columns everyday spirit so for example for my eyes if I'm trying to compute on time of canonical images over a good working range in a 3/4 to a 4 maybe 100 disparities 120 disparities so Rose x 122 size of the window which might be what's a 11 by 11 free comment so there's a lot of Computing in this I want to watch in fact up until maybe 10 years ago even just running a stereo algorithm was there a fit just point out that it turns out the way just describe that out for them although intuitive is actually not the way that most people do in Fermanagh is a slightly better way to do it is literally MATLAB go to I'm bringing in computer vision this is the MATLAB computer stereo on and you can see the main thing is I'm actually looking 1st of the disparities and then I'm looking over effectively rows and columns doing them all at once the reason for doing this without going into details as you actually save a huge number of operation so if you ever do and come in stereo and I know there are some people in this room her interested in don't ever do this it's the wrong thing to do do it this way it's the right way if you do this you can actually get pretty good performance out of the sister just one last wish to this so one of the things that's going to happen if you ever do this is it gonna you can be happy because it's going to work reasonably well probably pretty quickly and then you're going to be unhappy because you're going to see it's going to work well in a few places and it's not going away another place someone in computer vision can give me an example of a place where they sell them is not gonna work sunlight is unlikely to work situation a simple situation I'm sorry ok Benetton replication girl band is going to be a problem right cos I'm going to get occlusion relationships will change the pixels let's go to clusion to bed about this I look at a white sheet of paper when am I going to be able to match between the two I must nothing I tell you to put a stereo out in this room it's going to be great on the chair accepted the band but it's nice whitewall back there there's nothing a man so it's not gonna work everywhere so I'm gonna work if you place how can you tell when it's working it's one thing to have an older than that does something reasonable tune other to know when it's actually work are any answer turns out to be a simple check is I can match from left to right next match from right to left now if the systems working right they should both give the same answer right I can actually hear it shouldn't make any difference well when the right when you have structure to the image that will be the case bye if you don't have good structure to the image of turns out you usually just getting random and and so I said something like 100 asparagus right so the eyes that you pick the same number twice out of 100 is really pretty and so it turns out that almost always this period is therefore and you can detect that it's got the left right check and a multi-core processor it's great because you have one core doing left-to-right 1 core doing right till at the end I just meet up in you check her out listen disparity Maps these are actually taken from an article by cork and banks some years ago just comparing different metrics I hear it just happened I have two one is so-called SSD sum of squared differences the other is 0 mean normal is cross correlation couple this quick things to point out so I can the top images you can see that the two metrics that they chose did about the same can also see that you're only getting about maybe 50% data dance so can you turn the left right check half the date is bad so can I have another thing to keep in mind 50% good day 100-percent not 20% or 50% second row why is there such a difference here well is a brightness different energy can see but the right images darker than the left well if you just matching pixels the brightness different shows up as just a difference it's trying to account in the right Colin they've taken s 0 meaning there's a crack in the mean of the neighbourhood of the pics get rid of brightness differences pulls him into a better alignment in the brightness enter the better dance and this is just in artificial tea the most interesting thing there is it's an artificial scene you've got perfect photometric data and it still doesn't do perfect because of these big areas where there's no tax it doesn't know what to do with so it's producing random answer left right check frozen no guarantee is that correct he could make a mistake but the odds that makes mistake it turns out a quite small it actually yes I should say it's a verbal bible mention because usually it's going to pick the wrong pixels occasionally by chance to it'll say yes it doesn't be isolated pics usually if you making mistakes you don't make a mistake on a pixel you make a mistake on in area amateur trying to do is really kind of military away a good point it will it's not perfect actually in the world division it's one of the nice things that you get from US free I just say that these days what you see out there is real-time stereo so starting really about 10 years ago people realised if they're smart about how they implement the other than they can start to get close to real time now you can buy systems that run pretty much and software and pretty 30 frames a second stereo data caravan dimensions yeah I said that the date is not perfect well the day it is not perfect and as a result if you can imagine we could wait to do is textarea build the geometric model I'd like to do manipulation I want to take this pain I want to have a 3D model and then I want to generate or 3D well you saw those in stereotypically doesn't produce data that's good enough to give you a high precision completely dance 3D it's an interesting research problem people working on but it's a great modality just want to kind of rough 3 description of the war and you can run in real time and you now getting a real time horse 3D and so I think that's why right now real-time stereo is really getting out of interest because it gives you this course widefield 3D data 30 frames a second let you just do interesting things I just thought I would throw in one example of what you can do this is actually something weird 10 years ago I guess your mobile robot anyone detect obstacles in a running on a floor an article with positive optical something that I'm going to run into or could be a negative article in I'm coming to the edge of the stairs and I don't want to fall down the stairs sanguinius stereo to do this answer the main observation is that since I've seen them all my shopping on A4 get a grand point and it turns out planar structures in the world are affected by planar structures in disparity it's very easy to detect this big Pine ant remover in want to remove that big pine anything that's left it's got to be positive and doesn't matter what it is so you run stereo you remove the ground pine if there's something left that something you want to worry about a boring so here is a a with a video showing this so there is a real-time stereo system the first we put down something that an obstacle it showed up nearest something which if you were just doing something like that grand subtraction you might say that newspaper is an obstacles difference in the 4 rights you would drive around it could be something you don't want them into b here since we've got this ground plane removal go we can see that this is very quickly an obstacle that is very clearly something it's just attached to the foreign disk and this is something real cheap easy simple dimple that really is the great value of stereo on robotics right now today you're sad most Ariana Grande can give you this course sense of what's around you and where you're going and you can use it for downstream constipation in Wallace tarian research there what about the issues of people trying to deal with how do you increase the density increase the precision deal with photometric issues like shiny objects deal with the differences between the images just by the brightness I'm like a texture how do I deal with the fact that in some places I don't have my protector how do I unfair some sort of death there and also geometric ambiguities like occlusion down how do I do it occasion is I'll be part of the image at the left camera sees in red camera so there's ongoing research there most of these methods are just so fridaythorpe stereo not as this local region matching problem I mentioned it is a global optimum cancel there's a lot of work and different global optimisation hours and there is hope that ultimately stereo will get to the point that they really can do the sort of thing I mentioned I'm going to pick this up and I really want to get a 3D model in use it for an overlay are we not there today I should just say that there's one simple way to get a huge performance boost out of your stereo something that people often do everybody can get one way to just take a stereo out make it work at home at better speak about life how I could change the sheet of paper to be something that I could actually do matching you want to text you how could you add text DAB radio just put away projector on the top of your stereo system and you'll be amazed at how well at work suddenly this thing that you could not before it becomes the world's best place to do stereo because you get to choose to text you and you get to match it so that's the other thing that people that little add into your seeing the word search structured lights carriers another way to get better flat stereo the message here is by using two cameras you can get at this point data density and accuracy that's 2 exceeds pretty much anything else you can imagine the laser rangefinder in world it's not as rival so it's a rangefinding and that's probably the thing is still there the main topic any quick questions on that before a shift gears ok timer robot I'm running around at get real-time stereo I don't run into things anymore it's somebody walks in front of me ice cream away as quickly as I can so that I don't hurt them bye I have no clue where I am in the world I have no clue what's in the world around me so if you said you I go over to the printer and get my print out where is the printer where am I where is your office who are you so how can we solve those problems in fact this I think is an area of computer vision that I would say in the last decade has undergone a true rebel 10 years ago if I would have talked about arctic recognition in this lecture we really had no you're kinda some interesting things going on in the field but we had no and today there are people who claim that at least certain classes about the recognition problems are solved we actually know very well had a built Solutions in their actually commercial solution so what is the problem with article well it's a chicken and egg pram if I want to recognise an object there are many unknown so I work in an image I don't know the identity of the object I don't know where it is and most importantly perhaps I don't know what's what's being presented to me so I don't happen heavily after we go so you know if I say recognise find myself down in the image you don't know if you're going to see the front of the cell phone the back the cell phone the top of the cell phone I don't know if you're going to see half of the cell phone hidden behind something else you don't know what the lighting on the cellphone is going to be huge unknowns in the appearance where they won't then finding at the image and segmenting at in the next week doing identification so is a sense in which if I could sygnity on if I could say here's where the object is in the air then solving recognition and pose would be very e if I told you the power the answer solving segmentation and recognition with easy to what if I tell you what the optic is finding it and figuring out it's poses doing all of them at the same time as hard super long time people try to use geometry so maybe the right thing to do is have a 3D model of myself down and use my stereo vision to record are we just said stereos not real reliable probably not good enough to recognise abs another set of people were said well how about we recognise it from appearance so let's just take pictures you know the way I'm going to recognise myself down if I just got 30 pictures in myself down and you'll find it in the end so you can do that in fact can see here this is some work at 3 hour about 10 years ago medium pretty well on a database of about 100 but you know some other things not the baby black background the Antiques actually only have in this case one degree of freedom it's rotation in the plane so yes they've got 100 objects but the number picture is that they can see it's very small no collusion no real changing lighting so this is interesting you know and sometimes they generate a lot of exciting how the first assistant I could ever do 100 odds but it is very limited answer the question was what how do we how do we bridge that gap how do we get from hundreds to thousands and do it in the real world really the answer you can always think of this combining pyjama tree in the current based approach so the observation is a views are very strong and strength giving you all these different views and recognising from views work 4:00 it's just hard to predict a complete view it's hard to predict what part of the cell found I'm going to see it's hard to getting up images of it to be represented it still isn't sold the problem of occlusion if I don't see the whole thing cell view seemed to be in the right direction just not quite there so criteria smithboro pieces in 1997 with Roger Moore he tried a slightly different approaches said what if instead of storing complete views restore thank you this interesting aspect 7 you know if you're going to store face what are the interesting aspects well but things like the eyes and nose in the mouth the cheeks are probably not that interesting is not much information there and but the eyes and nose in the mouth they tell you a lot or you know myself down you've got all sorts of little textures so what if we just started to think of it this way thumbnails of an art to my cell phone is nice a bunch of images it's a few thousand thumbnails and I suppose that I can make that feature detection process for repeated so if I show you my cell phone in what different ways you get the same features back now suddenly thanks start work interest because the signature of an object is not the image Kirsty thumbnail manahatta Poole the sun if I get half thumbnails maybe I'll be just fine if the thumbnails don't care about rotation in a pint that's good they don't care about scale even better so it really starts to become a durable protection in fact this is really what his revolutionise this area any particular there is a set of features called sift scale-invariant feature transform which I know you warned about computer Vision developed by David Wells will you become pretty much the industry standard in fact you can download this from this website build your own attic system if you want imagist talk a little bit about a few details in your car so said features is where we want to go well the two things that we need to get good features when is we need good detection repeatability I need a way of saying their features on this wall this warrant ation features in this mode disorient I should find the same features so detection has to be invariant 2 image transformation and how to represent these features somehow probably just using a lot of thumbnails not the best way to go right is a thumbnail if I take myself down and I wrote a little bit out of plane where I rotate even in plane image changes away and I'd like to know I have to every possible appearance of my cell phone under every pass so I'm we need to represent them in a corner in go away how many watts and when I say why TM I mean ring white light Pacific features service problem they doing the following way they do a set of filtering operations to find features that are invariant to the detection is invariant to rotation and scale it does a localisation process to find a very precise location for the signs in orientation to the Future so now if I re detected I can always assigned the same orientations That featuring cancel 4 rotations in the image builder keypoint descriptor out of this information typical image shield about 2000 stable ironing some evidence recognise an antique like myself phone you need 360 self Matthew 1000 features only need 10 2% any of there so again just replay the steps set a filtering operations with a trying to do is to find features that have birthday local structure that's a maximum of an objective function and a size or scale that's a maximum object the Ruby doing a three-dimensional search for a Maxim Wednesday have that they say harder series The Future keypoint descriptors what they do is a computer second gradient structure avium so this allows them to sign a sign of direction to features and so again by getting by having a sign orientation they can get rid rotation in the image so if you do that in your rented an image you get confusing figures like this what time is it drawn arrow in this image for every detective feet sorry was being a big feature so a large-scale feature and smaller is being fine detailed feet in the direction of the arrow is this orientation assignment at the and he can see in this house picture it's not even that picture it's 233 ba189 832 regional keypoints filter down to 536 when they did a little bit trying out without wood bed so what's the features lots of information has been memorized but discreet not the hallway mate discreetly if you take those features in your try to match features it turns out also the very discriminate so if I look at the difference in match value between two features that do matching two features that don't match it's about a factor terrific and so there's a no signal that you can actually get matches pretty wired dimension geometry so right now a an object would just be a suitcase a feature self I going to memorize myself and I just said I gave you Santa nails so most systems actually build that into a view so I don't just say my cell phone is just a bag of feature is a bag of features with sunfish of relationship among it's an hour if I'm out a feature up here it tells me something about what to expect about features down there am I generally if I see a bunch of feature matches I can now try the computer in object code that's consistent with all of them and that's how the feature matching work is a something called I have transformed you can think of a voting technique just general voting is a good thing I just says inside this whole thing that I've been talking about are trying to do is to set up voting we're really trying to be in an election where we're not going down to the August convention to make a decision of who's winning the primary this is an election that we want to win on the first try these features are very good feet they do very discriminative messing about you are a little bit of geometry and suddenly in the future match you're getting clothes and identity of an app from a very small amount of in the hero couple of results from David Rose original paper Soham you can see there's just a couple of doctoral training at froggy and there's the scene and you know if you just given that cm think even a person has to look a little bit before you find a frog in the toy train and on the right are the detecting frog in toy train including A Foggy that's been almost completely hidden behind that the dog black Frank Fletcher in his backflip you don't say anything else in the systems actually detect this case two instances that one so we got one instance even got it realise that even though was a clue it's one on tick I'm in Leeds again I think it's fair to say fly remarkable where the field was at that time since then there's been a cottage industry of how can we make this better faster higher stronger so this happens to be work by pants in Roscommon will they try to extend it by using better gymnastic models and slightly richer features so they're 51 hours and they can have any number of objects in a scene and this is the sort of are recognition parts that you're starting to see now so you know when I'm talking about getting right 60% of the time was 70% of the time getting 90 + percent recognition rate and his dad now of course I've been talking about antique recognition just point out that magic recognition is there's an object in front of me and I want to know it's identity in its pose or you can think of the Arctic is the world and I want to know my pose the Inside this big actor called the world cancel for example if I'm outside and might see a few interesting landmarks and recognise remember there's one more using features and now when I drive around the world I'll go and I'll look for those same features again and use them to decide where I am this is again workout of ubc whether literally using that same method to model the world recognise you I'm in this room I see you bunch of features I go out in the hallway I see you bunch of features I go in the area I see about your feet story of the speeches and now I am driving around in world I look for things that I recognise if I see it then I know where I am relative to where was before moreover remember I said that first area to get geometry we didn't have to actually calibrate a stereo system we could have one camera any could just walk around make a computer so cold epipolar geometry automatic and then we could do stereo sewing fat with they've done in the map save from One camera as a driving around do not computing just the identity but the geometry of all these features are so they can build a real 3D map so I can build the laser rangefinder but now just by matching features and in fact we edited a joint issue of ijcv and ijrr about I guess 6/8 months ago can we have the papers in that special issue ended up being how can you use this technique to map the world in different variations so again is a technique for true in many ways is there you can download it from the web practical and put it on your mobile robot make it run in fact this is my favourite result so this is work Brian Eustace who are was postdoc at Hopkins with Wickham who doesn't have underwater robotics so this is the Titanic this is actually about expedition with a Flew Over The Titanic with the camera and the goal was obviously to get a nice set of images Titanic the problem is that underwater it's really difficult to do very precise localisation and Adama enter what Ryan did is he took his technique any build effectively a mapping system very high precision mapping system it was able to take these images using images to localise the underwater robot and then put the images together into mistake answers here's a mosaic of the Titanic is a Flew Over can see the numbers up there play actually ran for about 3.1 km when is it how many images there is over 3000 images 4500m not successfully computed the motion of the robot successful filtered all this together memorable to Bruce this music a really impressive impressive cyst they actually have so from this and should you get the 3DJ I am listening active they basically project it down they are computing up to the surface features of the report 43 and actually the little red vs Brown up there read I believe is the original odometry that they thought they had on the robe Anna Brown is actually the corrected odometry I'm not a computer or vice versa I don't know which is Which now I can remember if they did the two separate pieces are related to a really impressive very nice also I mentioned here doing the accountant film through the he built this comical to that operated on the space of so that is the next piece of this puzzle you said one of the thing in here so why are people interested in 3D now so this is Peter out also putting together in curious just showing the Range data but you can imagine if your brains an appearance now you can actually do interesting things using both 3DS another some work going on here today so let's get a chapter 2 so now a set of techniques that not only let me avoid running into things in the world buy a set of techniques that let me say well where am I and where is some things that I'm interested so you can now I actually imagine praising the problem I want to pick up the cell phone and you could actually have a system that recognises the cell phone is able to say hey there is something I might pick up so I just finish up with what I thought was the last piece of this puzzle name way how do I pick it up I'm not gonna tell you exactly how to pick it up this I'm out of interesting and heart problem picking your head put my fingers on this attic actually pick it up release let's talk a little bit about the hand-eye coordination it takes for me to actually reach over and grab or even better if I do that if I do that how do I get a cat which Barclay I did my Zippy every sad watch so I'm going to talk about this in two pieces so one piece is going to be visual tracking so when are really moving to the remain where I want to think about moving objects in the world and having precise information about how the move how to change so visual cracking is it to tax a promise I know you're so video if you week ago humanoid robot that was playing badminton ping-pong Bible Valley by takeaways and so I think it already explained that they doing some simple visual tracking of this big coloured thing coming out using that to do the feedback what's the big horrid thing tonight unfortunately myself phone is not dayglo orange so it's hard to just use colour is the only thing that you deal but tracking has been your problem with interest for a long time tracking people tracking faces tracking expressions also two different tracks when I think is interesting is supposed to say what you mean by tracking to begin it's gonna call the red paper that says tracking about but no one's already find tracking so I have a very simple definition of Visual tracking with simply I'm going to start out with a target your my face is going to be there the canonical target here so I x 0 for some reason you decided that's the thing you wanted in the game in town is to know something about where it is bedtime in the something about where it is something is which you in principle gets back please can I have the configuration space for this after yeah I could the simplest thing is your big orange bowl it's just round to it got no orientation it just has a position in the EU it's configuration is just where the heck is the orange bowl but you can imagine you know my cell phone has an orientation so presumably orientation might be part of the configuration or if I start to rotate out of plane you get out of plane rotation a fact about a rigid arctic how many degrees of freedom does it have you know the answer to this sex yeah wake me there's no trick questions and he knows what he's doing so he told you it's 6 of really is Sex is no not questionnaire I'm set so sure if this is a rigid object in principle it must be six degrees of freedom that describe it of course you know if it's my arm then get more degrees of freedom how many more has any ok so there's going to be a configuration space for this object and ultimately battery car battery is that configuration space the problem is that the image we get depends honest configuration space and so here I'm going to imagine for the moment that I predicting image yes I know it's configuration if I knew the original and so you can imagine this is like the forward kinematics of your robot can I give you a kinematic structure and I'll give you some joined value and now you can say hi here is a new kinematic configuration from either so the pub menu I am going to take a tracking problem so I know the initial configuration I know the configuration at time T and you're the original image now that I like to do is the computer the change in parameters or inverter just the premises and sells I don't know if he stand for so don't ask I want to complete the new configuration it's time to plus one from the images time 2 + 1 and everything else ok another way to think of this is I said I believe I can predict the appearance NRG from 02t I can also think of the other way around I can take the into time t if I knew the configuration I could predict what it would have looked like when we start and I can try to find a configuration that best explains the starting and so this really is effectively a stabilization from I'm going to try to pick a set of parameters they're always make what time predictor work as close to the original Templars possible to take the face and unrotated in try to make it look like a ridge SMI stabilization point now is an image answer this gives rise to a very natural sort of notion of tracking where I actually use my world model that I described my prediction model to take the car in image apply the current parameters produce but hopefully something all slightly in are the Attic to start with so if I start with myself I'm like this in later on or it's like they are going to take that in southwards hopefully it looks like that again if it doesn't look like that is going to be some difference and take a difference running through something hopefully that something will tell me a change in parameters accumulators changing parameters and suddenly I've updated my configuration to be right now it's interesting about this perhaps it's just skip over this for the moment we can for Pinar object we can use a very simple configuration which turns out to be a so-called affine model Sara salvet stabilization from or again I said I'm going to start out with predictive model which is kind of like you're kinematic and if I want to go from kinematic description talking about positions in space to blotches in space what do I use jacobian imagine that hey we've got you now kinematics in the rigid body world without forget kinematics an image let's take a Jacoby we take it to cobian we now relating one changes in configuration space the changes in appearance just like the jacobian robotics really changes in configuration space to change Cartesian position today girl I'm going to take it to Cove big jacou so the number of pixels in the image might be 10000 I'm going to 10,000 Rose and however mini can figure 10000 by 4 set a reminder jacobian but it's jacobian and let me know how to take now I've got to wait for a wedding change and parameter to change in the image closer measure an error in the image which is kind of locally like a changing image so an error in the in the alignment well suppose I effectively inverter jacobian now I can help you to Sue interest could I get this big Tom instead of M2 so I take the incremental area that I've seen in my line go backwards to the coving around beholder give me a change until I close the loop by whether we doing interest account it's the same thing you could use control your robot to a position and quotations stagecoach really no difference really is a set point control problem I'm again I won't go into details right now this is a huge big time-varying Jacobi it turns out that you can show this is work that we did and names of smile same you also the work showing that you can make this century a time in Birmingham which is just a way of implementing things very fast what is a utopian look like for the coping about images you can look at your Toby because they are image so this is actually what the hounds of magicka being look like so this is the jacobian if you work at the end for a change in x Direction motion in what kind of make sense you see is beginning all the changes in the along the the road why is getting a change one the column rotation is kinda getting this varsity field misdirection stone and stuff so that's what it looks like if you never said you're going it turns out that I will I still use for planar object you can do this for 3D so my nose sticks out a while if I would have just kind of you my face is a photograph and I go back this it doesn't quite work right so I can deal with 3D by just adding some terms to the Caribbean in fact you'll notice what can I say I've got a big nose in so that's what comes out in the jacobian of my face is my nose tells you which direction am I facing again we can deal with illumination and this is actually probably a little more interesting I can also do with occlusion one tracking because if I start to track myself down in a girl like this for low and behold it's on pixels that don't fit the model so what I do as I had a little circle blue wedding with the just detects affected some things run out of sync ignore that part of the in so you put it all together and you get something that was not like so I just so you know what you're seeing remember I said this is a stabilisation problem to find tracking something right I should destabilizing the image I should be subtracting all the change so that would all picture in the middle is going to be my stabilized face I'm gonna start by tracking my phone and this is actually the big moon your system I'm saving my jacobian which action includes motion and includes some illumination components to which I didn't talk about so I'm just showing you chico Bean you can kind of see over on France flashing as a badly made videos back when I was younger uninitiated internet you can see I'm running the tracking this is just using planar tracking so as I tip my head back and forth and move around it doing just fine hi scale is just fine because I'm computer all the configuration parameters that have to do with distance not accounting for facial expression so I can still make goofy faces and they come through just fine now I'm saying to an unseen partner turn on the lights so I think some lights flash on and off photo showing you can actually model those changes in illumination that we talk about and stereo to gruesome magic that only I know who is Noah that is not hard to turns out that for navigate bike your face if you just take about I have a dozen pictures under different illumination and use that as a Win Your basis for elimination that works fine for me how does hair than 20 side to side Owen it clearly doesn't know anything about 3D you can actually make my nose grow like Pinocchio so just let this little one ok so now they're putting the 3D model enter the interesting thing I do to my nose is suixtil I actually know enough about the 3D geometry the face in 3D configurations that I'm cancelling all the configuration are the changes due to configuration at as a side effect that happen in a worm looking too so if you look at the backside telling you at any point in time and I hear I'm just kind of pushing it eventually if you start to get occlusion starts to break down obviously because I haven't I wish I could fast forward this before the days of fat and my face is falling apart he wasn't supposed to be there you're happy it's the Saturday what are you doing and this is showing the what happens if you don't deal with occlusion in Vision see the can a knock in the singer back and eventually and now we doing that exclusion I'm saying hey with things now things don't match and are you girl set alarm so you can take these ideas and you can then push them around and lots of different ways this is actually using 3D model here we're actually tracking groups of individuals in regrouping and dynamic go on here is probably the Most Extreme case so this is actually tracking to DaVinci to Altrincham surgery William Waring be parents of the tools restart the nearest 18 degrees of freedom so it's a tracking in 18 degree of freedom configuration space doing Siri ok very last thing I've 10-minutes I'm racing for home now so I I contractor cool so why it's fine the thing I said I wanted to do eventually was to finally manipulate something I want to use all this visual information I want to pick stupid self h and call my friends and say the Vision lecture is finally open robot GO Outdoors the question how long to do that so I got camera everything also School information I got a robot that I want to make drive around where do I drive it too how do I drive it so which should I put in that box any suggestion you can assume that so good stereo I've got pretty much anything you've seen what's anybody think about I don't care which way you want to think of can you put that back what information would you use and what we put in the bath going to be on the mid colour simple thing you can imagine right inside if I said I got two cameras I can actually with those two cameras measure a point in space I can actually calibrators cameras to the robot and so could just say hey go to the point in space Enda story breaching betting good or bad I think it could be good or bad ok your night March second monitor in real-time right so that would get rid of that from what my broadband at the rustic robot what's my kingdom angry I carried out the DaVinci kinematics that great so I could reach out to a point space but maybe Miami here or there instead write to the camera to tell me to go somewhere but it's not really closing the so what if I do one better what if I compute the position of my finger traffic lights say in the computer solution is a phone in 3D space now I can actually closer lyrics I can say I want to make this distance 0 can we get right down in control that would actually do that it's your favourite controller I know it's summer has some ideas of but and that will work in fact our work pretty darn well suppose that my cameras are miscalibrated in fact suppose that I say what I want to do is to go along a line defined by the edge of the cell phone I might be here turns out you can show that if you do it in position space and reconstructed space and your cameras answer of the calibrated you can actually get there infecting it arbitrator is if you want real likely better can happen there's one of the possibility which is I'm looking at this thing I'm looking at this thing what if I close the loop in the image if I just write my controller on the image measurements turns out if you do that and what is cold calling code if you can encode the task you want to do like touch this point of the cell phone to my finger and do it in the image space now in reconstructive space are you defined an era doesn't mention calibration I did just says make these two things coal incident in the image if you can close that loop stay boy think of jacobian being for example you can actually Drive the system to a particular point and you've never said anything about calibration in your error function between said even if the camera is calibrated you go there in fact is pretty good evidence that with you you don't sit there and try to figure out the kinematics of your arm in the position in space and then cannot close your eyes go there you're watching right in your ass for using visual space we know this because I can put funny glasses and rice and after while you still get pretty good getting your fingers I'm again and this time it won't go into great detail but the interesting question is really when can you do this in coding when can I write things down in the image domain any answer again depends a little bit and what you mean by camera what spice to say you can do a set of interesting caf just by doing things in the air closing the loop in the image space and the interesting fact is that sorry pass you might imagine like putting a screwdriver in a screw or putting a disc in a disc drive you can write it on the image space and you don't need Calvert care or you don't need well calibrated say so this is why did Ava get into could I was sitting in the Superdry hat yellow and I started to this tracking and just for the heck of it I've got this robot controller division 2 Lucy and tracking and controlling here and bye the usual cynical young family member I never expected this thing to work first time I had in Calgary the cameras I just guessed with the calibration was you know I just through the code to get I found this thing on it work I mean it work within 1/2 mm it wasn't like it just work it was right and then I start to think about and I realise the coursework I didn't need to calibrate the camera until then we actually spent the next four years thing why was that I could get this kind of accuracy out of a system where we are put the cameras down on the table what are interesting about a foot apart and random Ennis the wild woman and that so it's out there doing some stuff and you know doing more problem of pulling your eyes out of your head and moving it over here and saying ok see it still do whatever you end you know just to prove you can do useful things with that we had that my pizzeria you can also see how long ago this was by the the form factor of the Macintosh than putting the floppy disk into anyway alright so I'm a bad at it at the time but I hope I have convinced you of this the least of these basic capabilities we've got you know we've got stereo real time respirometry we can recognise obvious we can recognise places outside of it we can track things and we even know how to cook closed Loops in way that are rubber so we don't have to worry about having finely tuned so why aren't we running around with robot you're not playing baseball with it well I've given you the simple version of the war obviously if I give you a complex geometry object you haven't seen before neckwear we really know how to pick grande motte lower hope we're getting close why the World Is deformable Not rated by the configuration space had I talked about tracking it and manipulating it and I'm other things somewhere in between you and rigid objects on a train yes I could turn it like this but it really doesn't accomplish the purpose in my understanding those physical relationship in the real world there's a lot of complexity to the environment it's not myself down sitting in and cuddled gaskets my guess would be happy if it were that in Qatar and I'm telling you to go and find something on it mean if you are so complexity is still a huge issue complexity in terms of what's out there is complexity what's going on people walking back and forth and up and down things changing things moving so imagine trying to build a map with People moving through the corners all the time I want to go to there's some movie can I infect again I know is something of interest in human computer interaction you know I can track people so now and principal I can reach out and touch a peep what's the safe way to do when do I do how do I do it what am I trying to accomplish by doing so how do you actually take these techniques for daddy wire which is really socialism say social interaction type of a narrative notice but I think he's not yeah there's a a research aspect to it is also a market aspect with a what point has become interesting to do in a what's the first killer app for Absolute picking things up and moving it around escort to do it can you actually make money analysing and beginning I said this yeah the real question is when you going to be able to build a system where you don't pre-programmed it's one thing to program it to pick up my cell phone it's another program that pick up stuff and then at some point having worried about cell phones and say go figure how to pick up this cell phone and it's a plane by the way don't scratch latte glass tell again it's about work going on but I think this is really the place where I have to stop and say I have no idea I'm going to sell those I know this all the problems I've talked to bed so far but I think this is where really things are reopening Angela cross-cutting challenges of building complexes putting together so they work so I'll just close them by saying you know the interesting thing is all this it's getting more and more I'm this tired I'll just tell you is dating myself I broke my first visual tracking system in my last year grad school because I wanted to get out and I needed to get something and it ran on something called microvax to and Grandad 10 Hz on a machine that cost 20000 box so cost me about 2000 hours at cycle to get visual track inside still have it over him today and far and I just kept running it as I got new machine service numbers are literally Towers Herts recycling but I could get out of the sea it's from 2000 hours till when I get tired of doing it about 7 years ago when it was down to 20 sensor literally for packet change I could have visual track so you know all the vectors appointed and rightway insurance technology knowledge I think we've learnt over the last decade give me a call to we've now and see all of the stuff that actually happening I think the real challenges putting it together so if you work at an interesting set of objects an interesting set of tasks like be my workshop assist which is something I proposed about 7 years ago did that you can actually build something that would really go out and say a ha I recognise that screwdriver and he said he wanted the big screwdrivers so I'll pick that and I'll put it under screw or hand it to him or whatever I know I've never seen this thing before but I can we still out enough to pick it up and handed over and say what is this when he says it's a hiya I'm on the way it is the pieces are there is the interesting message but nobody has put it together yet and so maybe one of you will be one of the people so I'm I think I'm at a time I take everything I said wake up if any questions or take questions including after class 