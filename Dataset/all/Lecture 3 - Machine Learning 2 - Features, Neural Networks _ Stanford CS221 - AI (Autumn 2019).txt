ok welcome back everyone this is the second letter I machinery so just before we get started a couple of nonsense homework 1 foundations is due tomorrow at 23 know that it's 11 p.m. not 11:59 and please I would recommend everyone Friday do a test machine early right it would be unfortunately you wait until 10:59 and you realise that your computer or you can log into the website if that has please don't just bombard me or emails so just to remind you are responsible for any technical issues during connoisseur please do that test emission early to have a piece of mine and then go back to finish in your homework next Tuesday and finally there's a section this Thursday which will talk about backpropagation and nearest neighbours and DVR overviewer scikit-learn which might be useful for your project so please come to that ok so what's champion I'm going to spend a few minutes with you in what we did last time kind of storing at the various tracks and rolling down into the details so fast track level learning as well taking your dataset and helping a predictor app which will be able to take inputs X4 tampon image and output or label or output why for example whether is a car door artrocker someone and if we talked about how we want to parameters optimisation problem which captures what we want to optimise what properties the predictor app should satisfy apart from the optimisation algorithm which is how we accomplished or objective optimisation problem that we talked last time was minimising the training was and symbols this is the training loss which depends on the particular way back is the average overall examples in a training set of the lost of that particular example with respect to that way tell me what a find the wmm Isis so we want to find the single w.org mixtures on average all the examples have ok so looking at the loss functions now this is where it depends on mobile trying to do if we doing regression than the permanent thing to look at is the residual which remember is the models prediction - the true label so this is how much we offer shoot and the loss is going to be zero if the residuals 0an increases either quadratically for the square glass or early for that deviation depending on how much we want a pennywise large deviations classification classification more specifically to look at is the margin which is the score times of the Labour why which number is + 1 - 1 so the margin is in single number that captures how correct we are so large margin is good in that case we obtain either zero or near zero what margin listens your means that were making and mistake so there's zero Moss capsules that were making a mess I've lost one buds are the hills light another just last Kind of grow linearly because allows it to optimise the function better question I'm so there multiple graphs are here so remember last time we look at residual if you look at exore Fairfax over why so here's a line cures a particular point of X field xry and the residual is basically the difference between the models prediction and the actual Point Clear this is different this graph is on visualising is in a different space make some of these things are on the 3rd of March for craft what is the residual is on number so if your residuals can you Academy this is the last this case end of the residual is -2 then yeah that was that any other questions about this the square last walk analyse large and wires a lot more which means that has can a mean mean like qualities where is the absolute deviation penicillin last so it's more like a median just for intuition I'm but the general pointers are all these last functions capture properties of a Desire predictor basically say how many predictor and I'll try to assess for you how good this is right this is kinda establishing what we want out of it and you also another comment is that this loss minimization framework because it's so general anything basically that you can give you some sort of your loss minimization if you think I'll PCA or deep neural networks different types of autoencoders they can all be viewed as some sort of what function which year trying to minimise o that's why I'm keeping the framework summer general ok so what's a good observation of generality example and try to put all the pieces together so suppose me I'm a simple regression problem we have retraining example 10-day output is 210 dr4018 is - 1 right so how do we visualise what learning on this looks like so let's try to phone the training was the trainer last remember is the average over the loss of that individual examples so let's look at the what is an individual temples so we doing linear regression so and axis two-dimensional and Fear Factory goes xx so in this example so we're basically trying to fit two numbers that mean one in W2 so if you plug in these values for X and Y into just last function then you get the following quantities so the doctor between wnx is just wy right I'm because x Xperia 0 and you -2 and you swear because we looking at Square glass the same thing for this point instead of 2 you have a 4 and therefore this wwfx - why is W2 now because I'm now the tours are active - - 1 squared so these are the individual loss functions each of which tells what I kind of what out of w so if I'm looking at this W1 is too then that's great I get it lots of 0 this once we want is for that's great and I get a lot of 0 obviously you can have both indigo of the trainee loss is trying to look at the average so that you can pick one we that works for as on average is good for all the points ok so now this is a function in two dimensions it depends on W1 and W2 so let me try to draw this on the board to give you some more intuition with us all looks like I'm going to draw W1 W2 and so the first function is W1 - 24 K so so what is this function what to do what we want to be close to or closer to and didn't care about W2 right so I'm not really sure had a drug test from him but it really request or something in 3 days so you can think about the ball shaped kind of coming out of the board I like this if this direction is meant to be there ok so I'm going to try to do well let's let's try this it's going to be ok no problem look like ok so what about the second one the second one is W1 - 4 squared so that's going to be basically the same thing but I kind of centred around 4 so this access the board and then finally the other point is W2 - - 1 so it's going to be happiest when W2 is -1 so it's going to be kind of a bunch of your problems come out the board ok so you add all three functions up and what you get you get something that is on has first where do you think the minimum should be wanna b the first electric Ireland volume down to 30% the Red Lion payment it's definitely been minus one because this is the only function that one so it's gonna be somewhere here and both by Cemetery were this one wanted to BR2 this 14 so the average is somewhere between you can work out this actually mathematically I just giving the Rock into Russian and let me Draw the locus hear the love of curves are going to be something like this where again if you drive on a 3DS like I'll probably come out of the board here we're here is the lowest point alarm and as you venture away from this point your life is going to increase ok yeah how do I get the smell of Pointe so one is that if you add these two functions up and kind of planet it turned out to be at 3 it would have read the square Los when you're average x x Amin so can a no it's going to be somewhere between is also related to one of the homework problem so hopefully you'll have a better appreciation for that ok so so I guess what's we have the 3 of 1 and 12 answer question is once we have the three how do you measure with a minus one so the three is regarding we wine and the minus one is regarding W2 so you just add them together in this particular example they don't interact in general they will summarise so this plot shows for every possible way back to Adobe wondering to have a point and the amount that the function comes out of board is the loss and the last function is define on in the slides while there and I'm doing is trying to plot this function The Last of Us Part II so unfortunately it's hard to Canada 93d so what I'm trying to do if you're taking each of the pieces in trying to explain what each piece is trying to do so in general the training loss you don't have to think about kind of how exactly it composes the individual losses this is probably as complex example will have to understand it but this gives you an idea of how you connect these pictures were you see him these are problems with in the picture which is actually the of the ok but for now let's assume it's a function of a property sum function and how do you optimise this function so you some sorry gradient descent so last time we talked about how you can just do vanilla gradient descend where you initialise with the year of and then you computer draining of the entire training loss and then you update once and the promise that is the computer gradient requires going through all the training samples and that's really slow so instead we looked at the grandstand which allows you to pick up an individual example and then make a gradient step right away add empirically with shower in cold how it can be a lot faster no of course there are cases where it can also be last stable it so there's gonna be some your trade-off here but by and large the cassegrain understand it kind of really dominates machinery applications today because you there's only way to really have scale to large ok yeah I'm so apart from being the scale-up is there any advantage of the cassegrain understand another besides carpet another advantage might be that your data might be coming in online fashion like over time and you want to know update kind of on-the-fly so there are cases where you don't actually have all the data once that was a quick overview of the general Concepts now two sets the stage for weather going to do in this like you when I ask you a question so can we have change decision boundaries remember decision boundary is the line that or the curve that separates the region of the space which is classified positive vs negative Lee can we have the paint decision boundaries which are circles by using when you're passive ESO armour doesn't make sense so we want to get something like this where you have now we're going into one of x902 of x and we want to the Cinnamon Tree is that look like this where you classify maybe these positive and negative is that possible so you're saying yes ok so we're going to start by talking out of features which is going to be able to answer this question 50 years old and talk about neural networks which is in some sense of automatic way2learn futures show you how to train your own networks using back-propagation hopefully without ears and and then talk about nearest neighbours which is another way to get really expressive models which is going to be how much simpler ok so recall that we have a score to the scores between a wave vector and a feature vector and a scores Rise predictions so if you doing regression you just help with the score as a number if you doing classification by the classification than your output the sign of the score so far we focus on learning which is how you choose the wave actor based on a bunch of data and how you optimised for that so now what we're going to do is focus on feedbacks and talk about how you choose the speeches in the first place add this actually feature in feature extraction is no such a really critical important part of head of a machine learning pipeline which gets because when you take a class using ok well there's some Future Factor and then let's focus on all these algorithms but whenever you go and apply machine learning a world future extraction is turned out to be a kind of them no not scan navigate to some extent by you still it doesn't completely make feature extraction on your absolute so we call that a feature extractor takes on import such as this the string and outputs a set of properties which are useful for prediction so in this case it's a set of a named r future value last time we don't really say much about this we just kind of wave your hands ok here are some pictures in general how do you approach this problem what features do you include you just like start making them up and how many features do you have we need maybe a better organisation or Prince in general featuring is going to be someone of Arts I'm not going to give you a recipe by list some frame everything about features for the first notion is a feature template is informally just a group of features are computed in the same way this is all kind of some up Atlantic buy a caravan that I want you all to Canterbury aware of so I'll feature template is basically feature name with holes so for example length greater than blank so remember the concrete features lines greater than 10 now we're gonna say they were black and replaced with 10 9 8 or anytime the Templar Dad give rice in Multiple features last week equals blank contains character blank is all examples of feature templates so when you go in your project or whatever and you describe your features only think about a group in his features in terms of know these blanks another example if you have to be like a raw image right there Sue implicitly some sort of why did think about it as of feature template which 2:15 like the pixel intensity of position glenconner plan is to give rise to the number feature is equal to the number of pixels in image and is useful because maybe your input isn't just maybe it's better than having this kind of language for describing all the features in a unified way is a really important for clarity ok so as I leave it too which feature template maps to a set of features so by riding last three quarters equals blank I'm saying well I'm going to define a feature for each value of blank and that feature is going to be a city with a value which is just a natural evaluation ok so all these are 0 and 1 so in a general you are going to have each Peter temple again I give rise to many many features the number of possible 3-letter characters your some number of characters to a cube which is the larger number so one question is how do you represent us right yes first Factor yeah good answer so mathematically it's really useful just think about this on vector as a dimensional vector just numbers just laid out and because that's mathematical convenient but when you go to actually implement this stuff you might not represent things that weigh in a particular know what are the ways you can represent a vector well you can say I'm going to represent the red which is just this list of numbers that you have what is it in efficient if you have of accuse number features bad in the cases where you have a sport features which means that only a very few of the feature values are non-zero then you're better off represent as a map or in Python a dictionary would you specify the feature name is a key and valuers and older the home and basically work in this parts of future your framework and you're just going about know a lot of especially in NLP and we have discrete objects on traditionally it's been comment to use candy sports feature maps no one today has happened with the rise of neural networks is that often you take a basically your employer time in Batman 2 songs for the fix the metal vector space and that feature representation have been more dominant but no sports pitches if you want to use mirror classifiers is still can have a good way to go so it's understand it's ok so now I'm sorry storing possible lot of features now just sports store the key and the volume alright so this was your tablets the overall point as an organisational principle an ok so that's switchgears all about so which features are featured templates should you actually write down I want to introduce another notion which is your pretty important especially if you think about the theory of machine learning and this is class ok so remember we have this project so for a particular way that that defines a function that maps and imports into it and iPod this class is just the set of all predictors that you can get if you are very the way Factor ok so let me give you come back to the slides let me give you an example here suppose your dream regression and you're doing your linear regression in particular so you going one dimension Furious x and here is why so if your feature map is just identity to maps x 2x then this notation just means the set of all functions like this then the set of functions you catch you can visualise as the sweat so you have in a 1 function here and for every possible value of w1u have a slope of 0 we should all go through origin and you have no these are your functions your hypothesis class F1 here is essentially all lines that go through think about it when you write down a feature bachata your implicitly come in yourself to saying hey I want to think about all possible predictors define by this feature ok so here's another example suppose I define the future map to be x comma x squared so now what are the possible functions realise that I'm like and all them in particular it also includes the layer functions right because I can always set w20 and very W1 which means that also get all over your functions to right so this means that don't have to if you think about the set of functions of larger set than F1 is more expressive and we mean by the expressive that means I can represent more things so for every feature vector you should think also about the set of functions are you can get by that Factor ok so what is there a question 90s R&B expressive expressive set it off myself in terms of no that's why I answer is not necessarily in terms of sure you have more features so that it is more expensive but the difficulty optimisation depends on a number of different factors and sometimes anymore features can be easier door tonight because it's easier to figure it out ok so now let's go back to this picture ok so this is on a concrete examples of feature or now let's think about this big blood as the set of all predictors any predictor in your wildest Dreams know they're in this and whenever you go and you define a feature map that's going to Cork out so much smaller set of functions and and then what is lonely doing learning is choosing a particular element of that function family based on the data this picture shows you can before pipeline and how are you doing machine learning is no there you first declare structurally I said of functions that you're interested in and then you say ok now based on data let me go and search that set and find the one that is best for me so now there are no two places where things can go wrong extraction maybe you didn't have in a future so now you're you're you're a purple said is too small then no matter how much learning you do you just not going to get good accuracy and conversely even if you define a nice on his class if you don't offer most popular you're not going to find the element of that no hypothesis that fulfills your goals will be able to compute function the question is so you're define your function this is fixed and then learning sets and together John Lee that specifies a particular function or predictor don't use the appropriately stick with O2 line display tuition tells me regardless of the issues the actual model YouTube should be able to do you know burn the function fee that you would affect I know it's doesn't learning kind of compensate yeah just figure out the field that you would have picked I'm so the answer is no the fears really kind of a bottleneck year if you define fee to be asked so that's when you're when you're right so if you did that moves around in a sinusoidal way you was looking alike fiddle with that and your kids Christiano mount of learning the only way to fix that is bi changing your feature representation why is on Bruno Mars so yeah so all this assumes that we were talking about the new predictors of course the same general idea to any sort of play a song so to some extent than the Manor fishing you have to do it today as no much less 1 things protect you wanna predict your the somproperty about your movie review know what the first order bits are like what even goes into that does the text that you have meditated you have other star ratings and those are no pictures you can there's no such thing as like because there's always song called that takes the the world that down into something that fits in memory so that you can think about this feature extraction yeah question is why don't you just make fears largest possible score on all the features and overfitting is no one of the main concerns which you're welcome back to the next lecture ok great questions so what's what's actually skip over this so there's another type of future functions you can define an interesting question is linear what is this yes right because I'm what is a new function it's basically some kind of waited ok so is it a linear in Fairfax by symmetry should be because it's just a dot product so is it linear in Acts no in fact this question doesn't make sense because xx mimosa stream so ok so here is the nearest kind of the coating now is no please predictors can be expressive long linear function in decision boundary in the case where is the actual real Factor but the square is a linear function of w ok so this is core because you're from a prospective right from the point of actually doing prediction your you think about like how does the functions operate on X and you can get all sorts of no crazy functions coming out we just look at quadratic functions but you can do all sorts of things but from the point of view of learning it doesn't care about that this is Fairfax in a particular you're learning ask a question how is this functions depend on W because it's turning W&W and your first reasons I'm not gonna go into this conscience official morning because the loss function becomes complex which up that's also ok so so one kind of cool way to visualise what's going on here then you're going back to us so remember we want this to the m classification problem where the true decision boundaries the Harley fit that what does it mean for a linear because we think when your is like should be online right who are I graphics ok so here is Adidas points inside the circle and classify but the point is when you look at the fleeca map it actually lift this point into a higher dimensional space now have three features write in add you in this how-to mysoulspace I can actually things are now I can slice it with kind of a knife and then you're in the high-dimensional space it seems are cut and what it induces in the lower dimensional space is the circle so hopefully that was a nice visualisation that shows how you can actually get non-linear machine functions out of machinery right and you're ruining no nuts no that's technically is false because you actually get really expressive models out of your own that works out of linear models the point when you're now it's not that they're not your more Natalie Morris but the fact that they have other of energy for example in doctor advised that comes with architectures and the fact that there are more efficient when you go to a more expressive models and someone ok so wrap up all things I want to come to us no simple exercise so here's a task so imagine you doing your final project and you want to predict Mayweather two consecutive messages in support of forearm or a chat or the second one is a response to the first so it's fire classification in put it through messages and asked to predict whether the second is a response to the first ok so we're gonna go through the exercise of coming up with your features there might be more featured templates might be useful to do pick out properties of x to my beautiful and we're going to assume that were dealing with linear protectors so what are some features that might be used for WhatsApp who is the last time with you so how about time it last between the two messages that useful how many insidious ok so this information is definitely good what's autopoint is that the timer Labs is a single number and this number is going to go into the score can have in a linear fashion so what is that mean that means if I double the time then the score is going to or that the contribution to a square is going to like x 2 so think about it as I increase the time it becomes generally more likely that I'm going to be lots of not a response or no response so this is your maybe kind of not what you want because you know the difference from that perspective like if you were the Time molasses like a year then that really count dominates the score function on way more likely that is going to be a response than if it were like 1 minute which is and not what you want you're 5 seconds and 1 minutes because everything is squash ta20 right so approach that is to the future's so that if you have a numerical value which you really kind of want to three kind of in a sensitive way you can have a break up into pieces so the future tableau would look something like time elapse is between black and blonde so you can do things like ok is it between 0 seconds and 5 seconds and is it in 5 seconds and like a minute and between a minute and an hour an hour and a year or something and then after that it doesn't matter because I'll give you a kind of more it's more than my knowledge that tells you kind of what things to look out for the difference between latte a year and a year plus 2 seconds is it doesn't matter where is the difference between One S and 5 S might be significant so long way of saying classifiers or even if you're using know now works I think it's really important think about how you're right features are can entering the system and think about like if I change this feature by light it up does the prediction change in a way that no I expect from having the same what prevents us from here so if you have every possible range isn't that like a infinite number of features so even if you did that you might still be ok because there's probably some if you think about like discretizing this space of time elapsed time elapsed and you're basically saying for every bucket I'm going to have a feature it is true that you have anything but you might just cuddle up and if you don't come often used sports teacher representation you don't have to I'm have a preset because remember most of these features are going to be 0 because of chances of some data point being like you know 10 years is going to be in general when you have features that or have multiple timescales you want a kind of space it out kind of wore red microwave so you wanted 22440 on so that you can have both kind of sensitivity and but also kind of cover a large on the back make it the most informative hospital learn how to discreet eyes the the features there are there's different more automatic things you can do besides just and specifying them at some level though you have to input the value Bourne liked it if you input into x vs what a log of x no choice is often can make a big difference but if you use more expensive model techno now he can no mitigate some of this yeah good question so when would you actually want to not describe it so there are essential you expect kind of the the scale that feature too roula cannon mada in innocent certainly when you think that something's Behaviour when you're early then you just want to preserve the any or if you think that it behaves quadratically than you want to keep the future but also add like a square turn to a move on this happy to discuss more often I'm so some other features my include a first message contains blank would like is a string right so maybe things like your question marks are more indicative things been the second message me message contains word two messages both contain a particular word on your there is cases where it doesn't really it's not the presence and absence of particular words in the in individual messages but like the fact that they both share a common word used for another teacher of witches have I'm some number of common words I'm so this feature is an interesting because it's there's you look at this feature it's how the number of what's a future actually future tablet so for this feature template there are many many features 14 possibly any number of words and this leads to kiss as well you might have a lot of sparsity and you might not have enough data to fit all the future where is this one is very compact that says I just have to look at them number of overlaps the two messages my container word I never seen before I know it's the same word and I can recognise that pattern I'm so yeah there's quite a bit of things you can do to play around with features that capture the intuitions about what might be relevant to your task question knockouts the question is when you have a large sparse features do you want to do dimensionality reduction ALM not necessarily so in terms of computation how many sports pitches it doesn't necessarily mean that it's going to be no really slow because there's efficient ways of don't suppose teachers in terms of expressivity one thing that in allotment of your application UFC do wants a lot of features and you can have a lot more features than you might think you can handle it because you really wanted the first orbit is just to be expressive enough to even fit a dog let me move on ok so summary so far no we looking at features we can define this feature templates which organise these features in a meaningful way then we talked about this class which are order fine by features and this defines what is possible from learning arm all this in a context of linear classifiers which incidentally can actually produce these nice and a decision but in the next section I want to talk on your now works because these are even more expressive models which can be no more power arm one thing I often recommend is at yeah when you're giving a problem you always try this simplest thing always try council in your class and just see where we get because you'll be surprised at how far you can get with the newer classifiers and that and then go and increase the complexity as you needed I know there's sometimes it's sentation to your Friday fancy new shop no hammer but sometimes keeping it simple and really really good so that's there's a couple ways of motivating this one motivation is no comes from the brain I'm going to use our kind of slightly different motivation which comes from this idea of decomposing a problem into parts this way this way and I want to determine whether it's safe which is positive or it's going to cry lot suppose for simplicity that the true function is as far ok is there just measuring whether the distance is at least one car park now this is kind of a little bit like what we did in the last lecture where we suppose it was a true function and then see if they can recover that we're in practice obviously we don't know the truth but this is for pedagogical purposes ok so just to make sure we understand what functions were talking about so if I'm X1 is one next to S3 kind of like that on a board then your plus one so this is like driving a us this is like driving in UK no mate that's fine too but if you are too close together than that status alright so what's think about decomposing a problem because if you look at this this this could be your kind of complicated on your function I was trying to break down into kind of linear function because at the end of the day no networks or just about of linear functions with which are stitched together with some normal so like there are linear components that are Critical to their own that's ok so one so problem is the checking car one is to the form out of cartoon is greater than you another problem is testing whether culture is a fortnight of car one and then and then you can put it together by saying if at least one of them is your one then I'm going to put safe I'm otherwise I'm not safe ok so here is our kind of concrete for 13 Carter reason for right of car one so that's why you added uptake assay what's my name in after Direction it's so fine and in this this case but it's 1-hour 0 so that this is just kind of trying to take this expression which is true function and ride in the morning model away we have different pieces course I need different competitions ok so now we could just write it down obviously to solve this problem but we are in the what the radio but suppose we didn't know what the true function is in we just had data so that so we don't actually know what these functions are so can we kind of learn learn these functions so what I'm going to do is going to define a feature vector now I'm over text which is going to be wine X1 X2 and then I'm going to rewrite this intermediate Sopranos follow x two green and one is going to be represented as this vector V1 Dad review 1 is - 1 + 1 - 1 so you can you pass for a second you can verify that this is X19 to know greater than equal to 1 this is just another way of writing yeah what we wanted in terms of this like that product and you can see kind of how this may be moving more towards something that looks so typical which allows you to not just no threshold on 0 B restaurant how many inulina classifiers that talks about generally you always have a bias term that allows you to and modulate how likely you're going to predict 1 vs -1 ok so you can also do it for 82 it's the same thing but just on the switch in the roles of X1 x2 an Elsa for sign a final sign prediction you can write it as follows now CDs adjust weights on H1 H2 ok so now here is the kind of the punchline is no fraud no network we're just going to leave V1 V2 and W as unknown our quality is that were going to try to fit through training but we motivate this problem by saying ok and this case there's some choice of you 12w that works but now we came generalising if we didn't know this one of these we just leave them as variables and we can actually still ok so before we were just turning w and now returning both of and this specifies the choice of the hidden problems are weird interested in and W government how do we take a result of the hidden problems and come to a final ok so this one problem here which is that if you look at the gradient of H1 with respect to everyone it happens to be 0 ok so if you look at the horizontal axis is V 1.4 your bags and packs is H1 that function is looks like a step function right because indicator function of some quality criteria is more over here over here and remember we don't like 0 gradient doesn't work so the solution here is to on take some sandpaper and you use this function to smooth it out and then you get something that is no different so the logistic function is this function which is a smooth album version of this riser so it doesn't hit 1 or 0 ever but it becomes extremely close but it kind of goes up in the middle and you can think about this as I'm a difference of all I got a smooth version of the step function behaves and looks like the step function is search kind of the same intuition that you're trying to test whether some quality is good but it doesn't the value of the function has 1 - 2 value of the function and the value function ever hit 0 ok so now we can define no not in contrast to liver function so remember a linear functions we can visualise it as inputs go away add the employee gets raided by some why you get the score for the function looks like now with one and two hidden units 12 what's the something like this where you have on disintermedia hidden units which are the sigmoid function I'm applied or logistic function in this case in Derby concrete apply to wave actor Vijay x so each one is are going to be taking the employed X Factor and you get some number here and then you send it through the song logistic function get a number and then finally you take the output of each one Age 2 and you take the dot product with respect to you and then you get the final score soaking the intuition is that are trying to break down the problem into a set of problems where you the problems are the kind the result of these enemies you can think about these days each one is really kind output of a mini when you're classifier it's too as output of a meal in your class tomorrow then you taking those outputs and then you're taking them through another within your plastering in the score so this is what I mean by you at the end of the day it's kind of linear classifiers packaged up and strong together and expressive power comes from the kind of composition question 8% day the question how do you get a chance of Jay when there's multiple please it's only one Fairfax also this is this is a first component of fear that so this vector there's this is reading and it has two functions of the one where you can think about it is that features from data as opposed to having a fixed or set of your features feel right because this layer we always see these which are coming through which look like no features that works you can't just keep on stacking there so you know this output of one a set of classifiers becomes a foetus to the next layer and the output of that class or becomes a features to the next layer and someone for now works is that as you proceed you can derive more abstract new features for example images you saw with pixels and then you find edges and then you define object parts in there now you define kind of things which are closer to the actual classification problem why don't H1 and H2 basically end up in the same place because because of symmetry if you're not careful that will happen so if you initialise all your waist is euro and I'll or initialise these weights the same way then they will be kind of moving Locks locks tap so what is typically done as you randomly initialise so they can you break the symmetry and then what the network is going to do is it use learning problems too I became complimentary because you do it this joint learning I should know responsibly know that these are Mabel last in style than they used to be in the coating into now is to use a value or are rectified linear which looks like this and you might ask why this one well there's no one reason but I'm this this function has less of a kind of this song gradient going to zero problem it's also simpler because it doesn't require exponentials but there's I'm going to just leave it at that what the benefit of this function is pedagogical results and it's a little bit of a throwback to ok if you read a note and electric slicers and more details on like why you would like change choose One vs another ok so now we're kind of ready to doing you're not learning right so ok remember we have this optimisation problem the trainee last now depends on both v&w and remember is the average of glasses of examples the loss of interview example that question is the squirrel difference between Wi-fi and the function value and remember the function value is the summation over the weight at the last layer x activations of the hidden layer and and that's a bit of a busy quiet and I have to do a computer screen so you look at those things you say ok well you know if you get in your house enough scratch paper or you can probably like work it out I'm not sure you different way to do this without going through the change so this is going to be based on the computation graph which will give you insight more edition inside into the kind of the structure of complications and visual as what it means what does a gradient mean in some sense and also happens at this competition grass is really at the Foundation of all these modern-day planning frameworks like tensor form part 2 so this is a real thing you're turns out bad no way I thought this it made people still can't prefer to bring out the mouth while except for maybe you're more familiar with that so I would encourage everyone to can at least try to think about the competition graph as a way to understand your brilliant even though initially it may not be no faster and it's not to say that you always have to draw a graph to computer but you're doing a few times might give you additional inside that you went otherwise get ok so here we got so functions we can think about them as just boxes right the boxes you have some imports going in and then you get some alcohol at all function is and partial derivatives or no gradients as a question the following question how much does the Albert change of interchanges on little bit ok so for example if we have this function that computes two times in oneplus into in 3 you have to question like you take input 1 and you just had a little bit so I can read out what happened in this case added so then you can clue that the gradient of this function with respect to in one is because the greatest Hamza amplification if I put in Epsilon Epsilon Alpha gradius 2 with the partial derivative it's ok let's do this one so if I add Epsilon 2 into then I algebra showdown get change in in 3 episode so what's on the PARSHA with respect into right ok good so you could have done that but I really want to stress that interpretation of inputs and witnessing the output because I think that useful information ok so now all functions or not also made out of the box but most of the functions that were interested in this class or going to be made out of this these 5 pieces ok answer for each of these pieces it's it's a function it has imports and you put things in and you get an outfit plus minus x Max and the function ok so on this edges I'm going to write down in green the the partial derivative with respect to the input that's going into that function so let's do this the partial derivative with respect to a is and the parcel delivery to restrictive BS1 if you have minus then it's wine -1 if you have x then the partial is be na everyone follows so far ok so Max what is this is amazing I love you so so so remember my last time we have the result of Max in the context of the class right so you have the mass of these two functions which is this which means that you know what what is what is a another is p so if a is greater than b than other then word need to take the delivery with sorry then arm ok let me do it this way you know that thing on the board so I just have maxi of you ok so suppose as 7 and 3 because this the sweetest smile doesn't matter and in this case if I change be by a little bit then there's alpha change no because 3.12.19 is all so the MAX Function it's partial derivatives look like this so if he is greater than the then this is going to be a 1 if it is lesson to be this is going to and your conversely over here if I'll be is greater than Aiden this is going to be a lesson for the partial of maximum is always 10 depending on this particular your condition and then you can fit in your free time but I had on a previous slide it's just the sigmoid logistic function x 1 hours of function now you can compose and can build castles out of them all basically all functions are you seeing just basically and how you compose things there is a nice think all the chain raw which says that if you think about info going to find function alpo going to input a new function the partial derivative with respect to the input of the output is just the product of Portugal and you can think about is you think about amplification so this function Enterprise by two times and the centre of this country advertised by 5 all applications going to beetroot house fire we're going to do a classification with the hinge loss I'm just as a warm up and I'm going to draw this computation graph and then compute the partial derivative with respect to w ok so what is this graph so I have w x fee of x that's a square X Y that's a margin 1 minus margin mass of 1 oz margarine 0zy ok so he remember the parts of the river lateral side raise your the the right branch SE10 4 - this is a - 1 for a time this is going to be one of us over here I'm for the times it's gonna be buy the train roar if you multiply what's on all the edges then you get the gradient of the wash with respect to w doesn't get a graphical way of doing why you probably what I did last time which is if the margin is Alyssa bread and wind everything's are all in the margins that someone's and perform this so in the interest of time I'm not going to do it for the simple neural network I will do this in section but you either I love all you basically do the same thing you multiply all the the edges and you get everything that allows you to compute gradient for arbitrary competition craft any kind of functions that you can build out of these building blocks you can actually just get it so you know one nice thing about these packages like pytorch tensorflow is that you actually don't have to computer to reverse on your own used to be the case Dad know before these people will have to implement these Two Rivers by my hand which is really tedious and error-prone and part of why it's been so user to account is that all that's done for you automatically ok so that replication is going to two types of abuse of forward value and a backward value so fi for every node I is the simply the value of that expression and the backward value GI is going to be the partial derivative with respect the output of our that support apple fic is going to W1 x sigma SD1 you g of that node is going to basically the product of all these how much does the snow chains that open at 5 as a very tall ok so the album itself is you're quite straightforward there's a Ford pass which computer all the advise and then there's a backward pass a computer that so in a 4 pass you said from the leaves and go to the can you compute each of these values can be cursed were there computation depends on the sub expressions and in the backward pass you simile have a recurrence that or gives you the value of a particular GI of a particular note is equal to the GI of it's parent x whatever is on so it's ok to take a 4 past you phone or their fires and then you take a backward housing you feel more alright so I section will go through this and realise this might have a quick one quick note about optimisation is that now you have all the tools that you can do it you can run as I know which doesn't really care about whether you're what a function is just like a function you have a look and complete the great and that's all you need but one kind of important thing to note is that just because you can computer gradient doesn't mean you optimise the functions functions defined functions on top you get these complex functions functions are these functions that you can hold in your hand and in the have one global minimum and so if you think it's going coming down till you convert to the government and you solve the problem where is no nets it turns out that the loss functions or non-convex which means I will try to go downhill you might get stuck in local Optima in a general optimisation of your that is hard in practice people somehow managed to do it anyway and a works there is a gap between theory and practice which is an active area of research ok so in 1-minute to nearest neighbours to be fine because it's really simple so you can do in 1 minutes ago so let's throw everything we know about Slayer classfinder that you training as you store your training examples that's it and then the predictor of a particular example that you get is you could go through all the train examples and find the one which is closest has employed which is closest to your employer I know he's going to try you're going to be turn on ok so in intuition series that similar examples of output ok so here is supposed to mention vacation and you have plus over here what's 2 + and you have your minus ok so if you are asking what is the label size that point it should be plus because this is closure this is to be minus this region should be - should be plus and what kind of thing is that if what is the decision boundary so if you look at the point equidistant from these and drop her particular that's a decision boundary there same thing over here and so you have basically cards out this region were this is - and everything here is this is what percent of worn-out diagram which if you were given a bunch of points on the defined regions of points which are closest that point and everything in a particular region like the television is assigned the same level as this point and this is what is Colin on parish tomorrow which means that the number it doesn't mean that there's no problem is it means that the number of predators is not fixed the more points you have the more each point is on parameter so you can actually fit really expressive models I'm using that it's very simple but it's kind of competition expensive because you have to store your entire training ok so we look at three different on models and now there's a saying that why I guess in school you there's three things that is sleeping party or something in you have to only pick two of them will suffer learner's kinda same you can either be fast to predict for linear models in neural nets you can be easy to learn for the linear models and nearest neighbor's or it could be powerful for example like your networks and nearest neighbours but there's always some sort of compromising exactly with method you choose will depend on what you are ok see you next time 