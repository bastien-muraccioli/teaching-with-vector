Quran start again today play sleep chat what I'm going to do is be talking about question answering over text another of the big successes in using deep learning inside natural language processing and it's also a technology that has some really obvious commercial uses a son it's an area that's attracted a lot of attention in the last couple of years bo4 plan just a couple of reminders some things at the Beginning about final project stuff and then for basically all of it is talking about question answer motivation history talk about the squad data particular simple model l stand for the 10th of reader then talking about some other more complex hymn to the most modern stuff innocence what's the double purpose because if you're going to do the the default final project well it's about text your question answering and this is your chance to learn something about the area of textual question answering and the kinds of models you might want to be thinking about and building but the content of this lecture pretty much as in no way specifically tied to the final Project subject matter that relates telling you about how people using your nets to build question answering systems first as quickly on the reminders mid quarter survey I mean a huge number of people have actually feel this in already and we already had over 60% play Switch by the standards of people who do surveys they can as a huge success already but if you're not in it for saying I would still love to have your feedback and now the perfect time to do it just wanted to have a node on custom final general it's great to get feedback on custom final mechanism for that which is the project proposal I mentioned last time it's also great to chat to people me about final Project people and I've had been talking to want to people that final projects and they're very happy to do so but there's sort of a problem that there's only one of me so I do also have encourage you to realise that among the various tiers that really lots of them have had experience of different deep learning on the office sales page there's a table with like this but you can read it if you look at it on your own laptop which talks about the expiry and many of them have open areas and many of them are also good people to talk to you about final Project so for the default final project the text or question answering so draught materials for that are out today I'm right now on the website x really we calling them draught because we think they're still probably few things are going to get changed over the next week so don't regard as completely final in terms of the code but you know it's sorted 90% fine also in terms of deciding whether you're going to do a custom final project or default final project and working out what you're putting into your project proposal how much should be you know well more than what you need for this year the one other final B eyes play that I didn't get to last time is so for the final projects regardless of which kind you're doing well parrot some experiments of doing stuff with data and code and getting some numbers and things like that but I do really have encourage people to also remember that important part of the final project is writing a final project report and this is no different to any research project of the kinds that and students do for conferences or journals and things like that right to spend working over your code and experiments but in most cases the main evaluation of your work is from people reading a written paper output version of thing important that instead of reflects the work that you dear than the interesting ideas that you came up with and explain Sandwell and present your experiments and all those due to do a good job and writing up your project vague outline project write-up is likely to look like now there isn't really one size completely fits all depending on what you've done different things might be appropriate but you know typically the first page you'll have an abstract for the paper and introductions the paper will spend some time talk about related prior work what kind of models you built for a while discussion of what day they are using for your project experiment commonly with some tables and figures if you're doing a more tables and figures talk about the results of the hell well your systems work and it's great to have some error analysis to see what kind of things that you got right and wrong and then maybe at the end this sort of plans for the future conclusions or something like that whatever it for my extra ministry play questions on final projects that people are dying to know I'm good luck to say good luck final fish everything into the question answering so I mean so question answering is a very direct application for something that human beings want to do and maybe human being stone and general want to know the Aquarius who is Australia's third prime minister and maybe yeah that's not really the kind of thing you going to put into your queries but you know maybe you query who is the lead singer of big thief or something like that I don't know you are but you know what's a large percentage of stuff on the web is that people actually are asking for answers to questions if I put in this query into Google it actually just works it tells me the answer is John Christian Watson I'm so that sort of question answering work in the real world and you try different kinds of questions and Google you'll find that some of them work and what's them don't work and when they don't work you just thought of getting whatever kind of information retrieval web search result one fine point that I just wanted to mention down here so another thing that Google has is the Google Knowledge Graph which is a structured representation of knowledge and some kinds of questions I'm a being answered from that structured knowledge representation and so I mean quite a lot of the time for things like movies it's coming from that structured graph if you're so say who's the director of a movie or something like that but this isn't coming from that this answer is a genuine the kind of stuff we going to talk about today it's text your question on string from a webpage question answering system has extracted the answer if you explore these things one of these boxes here for a cabin off there's a little bit of Grey that says how did I get this resolved and if you click on their it actually tells you what sauces get it from and you can see if it's away from the text your question answering system or from something like an knowledge graph so in general the motivation for question answering is the these days there's just these sort of massive collections of full-text is the Billy answered information and traditionally when people first start thinking about search information retrieval Zafira old you know that kind of quantity and size when people first started building search system Unthinkable to index whole documents because no one has had this big enough and those days I didn't really they were indexing what titles and abstracts or something like that and so it seems perfectly adequate and those days to say ok we've just going to send you give you your results as the he is a list of documents only 100 words long I'm not the case now when we have these Sotheby no 10-minute read medium I have the answer to a question and so there's this need to sort of saywell can we just have systems that will give us recent changes in technology have hugely underlined that need documents works ok if you're sitting at your laptop but it works really terribly if you're on your phone and it works even more terribly if you're trying to work with speech on a digital assistant device something like an Alexa system you want to actually be able to produce systems that can give the answers to people's questions the clay doing that is factored into two parts part of bed information retrieval we use quite standard information retrieval technique documents that play the reason of this is normally done by quite traditional take additional techniques extremely scalable billions of systems actually are really scale liver billions and documents that's an area inside of which researches on going have sorted some candidate likely contain an answer and if so what is the answer and so that point we have a document or paragraph and we saying can we question from there and then that problem is often referred to as the reading comprehension problem and so that's really what I'm going to focus on today comprehension is on the new problem I mean if you can trace it back into the early days intelligence in in Opie 70s a lot of nop work was trying to do reading comprehension I'm in one of the famous strands of that was just tranquilizer person I'm not a terribly nice man I don't think I actually but the Yale school of AI was a very well known Verifone comprehension what sort of the time was too early in anyway it's sort of died out nothing much came out of there invite just before the turn of the Millennium Lynette hirschmann revive this idea in says well maybe a good challenge would be the reading comprehension question school kids do and let's see if we could get and computers to do that that was fairly simple method mediocre what after that Chris Burgess who was the guy who was at Microsoft research ne14lp person at all using machine learning person but he got into his head that will really a big problem that should be being worked on his machine comprehension and he suggested that you thought of could codify like this suffocation that is lived on and look at more today night so I machine comprehensive passage of time question regarding that text that can be answered correctly by majority made of speakers that machine can provide the string which though 3 by the answers that question and does not contain information irrelevant to that question so proposing this to solve a challenge problem for artificial intelligence about kleftiko best corpus which was meant to be a simple reading comprehension they collected and stories free kids stories they got to the beach after a long trip she's from Charlotte she travel from Atlantis is now in Miami easy staff and then they're questions why did Alyssa go to Miami so you've got there it is coming from the passage that's the answers of the question test is a Corpus of story challenge existing the few people worked on a that never really went for a fight either for the next couple of years really change things was there in 2015 and then with more stuff in 2016 and play people got interest in this idea could we have build new question answering system like if you wanted to do that I'm something I can see test could only be a test said make progress would be to do what have been done in other domain build large training said of passengers questions answers in such a way that would be able to train your networks using the kind of supervised learning technique play that on so far in this class and neural network learning technique sorry but successful stuff the power locations of deep learning not only an NLP that also not the feels like this and so the first vs dataset was built by people and deep mind over seeing and Daily Mail news story next year and partner is a Stanford PhD student working with pussies laying in a couple of other squad day they said which was acting much better designed they said and proved to be said successful driving this for and then follow along from that other people start to produce and lots of other and question answering dataset don't have interesting advantages and disadvantages of there including MS Marco trivia Q&A race with lots of them and class I'm going to concentrate on squad because squad is actually the one that has been by far the most widely used well-constructed cleanday the said that so just proved a profitable one for people to work with that was reading comprehension also just quickly tell you of open-domain question answering so the difference here for the Field of open-domain question answering that we're saying ok Wikipedia or there's a web crawl I'm just going to ask a question can you answer it so is this bigger task of question answering any of that was something that again was thought about are we on for this kind of early Simmons who sort of explores how you can do answering questions that text your question answering and he has the idea that dependency parsing the question and dependency parsers sentences of the two nutri mate over dependency parsers how to get out the answer sunset figured work that people actually within attempting to do 35 years later a bit more modern I'm doing kupiec she was working as the Earth park at the time came up with this system called mirror stage in the 90s that started to be the first totally available encyclopaedia available series in the growlers encyclopaedia and so he said about trying to build a system that could answer questions over then cyclopedia using place of shallow and linguistic processing method regular expression having information retrieval search over that that's started to evoke more interest from other people and so in 1999 the US national Institute of play I'm instituted that a trick question answering track where the idea was there's a large collection of Newswire document asked to provide the question of them and lots of people start the build question answering system in some sense that was this competition which was where people at IBM I'm working on textual Question answering and then play blazer IBM reading things into the 60th formers of I'm let's build a jeopardy contestant rather than let's answer questions from the news and that then leads to the deeqa system and 2011 but I presume quite a few of you saw IDM ok so they were able to successfully build a question answering system that could compete it have to be and we one of these demonstrations of technological success you can quibble about the way it was set up they're kind of computer just had a speed advantage versus the human beings that had the buzz in to answer the question but you know Neville is fundamentally the text your question answering had to work system that was answering questions mainly based on textual passages and it had to be able to find the answers to those questions correctly work so then more recently again and really the first piece of work that did this with annual system extended PhD student get to later was there in the idea of welcome we reply complex question answering systems by using annual Reading let's prove to be very successful play not a little bit more the kind of systems that would built for trick question answering and they were very complex multi-part system if you then look at something like IDM deeqa system it was sort of like this x 10 because it both had very complex systems like no more together sort of six different components and every play a combination on top of them that so far this is sort of around a Server 2003 question answering system and so things that went through the question it passes the question with a parser kind of like the ones we sort out dependency parsers it did some sort of automatic normalisation rules to try and get them know better semantic form question type classifier which tried to work out what kind of somatic type is this question looking for is it looking for a person name or country name or temperature or something like that nation retrieval system out of the document collection and Wychwood fine what's the likely to contain the answers then it would have a method of making those paragraph choices the likely to have the answers somewhere run named entity recognition on those passages to find into these that were in them these systems depends strongly on the ring into these cos then it could look for an entity which corresponded to the question type and then once into these electric try and determine whether these into these did or didn't answer the question this is the system from LCC by I'm Sunday by j&n mode of an interesting stuff here where they had a kind of a loose theorem prover that would try and prove that form of a piece of toe even answered that what the question was so you know that was kind of cool stuff knowledge base Finchley Outwood common answer so you know something else I want to emphasize you know sometimes with what's this you get these days the impression you have is that absolutely nothing work before 2014 and when we got back to Deep learning that's not actually true that these kind of fact that these kind of question answering systems within a Sunday main actually really works rather well so I started saying the word factoid question answering and so let me explain that cos that's the secret so people at least an LP use the term fecteau question answering to mean the case answer is a named entity so what sort of something like you know what year was Elvis Presley born or name of Beyonce's husband or he know walk or something I don't know anything that's got anything that's so the answer is so some clear semantic type into the and that's your answer I mean so within the space of those kind of question significant part of the questions again with sir tried lots of is Joe who was the star of this movie or what year was somebody born right there's millions of those all the time these systems actually really did work quite well that they could get about 70% of those bad at all and they really sort of didn't really extend out to other kinds of stuff beyond that whatever virtue's they had they were extremely complex systems that people spent years together which had mini component out of hand built stuff what stuff was sort of milk white separately any dust of hope that it put together in composite in contrast that to what we can see later for new network star systems let me now say some more stuff understand the question answering data state or squad that I just mentioned a little bit ago this is the data for the default final project as well I'm so what squad has is sinsquad have a passage paragraph from Wikipedia then there is a question here at which team won Super Bowl 50 and the goal of the system is to come up with the answer to this question comprehension what is the answer of the question and said that's the answer to the question and so by construction for squad the answer to a question is always a subsequence of words from the passage which is normally end up being a photo as spam turn up words from the pet is so that's the only kind of questions you can have you can't have questions that accounting questions or yes no question subsequence birthday the first version about 100000 examples so they're a bunch of questions about tell us something like questions for passes and are 20000 different bits of Wikipedia use it list of must be a span form is often referred to as extractive question answering he is just one more example that can give you some more sense of some of the things for the day and illustrate a couple of an effector even this one I guess what's and completely obvious what your answer should be because maybe you could say the answer to just have been Broncos so you could have said it was Denver Broncos general even if you're answering with the span is going to be variation as to how long a spend you choose and then say this was done with on mechanical Turk building questions and getting answers is the day got answers from three different people so he is this question along with non-governmental and non-state schools what is another name for private schools and three human beings rusty answer based on this passage and one said independent and two said independent schools Swan all 3 people gave the same answer get two different answers so that they sample 3 answers and basically then you can be career with any of the answers and so that sort of least give you a bit of a bus nurse the variation in human answers into the topic of a valuation title squad version 1.1 because that means and 5-minutes time and conversion to which adds a bit more stuff into a football just get 1.14 free answers that were collected in South evaluation metric the two of evaluation metric is exact match going to return a span if one of these three you get one point and if the scan is band is not one of these three you get 0 for that question and then your accuracy is just the percentage play Simple metric NXT the one that was favoured as the primary metric was an F1 metre this F1 metric is your matching at the word level for the different answers system span in each gold answer has a bag of words add a precision which is and the percent systems on star the directionally in a span span the recall which is the percent of words in a gold span that are in the system and then you calculate the harmonic mean of those two numbers and harmonic mean such a very conservative average so it's close to the mean of those two numbers keep your score and what you then do is question you score is the maximum F1 over the three different answers lyrics add you then average those F1 scores across questions final F1 result table thing to say provide the civil code and for you that does that sort of seems that F1 is actually a more reliable and better measure because if you use exact match so there's a bit of robustness to come some 3 people dances very low the Sullivan bit of guessing as somebody get exactly the same span some human being God where is your sort of going to get a reasonable score in the F1 even if your boundaries are off I'll it all so the F1 M is more reliable and avoid various kinds of artificial how big are smaller than the human beings tend to choose in some circumstances being used as a primary metric the people on in the leaderboard detail both m punctuation articles are and that I'm so how did things work out add version 1.1 I'm a go at the end of 2016 and this is how the leaderboard luck and this is the bottom of the leaderboard at this point in time because that allows me to show you a couple of things the leaderboard so they test and how well human beings did at answering these questions because you know human beings are perfect and answering questions either and so the human performance the day measured and had an F1 score of 91.2 and he are come back to that again in a minute and so when they felt the day they said they built it will just take regression baseline which was sort of a conventional NLP system so they dependency pass the question and sentences of the answer they look for dependency link matches so a word at both ends with the dependency relation between and count and matches of those sort of pointing to a likely answer I'm so as sort of a fairly confidently snow in LPS system Plex says but installed in the same vein and said earlier question answering system I mentioned and it done if one of about 51 so not hope that great compared to human being shortly after that and people then started building new network systems to try and do better at this task on this day 3rd and so one of the and first people to do this quite successfully with these people from Singapore management University maybe not the first place you would have thought of but they were really so the first people who showed that yes you could build and into in train your network for this time rather better and so they got I'm F1 the second system without the 7th and then things started and 2 by the end of 2016 systems that really work and rather well on this task this time was the top of the leaderboard talk later about this bye death system from Allen Institute for artificial intelligence in the university Washington so was going to 77 as a single system that like and just about all machine learning people pretty soon notice that if you made an ensemble of identically structured systems you could push the number higher and so if you want some Volvos you could then get another sort of whatever it is sort of around the situation when in the 2017 24-in class with first use squad version 1 final Project you know actually the best students got almost to the top of this leaderboard so how t24 getting window 2017 metres into the equivalent of 4th place on this leaderboard how much 77 and a half that wasn't really rather call that's a couple of years ago and since then people started building bigger and bigger and more and more complex play the squad it's basically sold so the very best system getting F1 score play 90s and particular you can see that the have higher F1 Sandwell higher exact matches than what was measured for human being I like a lot of the claims of deep learning being better performing from human being than human beings there some estrus you can put after that I mean in particular to this day the said the way they Mrs human performer Lidl because they only actually collect games answers former humans was being scored vs only two other human so that means you only had two chances to match instead of 3 so there's actually a systematic and the scoring of the human performance assistance got very good at doing this step then to introduce on the squad vs version 2 people that defective squad version 1 all cases answers Heather find the answer in the paragraph and so that's I've turned into a kind of array can pass you just had this what seems the most likely answer I'll return there without really having any idea whether it was an answer the question or not squad version 2 for the Devon is hamster and half of the questions that don't have an answer in the past different distribution in the training data fireworks for scoring no answer kind of council's like one word as a service special token if it should be in no answer and you say no answer you get a score of 1 and the either exact match Leisure and if you don't do that you got a score of 0 the simplest way of approaching squad 2.0 with Vedas a well-run just always returning the best are you some kind of threshold known if the scores of other threshold out counters and answer you could do more sophisticated thing so another area that we've worked on quite a bit of stand for this natural language inference past that I'll talk about later in the course it's really about saying weather one piece what is a conclusion of another and Peace of pigs and so that sort of a way that you can try she gives you a justification and answer to what the question was destroying decide with a gone and thrown is a quite difficult problem in many cases coffin squad so Genghis Khan United the mongol and turkic tribes of the steps and became great Khan in 12 OC is expanded the Mongol empire cross Asia above and the question is when did Genghis Khan kill great Khan answer the daddy is you know answer because actually Genghis Khan was name great Khan and he didn't kill a great Khan it's just not a question with an answer but precisely what happens with systems is even though this system to get high scores in terms of Pi understand that well so they look at something that says when did Genghis Khan kill great Khan well this is something was looking for a date dates in this passage there's 12 06 12 34 1251 and well there's kill and kill looks a little bit similar to destroy they can see the word destroyed and that's probably kind of matches and then we talking about and there I can see Genghis and Con in this passage and so it's sort of put that together and says 1234 is the answer when that isn't the answer at all and I text you kind of pretty typical of the behaviour of these systems 10-day work grade on the other hand they don't understand that asking with a is XY answered in the passage is a way of Revealing the extent to which these models do or don't understand what's actually going on at the time they built squad Version 2.0 they took some of the existing squad version 1 systems and modified them in a very simple way I put in a threshold how good the final match was deemed to be and said well how well do you do on squad 2.0 in the kind of systems that we saw doing well before now didn't do that well so something like the by death system that we mentioned before was now scoring about 62 F1 so that was sort of usually lowering its performance and reflecting the limits of understanding let's see that this problem is the day the said authors may be thought because it turns out that I'm here we are now in February 2019 and if you look at the top of the leaderboard we're going again Close again to the point where the best systems are almost as good as human being so and the current top rate system they and see is getting 87.6 F1 which is less than two points behind by the human beings are 2 they also corrected the scoring of human being so it's more of a fear of evaluation this time so there's still a bit of a gap but you know she doing really well sing thing there is no on the one hand these systems are impressively good and you can go on the squad website and look at the app for the several of the good systems and you can see that there are just a tonne of things that they get right there absolutely not bad system do you have to be a good system to be getting 5 hours tried video on the other hand they still make quite Elementary natural language understanding error example of one of those Swan the yuan dynasty is considered by the successes of the Mongol empire in an imperial Chinese Dynasty it was the Connaught Road by the successes of monkey Akon after the division of the Mongol empire in official Chinese history is that you understood for the mandate of Heaven following the song Dynasty in preceding the Ming Dynasty what dynasty came before the yuan any easy question I'd hope for a human being everyone can answer that question yeah so it says in the official tyres history is the outside under the following the song Dynasty preceding the Dynasty that you know actually this sort of the leading what model says that was the Ming Dynasty that came before the Iran Dynasty elementor really wrong but reveals some of the same kind of it's not really understanding everything there's doing a sort of a matching problem still play the service being used for and God it's still has some major limitations and I just thought I'd mention what a few of those RC aware of some of the issues so one of them I've already mentioned right that you're in this space where all answers are a span from the past just limit the kind of questions you can ask and kind of difficult situations they can be so they can't be yes no questions counting questions or even any of the summer more difficult implicit questions think back to when you're in Middle School and in Reading comprehension I mean it wasn't typically the case being asked questions that were just stated explicitly in the text that you know Sue is visiting her mother in Miami and the question was who is Sue visiting in Miami that wasn't the kind of questions you are asked you normally ask questions like Sue job interview playing it's a really important job interview for her future at breakfast both sides of her piece of toast you asked the question is Sue buttering both sides of her piece of toy be able to answer she's distracted by her important job interview coming up later in the day which isn't something that you can answer by just picking out of sub span a second problem which is sort of action bigger problem is a squad with constructed for his so expensive and various other reasons was what's the Wikipedia with selected and then mechanical turtles were hired to say come up with some questions and that can be answered by the this passage 1.1 and then version 2 they were said told also come up with some questions that look like they're related to this passage but I'm actually answered in the passage but in all cases people coming up with the question passive that it means that your questions as strongly overlapping with the passage the words that are used and even the syntactic structures that are used for your questions turning to me structures of the passage naturally easy what happens in the real world is the human beings think up questions and type something into a search engine the date iPad in is completely something might be worded on a website so that they might be something like you know did the price of hard disk drop below $1 and MB hey just say something like the cost of hard disk has been dropping for many years in pause 2004 make a b berry or something like that there's a quite different Passion of the ideas and that kind of matching is much harder and that's one of the things that people have done all the data sets of try to do differently limitation is the diesel questions and answers a very much addressing the 4 sentence return the right thing that there's nothing for the more difficult involves multi sentence together styles of influencing the limits of crossing and stop there is pretty much limited to resolving coreference which is something or talk about later in the class that means that you see a he or she around 8 and you can work out who that refers to the living the discourse nevertheless despite all those disadvantages it's sort of proof the squad was you know and well targeted in terms of its level of different day well-structured clean day they said and it's just been sort of everybody's favourite for a question answering they the same it also seems fee for people working industry and want to build a question answering system I'm starting off by training and model and squad actually turns out to work pretty well it turns out I mean it's not everything you want to do and you definitely want to have relevant in domaine de that and the using that as well but you know it turns out that seems to actually quite useful starting point what I want to show you now was is a concrete simple neural and question answering system and this is the model that was built and I guess she was southern my predecessor and since seriously a proceeding head tac2 24-in system attentively decanter gets cold now I mean this is sort of essentially question answering system that works pretty well so it's not a bad thing to have in mind as a baseline it's not the current state-of-the-art by any means but you know if you're sort of wondering what's the simplest thing that I can build that basically works as a question answering system this is basically it how does this work Texas like this festival we have a question which team won Super Bowl 50 and what we going to want to do is build a representation of a question as a vector and the way we can do that is like the turn on the question we look up a word in bed news dimensional word embedding resend one and lstm for Shannon then kind of like every talked about we actually make it by sdm so we run as a lithium backwards through the question we grab state of both lstm and we simply can't tonight them together into a vector of dimension to the if I hidden dimension d and we say that is the representation of the question once we have their we then start looking at the passage the star of dealing with the passage we do the same thing look up a word vector for every word in the passage run a bidirectional lstm now being represented a bit more compactly across the passage then we have to do a little bit more work because we have to find the answer in the passage what we're going to do is use the question representation to sort of work out where the answer is using a tension different use of 8-inch and the Machine translation the kind of potential equations are still exactly the same but you can now got this sort of one question Victor that we're going to be trying to match again 2 so what we do is we and workout and attention score between each turn cm representation and the question answer the way that's being done is we using this bilinear attention and that heavy briefly discussed will see more of the day we've got the question Victor the Victor for a particular position in the passage to the toucan catenated lsdm him stay we have this intervening learn wmatrix so we work out that quantity and for each position and then we put that through a soft next which will give us probabilities over the different words in the passage give us attention weights that point we have a tension way front position message and we just to clear that that is where the answer starts intend to get the end of the answer we simply do exactly the same thing again apart from we trying a different wmatrix here and we have that and predict the in token little bit saddle here because you know really were asking it to sort of predictive starts in the ends of the answer and he might think but wait a minute strauli we need to look at the middle of the answer as well because maybe words are actually going to be in the middle of the answer but you know really implicitly telling the moral of when you're training the middle that's useful it mean by steers job to push it to the extremes of the span so that this simple the retention will be able to get a big score at the start of the span I think there's something funny that this equation and that equation exactly the same so how come one of them smitten now it's picking up the beginning the end and again you know we're not doing anything from post that we just saying is your job to learn you have to learn my tricks here and a different one over there so that one of them will pick up parts of the representation that indicates starts of and suspend the other one into the answer spends and so that will then again the neural network to sort of self-organized itself in such a way that there will be some parts of this in representation that will be good at learning starts and spares you know maybe they'll be carried backwards by the back with Dylan and some parts of it will be good at learning where spend in and then aw matrix will be able to pick out those parts of the representation yeah so this is the basic stand for the tenth of reader model and it's just no more complex than that and the interesting thing is you know that very simple model actually work well so this is going back in time again this is the February 2017 squad version 1 leaderboard and but at that time that what is the new network success is in your hyperparameters and optimising your model really well and sometimes you know it's been repeatedly proven in your network land that often you can get much better scores than you would think from very simple models if you up to my eyes and really well so there been multiple Cycles in sort of deep learning research where there was a paper that did something and then the next person says he is more more more complex model that works better and then someone else has a paper saying he isn't even more complex than that model that works better and then someone points out know if you go back to the first model and just really trainer type of friend as well you can beat both of those two models and that was effectively the case that was what was happening with the stand for the 10th of reasons that that you know that back in February 2017 if you just is tomorrow really well it could actually outperform early squad systems and in particular it could app perform and the by death the version of by death that was around and early 2017 and you know various of these other systems and other people that was actually at that time it was pretty close to the best system that anyone had bill pointed out to you and the numbers have gone up a lot since then so I'm not in claiming that this system is still as good as the best systems that you can build simple System that already works pretty well there push you wanted system to work better quite a bit of work on there and so here I just mentioned a few things for stand for the 10th of reader plus PASS as the what kind of things can you do to make the model better and so he is the sofa picture improved system and we'll go through some of the differences and what makes it better there's something I didn't have before that I should just mention right so all the premises of this model just trained into and where your training objective is simply and working out how accurately predicting the start position and how accurately your predicting me in position so that the attention gives your probability distribution over start positions and in positions so you're just being asked what probably the estimate are giving to the true start position the true enter zishan and the extent that though one you then got love standard terms of log probability so how is this model and more complex now and I've got a show before essentially in two main ways one is looking at the question we still run the boiler steam as before now what we going to do is it's a little bit true just to take the in states of the lstm can make them together it turns out that you can do better by making use of all statesman lstm and this is true from most half you want some kind of sentence representation from a sequence model it turns out you can generally Again by using all of that rather than just the in points of it interesting general thing to know again because you know this is actually variant of helvic how you can use the tension there the last two years of Newlyn LP app is people found a lot of clever ways to use attention and it's been tiring just at all the advances so what we want to do is we wanna have a tension over patience in this lstm processing the query first seems like we've got nothing to calculate attention with respect to do is we just invent something so we just sort of invent here is a vector and it's sometimes called a Sentinel or somewhere like that but you know we just been out I thought say here is a Victor we going to calculate we initialise it randomly and we're going to calculate attention with respect to that Victor and we're going to you kitchen scores and work out where to pay attention in this file stm and then we've just sort of train that Victor so it gets values and so then we end up with a weighted sum of the time steps that lstm that are then form the question representation change the pictures only show shallow by lsdm but you're not turns out I can do better if you have a deep forest dm&co use a 3-layer deep bioscem rather than single later the other changes in the passage representation car I could we get some little bit more he and but the things that you can do that make the numbers go up so firstly for the representation of words only using the glove representation that the input vectors are expanded so they sew and named entity recognising a part-of-speech tagger is run and the sort of small sets of values that the output of those is just one hot and coded and concatenated on to the word vectors representing facial person name and whether it's a noun or a verb word frequency proved to be a bit useful so there's a you're concatenating on a sort of representation of the word frequency as Amazon unigram probability and then this part is kind of key to getting some further advances which is well stop the we can do a better job standing of the matching between the question and the passage this feature seems like it's very simple but if you quite a lot of value so you're simply saying for each word and the question the passage you're just saying Does this word appear in the question and if so you're sitting a 1 b into the import and that's done it three different ways exact match match and limits that means something like drive and driving will indicator of he has the word the passage that in the question in theory the system should be able to work that out anyway but explicitly indicate gives quite a bit of value and then this last one doesn't of a softer version of their where it's using getting similarities to sort of calculator kind of similarity between questions and answers complex equation that you can look out but effectively embedding of words and the question answers each of those you running through a single hidden layer neural network he'll drop product in head and then putting all that for a softener sort of word similarity score and that helps as well just overall picture and this gives you so if you remember show us the sun classical LP record progression based Lynas round 51 son of a fairly simple model like the centre 10th of reader gives you an enormous boost in performance try that's giving you close to 30% and Performance gain and then you know from their people kept on pushing it up neural systems but you know this gives you kind of in some sense three quarters of the value over the traditional nop system and in the match more distance to come after and yeah in terms of production are huge but it sort of more like they're giving you the sort of I'm 12% after that why the base system such a ton better no systems did some error analysis of this and it turns out the most of their games is because they can just do better matching of words similarities of rephrasing for the semantically related but don't use the same words the extent of the question is Christopher Manning born and the sentences Christopher Manning was born in Australia you know traditional NLP system would get that right to that to the extent of being able to get it right depends on being able to match sort of looser semantic matches stand that sort of it's a birth have to be matching was born or something that's where the neural systems actually do work much much better at the end of the story on Question answering systems and I wanted to say just a little bit about more complex systems to give you some idea and what goes on after that I go further into that are there any questions now stand for the tender breda turn back the tension in general cancelling scene has just mapping Matrix anybody tried to convert that to work play have hello you all network example then just a minute so maybe I will save it to them but yet absolutely yeah people have done that can be a good thing to play with ok so so this is a picture of the by depth system for this one may I to use of and the boiler system is very well-known it's another and sort of classic version of question answering system that lots of people have used in building Somerford isn't completely different what we saw before but has various edition so there are word embeddings just like we had before there's a biased em running just like what we had before and that's being done for both the and the question but there are some different things to the happening as well so one of them is rather than just having word embeddings it also processes the questions and passages at the Character level and that's something that we going to talk about coming up ahead in the class work at doing character-level processing and recent you'll nop but I don't want to talk about that now the main technical innovation of the by death model.is floway name bi-directional attention flow and so there was a model of attention flow where you have attention flowing in both directions between the query and the passage and that was their main innovation and was quite useful name model but beyond that there's you know there's some more stuff to this model so after the attention floor layer is again multiple layers of bidirectional lstm running and then on top of that the output layer is more complex than the sort of simple attention version and I showed previously look at their in a bit more detail I'm so for the attention flow layer Vodafone patient here was in the Stanford attentive reader we used attention to me a representation of the question onto the words of the passage question of the whole knapping onto the words of the passage hair idea was well presumably you could do better by mapping in both directions at the word level so you should be sort of finding passage words that you and Jeff on the question words and question words that shouldn't map onto passage words if you do them both directions with the tension flowing and then run another round of Secrets models on top of that that you're just be able to do much better matching between the two of them do that the button so at the bottom layers they sort of run these two lsdm so they have representations in their lsdm for each word and and passage do I have to put a slight apology because I just stolen equations and said of letters do they use change sorry and answer these turn individual words and these are the passage individual words what do then wanting to do is to say for each passage one each question word I want to workout a similarity score that similarity score is there concatenate in vector so there's the lstm representation of the passage were the question word and then they throw a third saying where they do a hadamard product so an element wise product of the question word and the context word Munich Putsch is kind of hadamard product which eat because you kind of wood hope that annual net might just learn the disk relation between the passage and the question was useful to look at but you can find a lot of models that put in this kind of hadamard product because it's so very easy way of sort of having a model that knows that matching as a good idea play this is sort of looking for passage word hair in oh do the best doesn't look similar in various dimensions you can sort access very well from look at that have a mad product big vector and you then product with a learnt weight Matrix similarity score between each position in the question and the contour what you're gonna do is use that to define set go in both directions 4 context the question attention this was completely straightforward put these similarity scores through a soft neck Sophie high positions in the passage your sort of having a soft next which is giving your probability distribution over question word wake me up with a new representation of the ice position which is then the attention weighted and version detention weighted average of those question words play your sort of having a tension waited you of the question that Don to each position in the passage do something in the reverse Direction but the one in the reverse Direction is done southerly differently so you're against starting off with the the same similarity scores time the son of wanting to sort of really a sign which position turning the question is the one meaning the most so they're finding a Mac the defining features the most line one and so then for each the eyes most align question word and said then they're doing a soft mix over these in scores who is the being used a new representation of the passage play something over these attention weights build these things up and it still gives you a new representation where you have original representations do representations that you built from the spider extra attention flow and you look at these blood hadamard products of them and let them gives you kind of the output of the buy their player put of the by death layer is then what sort of being favours the input into the next sequence of lstm layers I'm so then that's the modelling way have another to buy esteem layers and so the way they do the unsuspend selection is a bit more complex as well I'm so that there then sort of taking it out for the modelling layer and putting it through as sort of a dense on your network layer and then soft mixing over there a distribution of the star and anyone here another stmk distribution yeah so that gives you some idea of a more complex model in some sense summary if you go further for than here is the source of most of the work in the last couple of years people have been producing progressively more complex architectures with lots of variants of attention and effectively that has been giving good games Gibson's Time is Running over and out showing you that one let me just mention this fusion net model which was done by people at Microsoft because it relates the answer the attention question right definitely use different versions of attention right so didn't some of the stuff that we've shown with Pinto in for size this bilinear attention we've got to Victor's mediated by M Stanford NLP we've like this and version of attention since it seems to vary directly learner similarity but other people have used the little neuronet so this is sort of a shallow new Ned to work out attention scores in a sudden no reason why I couldn't say maybe even better if I make that unit and another way up and some of them to be perfectly honest also been done by people included Google arguing taxi dead MLP version of attention better and so there's something to explore in that direction the people infusion that didn't hear that direction because they said look we want to use tons and tons of attention so he wanting attention computation that's pretty efficient and so it's bad news if you have to be evaluating a little dent neurone at every position every time that you do attention so this and bilinear form is fairly appealing that I needed some playing with that so rather than having a w m use the rank and complexity of your w mate bring it into the product of two lower rank matrices unv matric is rectangular matrices that I kind of skinny you can then have a stuff a lower rank factorization and that seems a good idea and then they thought well maybe really you want your attention distribution to be symmetric putting the middle here and we can have the you and the Bee photo speak be the same and just have a diagonal matrix in the middle and that might be useful way to think of her and that all makes sense from when you're out Returns but then they thought off nonlinearity is a really good in deep learning so why don't we sort of stick the left and right after a velo and the hotel which doesn't so much makes sense out of Returns but let's see what they ended up using us their attention forms what's the things you can play with when doing your final and the argument is still you know that doing attention this way is actually much much cheaper and so they can use a lot of attention and so they build this very complex tension model and which are not going to try and explain all of now but I will show you this picture and sour point of they make is that a one of the different models that people have explored in different years you let you know they're sort of doing different kinds of attention that you could be doing attention right stop with the original lstm you can run both side through some staff and do a tension you can do self attention and side your layer that the lot of different attentions the different models of explored and a century what they wanted to say is let's do all of those and let's make a deep and do it all 5 times and the numbers will go up and to some extent the answer is usually do and the model and ends up scoring and very well the one last thing I just wondered mentioned but not explain is I mean in the last year there's then been a further Revolution and how well people can do these task 4 develop algorithms contextual word representations that means that rather than a traditional word vector you have a representation of each word in a particular context so here's the in this particular context in the way people build those representations is using something like a language modelling past like I be talked about of saying putting probabilities of words and contour specific word representation what's the first 19 such model and then people from Google came up with which work even better so bird is really in some senses supercomplex attention architecture doing a language modelling like addictive we're going to talk about these later and not going to talk about them now but if you look at the Karen and squad 2.0 leaderboard and you will quickly sorry I put the wrong slide and that was the bottom of the leaderboard with the last minute if you go back to my slide which had the top of the leaderboard you will have no the top of the leaderboard every single one of the top system uses Burke so that's something that you may want to consider that that you may want to consider how you could use it as a sub module that you can add other stuff to as many of these systems do 