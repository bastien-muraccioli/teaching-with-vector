play everyone I propose we get started has begun an email from piazza just go through my posting really quickly Sam in case any questions arise I think it's straightforward but but just make sure everyone is clear on this was the time when they was tight you just have until Wednesday at 4:30 the testator are at this link download that whole directory into your words and data directory whatever you have set for word sim home in the on homework notebook it's probably just 8 words and they're so your system can find it 1 let's move the directory not just its contents and that's the one I have to fill with this reader code we are completing homework 10 book you should have already submitted add 2 find the salary of the bottom that begins with enter your Bake-Off assessment code into this cell it's called at the Bake Off sell pasting this blob of cold here it's just to new readers you can tell that these data sets are 27 dataset which I a relatedness dataset text 999 which I think is a similarity dataset so if your own model favourite one of the other kind of problem will it's evenly matched here because working a macro average the score from these two test datasets you have gathered the two readers into this to book called Bake Off 1 suppose that the custom model you developed the 304 part for that suppose you called that dataframe custom DF have to do is in the Bake Off sell at the at the very bottom so it prints out enter this code where custom DF is the model that you're evaluating you have to set the readers argument to Bake-Off so that you don't use the development data for this if you feel your model needs to be evaluated with a specific distance function you should specify that as well otherwise it's going to default to cosine which might be fine for you but maybe this is an important design choice for your model Runner Bake Off sell Porton right so we're on the Honor code here some more than once with different choices for custom DFS is against the rules that is dishonest the idea is that you have completed development completely fresh stader you are seeing how that system works go back and make an adjustment to custom DF and try again that is broken the rules really check this but that's the way the field works in progress kind of depends on people being responsible about this cold ones must see whether we can reproduce yet the results that you got in the cell right below that this is step 5 just enter the macro average score that you got so that we can if we run your system compared against and maybe contact you if there's a big discrepancy or something you just upload The Notebook system as in the homework one if it depends on external code or data you know things that won't be in or course environments then put it in a zip archive and upload that as well and then you die you have to do that Wednesday at 4:30 look at the systems and we hope to announce the results next Monday Wednesday I think it should be really rewarding to see what happened with your system you're officially be gone Bake Off one switchgears for this week is supervised sentiment analysis do a bunch of things with this unit so as you can tell from this overview here by the way the slides are posted so if you're free to download them and as before they include a bunch of code snippet use for free you in terms of taking the material and turning into code that you can use for your homework and for your Bake-Off submission and I'm Gonna Leave sometime at the end of the day today to introduce the next Bake-Off and the home guys feel like you can get started right away on this problem trying to do for this to lecture sentiment to you in a kind of general way because I think it can be a wonderful source of Prada play data and I'm going to argue for you that I think the sentiment challenges a deep and all you challenge some people regarding this kind of superficial serious about this we can see that this is a kind of microcosm for everything and nlu give me some general practical tips that are kind of outside of the codebase I think about how to design effective systems for sentimental actually for lots of problem can you get down to the nitty-gritty I'm going to introduce the Stanford sentiment treebank which which is kind of our core dataset for this unit I want to do with you is make sure you feel comfortable working with this code in for here assisted up I which is a module that is included is the role of the SN that pie in the previous unit it's got like a lot of functions that I'm going to ask you to use for the home also my claim is that it represents a lot of good practices learning experiments especially in situations where you might want to try lots of systems and lots of various subsystems which is you know par for the course in lots of types of machine learning I think we won't get through that are there today but I hope you at least get a 4 they will talk about methods a dive into different model choices you might actions you could write if you're dealing with an of linear classifier Ireland classifiers infrastructure networks which are more modern and maybe more successful approach now stop it because cinnamon is chance for us to kind of station around best practices for supervised NLP problems that is something I'm trying to do in parallel with you so questions you have about methods metrics models all that stuff should be on the table or kind of using sentiment as a chance to introduce Ireland play material this is a small typo that should be two you say this is the core code in Earth II notebooks the first one is an overview to the SST I'm gonna kind of giving a look at that today one is more traditional approaches to supervise sentiment or supervised learning in general and features because I think that's their characteristic oh that's also type I'm embarrassed that should be SST the third one is neural approaches so the rnns and the tree intermediate models that use glove type representations distributed representations as the input to traditional linear classifiers progression of ideas homework two and bake off to impaired in that notebook reading is this paper by so tread all that introduced the SST reduce the volume very powerful three structural networks for the problem suggested reading so if you want to just learn about Centre everything is great compendium of ideas for sentiment analysis 2015 that's a different that is a really nice primer for doing deep learning NLP it kind of unifiers in notation and in concert adults that you Encounter if you need a further review of kind of more basic supervised learning stuff check the website I provided a few links to different online tutorials and stuff it would be like one of your back classifiers in things which I'm kind of taking for granted in with the conceptual challenges I said that sentiment was a deep problem sometimes people think of it it's kind of superficial I want to claim different just as an exercise let's ask ourselves the question which of the following sentences Express cinema sentiment polarity positive or negative if any earthquake in California bad news seismologist tours safely out of the State negative sentiment this is a kind of education the sense that you might depending on how you freeze the problem to the people doing annotation they might say yes they might say no it's worth reflecting on 20-minutes negative you need to bring in a lot of other suns failed to complete the physical challenge positive is it a sentiment relevant statement or is it neutral the primary question and a secondary question is it positive or negative or that would probably depend on referred to and what your prospective was if we know that it's another team bad news negative sentiment maybe not maybe weeks until thing to be a point about clarity really to involve some kind of evaluative sentiment right is arguably not the sentiment necessarily of the person or the author of the speaker is it positive or negative it's like it's positive with respect to some other agent can see from these continuations they said it would be great and they were right as it fright by mobile normal definitions but they said it would be great and never wrong that seems more like negative there is that in this case for the first sentence we need to know not only that the adjective great was used used in the context of the Superb of saying and verbs of saying do not necessarily commit the author to their reporting other facts certain bias but it's only until we get to the second sense that we kind of know how to resolve the sentiment here the party factory cats are sipping their expensive imported wines positive effect -2 mi you know playing a role doing a lot of memory you would be the doors a lot of positive words in that sentence system is apton misapprehend the sentiment is positive when in fact the vibe that I get is pretty negative enlight perspective is creeping in you're terrible really depend on the context it sounds quite negative it sounds like an accusation a couple of friends kind of teasing each other about a joke or something endearing write and it would be hard to classify maybe the whole point of this little bit of negativity is to create a positive social Bond in which case calling a negative is really to miss the point list of yours to your pastor United that can be very affectionate in the right hand of God real slip it from a review of the movie 2001 and shall we have some 2001 fans in here is a classic movie that is also very long and let's face it at times very boring many consider the masterpiece bewildering boring slow-moving annoying that has a lot of negative suffering probably into it that the author of this sentence likes this movie probably invaded in a positive review not sure seems to be a seems like they're building up some kind of expectation that an event have to work right Harry Potter Katie prospective fact also just round this out by thinking about all the complicated ways that we as human beings can be related to products and people and events and so forth think about long-suffering fans who like the first album all the other ones were sellouts a whole lot of complexity to it that isn't just like I dislike this new album Bittersweet memories play embarrassing moments right it seems off to just say that these things your positive and negative there's just a whole lot of other dimensions here that would be is one dimension that's import other aspects to sentiment analysis if you think more generally about kind of affective Computing be careful how you define the problem Heroes problem kind of endlessly die retrospective on this is actually work that I do with morphsuit half one of the teaching team a while ago this actually from a network as a dataset transitioning from one mode to another they would depend a mood updates on a social network platform interesting things about this first of all the number of kind of moves that people are in is astoundingly high kind of ways in which they relate to each other and are differentiated is also fascinate you really quickly that standard things like positive negative or maybe like in phatic or attenuating those are just two of many dimensions about this sentence of transition diagram is that you can see that people are likely to transition in and around certain subpart of this emotional space and less likely to transfer across to certain other parts and it can give us a picture of the Contours of our emotional lives also shows you just tell high-dimensional this problem could be just positive negative sentiment but it's out there in ways of thinking about the problem that would embrace much more of this new ones about this because one thing you might do and actually built up for this on the first day it's think about applying your sentiment analysis system in the real world there would be any people in the business world who think they want like this this is my imagination about what it's like to be a business leader in q1 effect was 30 and in Q2 it's 35 an interesting read see the display down in your reviews or whatever your social media updates are trending negative this is it's very unlikely that that answers the question that they have this was estimated correctly what they really want to know is why nothing to think about is how you could taken nlu system that could do this basic thing and offer much more of that why question because after all is there is latent in this text that you're analysing Cassidy your systems capacity to just label them as positive and negative it's just like the finish line should be doing with that tech you could think about branching out and going deeper where to stay in nlu way where we could think seriously about answering those my questions about the spelling of general set-up so we're gonna have to be pretty narrow talking about the Senate Stanford sentiment treebank other ask sore areas within an oil you better adjacent to sentiment that I think I really interesting to address time for all of them but what I did hear is missed out a whole bunch that I could think of each one I listed a paper that I think will be a great starting point each one of these things has a huge literature associated with it so I had to be kind of subjective in selective but what I tried to do is pick papers that either or just about giving you a picture of the landscape of ideas better that have associated public data that you can get started on right away I really actually tried to favourite papers that have a data set associated with them I'm saying that this plans are the same as Centre very different even the ones that might superficially look like sending it like hate speech people tend to think about them together and I do think a lot of the methods that we discuss pretty nicely into these new domain trying to do the work of really thinking deeply about what these problems are like encouraging us to do for sentiment Adam exhausted West I just thought these are really exciting problems to work on comments about that shut up about surname.in analysis in general describe would like you to figure out why didn't you is expensive turn on the right track take this review that has 4 stars associated with it and see it down to the level of which aspects have been highlighted maybe some of them are negative there are some data sets that give you that kind of multi aspect Centre be a kind of latent variable that you want to try to induce with some uncertainty general practical tips I think these are interesting they don't necessarily apply to the SST because of its unique characteristics but this is good stuff to know about in general I claim tournament datasets that we won't get to look at here's a whole mess of them how to do actually is favour either data sets that are massive two Amazon one Amazon in one day is a poster key truly enormous for breakdowns by-product in by user and some other interesting metadata so that you could use them to do some sentiment analysis but also brought another kind of contextual predictors and you could certainly work at scale like if you wanted to build your own patience the way we did in the first unit as the foundation for your project these datasets would support that which I think is very exciting there is also like that large being with you has released tons of datasets about cinnamon and they range from just like 30 million reviews up from Amazon that he got somehow down to a kind of what you were how much is set the level of aspects of cameras how much for fine grain work master released a data set up here that gets a lot of use this might be a good kind of development data set for you it's pretty big message reviews that are on labelled for developing unsupervised representations and I think it's a pretty easy problem as they go this one is different sized involved with this work as well sentiment and social networks together I think it is a really exciting extension and if you've done work on kind of like social network graphs analogy I think about combining them with textual sentiment analysis that paper there West End dataset running for office on Wikipedia directions our pub evaluate until we have this network of people I meet as I have all the values of texts and we brought them together play the SST is one working other cat other greatest hits in mind data set to work with resentment please recall one space what is sentiment resources for you and actually these can be used for problems related to the SST tile item here I've been will use opinion Lexicon is just to word list positive negative you're going to work with it on homework land because it's built into nltk and it's really nice in the sense that classifying words in a pretty context independent way and it's pretty well at turned to the kind of data that you might see on the web that is a project of adding sentiment information to word during working word not it's a kind of nice counter UK has a sentiwordnet reader which actually I wrote Kuwait subjectively Lexicon is a can of classic and if you fall that went your favourite that group released a bunch of datasets related to sentiment general enquiries just a huge spreadsheet of words along the road different effective another social dimension measured along the columns at almost like a vector space that's been hand Curate issues in the field linguistic in Korean word count have to pay for look bad so if you don't want to work over whenever they're charging you could just use the Harvard enquiry the two others Hamilton it or will help them was a student in NLP group year and he released these datasets called social centre naturally called because that's not only some lexica but also some methods for developing context-sensitive sentiment Lexicon so that you could learn associated with music and so forth and there's lots of me once they're so I find that very exciting this is just a big human develops a human annotated it's kind of like an experiment huge lexicon different words along a few different affective dimensions and I've worked very successfully with this final one in the past too much time on it but I do have this life here that shows that for those classic lexico what kind of what the relationship so like say you could figure out whether or not it's worth bringing you can concentrate on just one by quantifying not only their overlap but also the number of places where they disagree on sentiment dive into this but it's there for you as a resource if you decide that you're going to bring these things into your sister you nuts and bolts things to the first one I wanted to start with it is just tokenization because return to default to default tokenizer is an area where you can see that that might be a mistake so here's my argument for that I started with this imaginary tweet can't wait for the June 9th project yay has an emoticon that's got and goggles and Lidl linked to our class site you might want to do as a preprocessing step is fixed up the HTML and today's weather in there so that it looks better Travis emoticon but this step here very common to encounter text like this and you might want to check to see whether it's worth fixing those up turn down text here what's a whitespace tokenizer in the sense that it has preserved the emoticon because it was written in a kind of co-operative way over here with white space around it identify the user name because it has a colon stuck to it Chinese talking to didn't do well on the day it didn't do on the URL because it left out period attached I'm not the best tokenizer this is the one that you will likely Encounter it's by far the most pervasive tokenizer just about any larger and an IP project has this this is a really meaningful choice because it comes from a different era that has really made a hash of this text so is the name in Spotify app Ryder Dr contractions for the negation is separate that might be good for you might not be it does it broke apart the hashtag hashtags are different on Twitter and certainly different for sentiment so you might want to preserve them as distinct tokens this stuff maybe that's ok and it also destroyed the emoticon list of punctuation and then also destroyed the URL so you think about using your texts see you in a fine on Twitter is probably pretty dangerous moving it's certainly not gonna allow you to find the emoticon found in the links that people are provided or do any aggregation by show me not the best and I kind of queues up a bunch of star from a sentiment aware tokenizer preserve emoticons kind of social media market what's the weather to preserve some of the underlying market that's meaningful for example that people have wrapped some words in the strong tag for example to indicate that they were involved something with people hiding crosswords because they certainly socially meaningful preserving capitalization worth meaning for right it's one thing to write grey do it in our cabs Moira dancing would be like regularising the lengthening so that why and then just hold down the achy and then why to indicate real emotional involvement where the longer they have down the key the more involved they are what things are just going to be very smart tokens and if you could normalise them to like then you might get a meaning for signal from them think even further down the line about capturing some multi-word expressions that how sentiment like out of this world parts centre there is certainly going to carry a lot of information UK also has this tokenizer here which again I wrote I really sort the court pretty well on these criteria here working with social media data that certainly argue for this one over the treebank one for example you might hope that the cinema where one would do it with preserve the username and the hashtag the date which can be nice Eleni emoticon and it regularized s little bits and report on some experiments what I've done please experiments is just take a homophone open table reviews classify simple like softmax classifier to them with different amounts of training data and always testing on 6000 reviews but here goes from 250 trading tax to 6000 grey line is whitespace tokenization the green line is 3 by just sent him anywhere shows that you get a consistent Prague sentimental where tokenizer especially large where you have relatively little training day because those other situations where you want a kind of impose as much of your own bias on the data as you can assuming it's a goodbye it's because your system doesn't have much to work by the time you get to 6000 reviews these differences have been minimised what's the roundabout what I did hear to test robustness is training on opentable reviews again went from 250 to 6000 but I tested out of domain so I tested on IMDb reviews the same kind of picture the the performance is more chaotic because of the of domain testing pretty consistently it's worthwhile to do the Cinnamon where token basically strictly dominates the other comments about the tokenization stuff you all the time about whether they should be standing their data is heuristically collapsing words together by turning off their ends typically here is helping you morphological variants I think that's what people are always imagining that it will take and smash them together into let's party in your data and therefore more clarity time in algorithms for doing this all in nltk the porter stemmer summer and wordnet limit for you here is that Porter in Lancaster destroy too many sentiment distinctions for you the one who's there add a place outside of Centre turn on the other hand it doesn't have these problems because it's much more precise I think it's not worthwhile when you see exactly what it's doing what I've done here is you know the Harvard enquiry Lexicon dimension before it has categories for positive and negative it writes them without cheese for some reason here is just give you a sample of words according to the Hartford enquiry Centre the same token if you run the porter stemmer so defensive become defence travertine sand extravagant become extravagant fiction and affectation but become after what's happening here real sentiment distinctions are being destroyed by the steamer intolerable Cala Temperance and temper become both become temper for the Lancaster summer I actually think this is even worse so again positive and negative and when you Lancaster stand where in filth become the same token call aunt Alice fluent for some reason but become TR you doing real violence to your data play Frankie by running EastEnders but for sentiment you're obviously going to be losing a lot of important information text Emma is different so what the word next Emma is doing is you need to give it a string in a part of speech will use it very high precision Lexicon to collapse them down into what you might think of is a base form so it does do the dream thing for sentiment which is that like explains exclaimed and explaining all become the same word pronounce forms the flipside it does collapse all compared variance of adjective standard to their base form very high precision if it's not unlocked s it's not going to do anything to your word I think this is fine to do costly to do it at scale probably not working in general for collapsing these if you have sufficient data and then presentiment you might regret actually having combined together in terms of send I did the same kind of experiment so this is open table in domain testing 86000 reviews tokenizer beats both Porter and Lancaster basically with the idea there is that if you take the Cinnamon tokenizer as your kind of default baseline show me hurting you out of domain testing oh did I not include that it's the same kind of picture when you do abdomen test stemming tagging you prefer to use approaches for preprocessing vs character play question one thing are saying that you're seeing marriage later in the course move two festival sequence model that's all these things in the context of what came before and maybe after them so analysing down to the Character level has made these decisions in some cases less import a lot of these newer models can recover from a bad tokenization scheme because of all the contextual modelling that they're doing say this is a great development because whatever you think about my cinnamon where tokenizer even it is probably not getting a perfect read on exactly what the unit should be dil SE play worth your while to start all these systems in a reasonably good place even if these differences are becoming men standing orders work on this payment spelling related to Ms because it's sentimental very understandable and it's too late going to do what they do when you look at them they're just basically huge regular expression methods care about my spelling because they don't actually even care about what I don't do that much you are methods misspelling this kind of related distributed representations and you have a common misspelling it's likely to have a very similar representation to the one in which case those systems one of the selling points is that they gracefully recover from that stuff and therefore reduce the need to like a run a spell checker as a proof other side of this is anything you can see the in this in his plaits like this makes it especially clear I think do you have the last choices I can the matter because the more your system is going to be able to uncover a recover from this bad starting point it's when your data are sparse is really tagging could help with sentiment that's my first pet here because there are number of cases in the English Lexicon where two words with different sentiment only by their part of speech so what is an adjective the resting I guess that's positive but the rest as a verb according to the harbor enquiry is negative find better better clear case so it's a fine idea that a positive define that's the noun version that's typically negative it might help you to create distinctions speech tagging your data and essentially considering every unigram to be a its word form and it's part of speech last year that's some evidence for directions transcend part-of-speech here I've got a bunch of kisses from sentiwordnet where one in the same word part of speech mean could be that your mean is in none not nice to people pork pie is a good apple pie something good smart Dad and that means it hurts serious mean different things depending on the context experienced a lot in my life serious problem might be a good one or a bad one depending on your perspective so answer here except to say that even adding as much pre-processing as as you can think of is not gonna fully December Q8 the word the colour of ambiguous things here that is part of it is part of speech tagging worth it is a preprocessing step for cinnamon it's not so clear to me that so kind of empirical play Powerful liquorice sticks saying an intuition that will return to in the context of the SST and this is just simple negation marker the linguistic thing is there is ways of expressing negation obviously kind of flip into a lovely what the sentiment is so I didn't enjoy it it's probably negative where as I enjoyed it is positive enjoy it negative probably negative present location here yet to enjoy it that's I don't enjoy it think I will enjoy it that's a case where give sentiment and the negation word is really far from the associated thing that you want a tree Disney dating which is sentiment analysis literature propose the simple heuristic what long if you encounter in word that is negative according to some Lexicon that you've devel to not no one in Southport marking all the tokens after that negative word with underscore neg maybe you hit like a karma or sat on a period of some kind of punctuation mark that tells you he rustically again that you've reached the end of the scope of medication me when you do that appending underscore name building a separate token this word when it's under the edition is a different word than when it's in a positive can't your system distinguish enjoy neg from Enjoy positive a big boost prison processing you just giving your statistical model a chance to learn that negationism Port what happens no one enjoys it anything after no with Meg I will enjoy it but I might if you've got your set to stop at a comma then it will stop that now I'm working at the end of what's into we close down be there and it's probably good bit of evidence that this can really help so comparison white space free bag playing cinnamon where tokenizer and red is the Sinnerman where tokenizer with neg Martin consistent boost all across the training data from 250 tax to 6000 yeah even out of domain this is a useful biased having post it's really giving your system a chance to see that negation is powerful for Centre the simple softmax classifier noted it down here the pretty good standard when you're model it's just a bag of words classifier it's just that when I've done the dog marking this bag of words has been kind of annotated in this club away skip by way of general staff turn a dive deep understand Fort Elementary bank this is perfect timing because this will give us a chance to talk about the code itself under st.com guys can leave here to the homework if you want play Bake Off 60 project the associated papers sorted out 2013 I was involved with this project as it was tremendously exciting at the time for me was the largest crowd sourcing after that I had ever been involved with I remember feeling something nervous that would even work because we have people and 18 hundreds of thousands of phrases what kind of small now Stanford has produced edited data sets that are vastly larger than this but still impressive effort for coding data release bus to Richard socher I think you can still if you if you visit that Arthur system it does wonderful visualizations you can even offer to give it new examples that it will they learn from of course you can use the code in lots of ways alpha being open about your data in your methods in your results levicorpus has about 11000 sentences in no censor derived from a classic sentiment dataset that was released by Peggy Lee who are we really Pioneers in doing sentiment analysis and I actually this paper Nicole won the test of time award I think the argument there is that they really did after the direction of thinking seriously about sentiment in its own right but also as a great testbed for Nou model rotten Tomatoes sentences naturalistically by their offers because it's review dataset SST Project 8 is crowdsourced labelling not only their sentences but every single phrase in all of the trees that are contained in those sentence 5-way label thing actually reviewers were given a slider bar also extracted and that was Justified on the grounds that by and large people slider bar that were kind of consistent with the labels that have been provided what is a tree is it look like this here I know you was in lightning he's a real predictions from the model all new test cases I was very impressed at how well this did are you on but it's still got this right labels for all of this sub neutral I know you was neutral in lightning as positive as a result of in lightning being positive that projects up the tree essentially that I use to motivate right so they said it would be great cor is that be great is positive thanks kind of art contributing sentiment and the Sinnerman single goes pretty strongly up until the top here but then it's the minute somehow and the overall sense is neutral prediction that I wanted from the sentence because I feel like phone does not tell us about the authors bias it just report somebody else's prospective you know who knows what was happening up here because this to emerge but it did really quote they said it would be great they were wrong that was negative that was negative because it and it must know to project things from the right more strongly and so that they were wrong over here with a 1 projected up to the top no this remains kind of ambiguous Lee neutral or positive white nail it would they said it would be great they were right must not have a strong enough sentiment signal on its own Mr did figure out that is kind of just neutral positive positivity kind of weakly expressed on both sides size and press by the system but I introduce examples more to show you power of this particular data resources kind of unprecedented that you have this many labels and this kind of degree of supervision for the individual example will be bad my intuition is a human they said it would be bad and they were wrong should be passed very interesting stress test for the system to see whether got that right needs to know not only how to bouncy cinnamon signals but kind of how they come together different problems that you can define a problem that's just using basically the row labels they go from very negative negative neutral or positive in very down for training dead there's a test set which I return to and I've not showing the statistics because I'm kind of trying to keep it out of our view for now able to dive fine but there are two things you might keep in mind about this version of the Prague intuitively if you don't think about sentiment strength capillarity then 4 of course is greater than 3 what is greater than 1 much more natural to think about this is a kind of two scales with neutral with respect to the other two maybe that doesn't bother you too much what should bother you is that if you fit a standard class a fire label dataset which has a writing on its label Pacifier will be conservative with respect to how well you actually doing because it will regard a mistake between 0 and 1 as just as severe as a mistake between 0 and 4 you might think about how you can get personal credit for being close to the true answer what's the electric do that even in the classification context like involving word no regression or no classification probably not doing that and so it's just worth keeping in mind for this problem it's a little bit strange the problem that makes more sense to me what is the Stern everyone which were going to make a lot of yourself group together 0 in one is negative and 3 and 4 as positive the middle what's on sentiment distinctions but at least with regard to the with the labels were given it seems quite justified nice because you keep all of the data that you have available version of the problem that is disgusting that in the paper alongside the 5-way one and this is a binary problem we simply dropped out the Neutral category together 0 and 1 and 3 and 4 respectable the only shame here is it first of all in the world there's a lot of neutral sentiment not everything is sentiment we had to drop out a lot of Our Data these statistics here are just for the root level labels ignore the labels that are done inside the trees all notes ask where you actually tried to predict all of the labels and all the same constituents you get many more training it says of course because some of these trees are really big define the same three problems in this way all different kinds of models we're mostly not gonna look at this problem tell me about Dad is just this is one of the more interesting aspects of the SST it has all the supervision due for projects in things to think about how you might model the phone as of this date 131 I mean that's kind of I mean the SST doesn't have that kind of multiway label mystic intuition understanding of the psychology of affection of affective states is that they have many dimensions I'm one of those Lexicon that was released by Victor kuperman the last one that I was stood which has a few different dimensions that they take us the true substrate for emotional expression we can do it evolving collapsed into a single scale down play Creed Lakeland dairies weather going forward B+ emphatic B minor synthetic as a binary problem and then you also have clarity which is positive negative or neutral no I take it back that's a great idea it's worth thinking about play as a way of kind model is learning it's interesting to impose that distinct let's dive into the actual code because I can kill you up to start working productively PewDiePie used to my interfaces a little bit claim is that having done that you'll be able to work really productive how to get I've created a little framework for you that should make you quite nimble in terms of running experiments is readers train reader which one of them has this argument class funk three choices if you leave that argument off it will give you the five way problem recette classroom to ternary past problem it will be positive neutral or negative binary class run could give you just a binary problem is pre-packaged ways for different getting different views on the data explore all these different problems and for the homework and the Bake Off for going to do the ternary one it makes a lot of sense just kind of setup you could pays the sin in follow along if you wanted SST is the library are you there free when your data distribution and Anisa the reader the thing to mention is you can think of is you for repairs the trees are like in this in a second and the scores of the strings as you would expect given the way the labels work slide here on these three objects so they are nltk tree objects I can see I created 1 from a string frustration of how to do that ok set up properly we'll do this nice thing of displaying them it's pretty intuitive he was amazing I'm here for subterranean three dots on trees that's a mess through all the cemeteries for you just a really useful method to know about cure this is basic tree components 03 that label will give you the root level label for that tree 0 and 31 will give you the left and right children respectively assuming they exist over here the left tree the left I'll note is that subtree rooted at to and nlu liver price is amazing so that's recursive so 310 with take you down to 2 is bunch of other stuff you can do with these trees but in my experience writing feature functions these are the important components that I need it if you think about writing a function that in a crawl around in nuts and bolts does framework in 3 Steps year is this notion of a feature function very simple example here this is a kind of bag of words feature function is that your right are the feature function should up to take a tree as input syncback to the readers readers are using threescore pairs it's going to operate on the left value of those Paris the first one return a dictionary how using a dictionary or counts for bullying the real value as well so like integers counts integers floats in bullying turn of the contract right you can write any future function that will be any function of individual trees as long as it returns a dictionary and here is the tree that leaves to get all the I'm so not really making use of the tree structure here just turns that list into a dictionary where the elements have been County play to do a bag of word I created that's Aintree nlu was amazing down here I have that tree yields this dictionary anything that you want to make a lot of yourself and I'm assuming that part of your big love your home interesting feature functions and they all they can you can do it every you want inside here as long as it's three to dictionary is about 10 night might look a little redundant for a bear with me generate functions cos they're in XY Paris where x is your feature Matrix where is your vector of labels what function should do is fit a model on that data so the supervise training data turn the fitted model 5 dinars progression from sidekick the innocent feature like the bias feature silver and multi class equals order just went issue it's morning's it seems to be inhabited now issuing warnings about does something tomorrow crucially you have to remember they fit the model in here and then it gets Returned this might look like just a tedious way of calling the fit method on a model but as you'll see rappers around these things you can do a lot of other stuff as part of this process without changing your interface and four more sophisticated models you might want to do a bunch of sophisticated things before you fit or as part of fitting the springs at altogether that experiment Swiss army knife experiment I've given it here with all of its default value so that you can see at a quick glance all the different things that you can do the point is you just point it to us St feature function little rapper all that's required SST data experiment those three things trainer model an assessment on data that separate from its training data a report like this not only will give you a bunch of information about your experiment included here data classification report very little code in order to test your feature function and or your model wrapper do you want to try out different conditions like you can go and here you could specify that your access reader was SST that everyday development change the training size if you haven't specified the assess reader if it's doing a random split is the class function you can you can change the metre turn off printing and I'll return to this vectorise thing a bit later what kind of if you want to do more nuanced experiments the things to keep in mind is that you can play test your future function and your mother rap I want to say is it you'll see this to out for this entire unit and in fact from many units in this classification reports we are going to care mainly about the macro average F1 score the reason for that is class and balances of course rather Proms the class and answers can be really large behind Makro averaging is that We Care equally about all those classes it's Justified in nlu in sometimes the smallest classes are the ones we care about the most micro averaging would favour the really large classes as Would accuracy and weighted average how is a kind of good clean picture at how you're performing across all the different classes despite their size reminders you look at these reports you're kind of 1A hill climb on that value the experiment unigram softmax experiment contains a lot of information about your experiment this is part of best practices like when you running a valuation much information as you possibly can about what you did time in my life that I've decided to leave something out every bread it because I wanted it later retrain the whole system or something tried to do is packaged together that you need to study your models performance sitar new data is that western here you've got the model the feature function trained on in the assessment data and that's relevant if you did a random the only way that you can recover exactly what data you were using the metric and the score each one of these training assess data sets has the future Matrix the labels the vectoriser which are return to and the rock samples before featuring station I think it's really important for kind of error analysis because if you try to do analysis on X and Y you just stare at this high-dimensional feature representations it's hard to know what's going I'm like a machine learning model would prefer the real Roxanne for you as play Bring it all together this is on one slide here a complete experiment bag of words on a logistic regression model 60 home Returns the dictionary turning the leaves simple fit marathon in an experiment SST that experiment I didn't show it but it would print that report experiments without a lot of copy and paste I don't like just repeated cells that you're basically the same thing I'm hoping that in a no but you could use this to kind of reconstruct or you not to conduct a series of experiments and study them having a huge one more thing and then time for a few more I want to give you a glimpse about what happening under the hood because again if you move outside of this framework this is a nice thing to know in terms of best practice is so could mining with your feature function who is the psychic learn feature extraction dictvectorizer through why I'm doing that because I think this is a really convenient interface for doing all kinds of problem illustration so imagine my train features up here are two dictionaries abbc and hm the accounts associated with them if you write a feature function nothing 832 a dictionary Charlie is doing it applying that feature function examples and creating exactly all this like this is under the hood what a machine learning model needs at least of the psychic ones what they need is and matrix they don't operate on dictionaries they operate on matrices that look just like the vector space model you were building before right strictly numerical date what are the meaning for units shiza Maps these list of dictionaries into such matrices call the vectoriser here Transformers the idioms in scikit on NatWest of dictionary mazamet play the dataframe just so you can see what it happened but under the hood but it's really doing is offering on an ENT giving you an NP array pandas dataframe is nice because you can see there dictionary columns example 0 and 1 we have the counts of those features because for example of failure mode for me before cycling came along go by hand from dictionaries to NP array confused to have a bath columns align with my intruder features and then everything would get screwed up no I just trust the dick vectoriser to do that so as a human and very happy to have these dictionary interface but my machine learning models wanted where is the bridge third thing that's really important about these diktat arises the third problem that's all protest examples the first one is and it's a can of 2 you with the account d that I never signed training call my vectoriser appear and I just said transform best features next it's perfectly aligned with the original space a b c and d has been dropped out part of my future representations for my training data my model will be unable to consume the morning transformer have disgracefully solved the problem that they would have impose it's doing the thing of aligning the columns and self-worth just made a new car it would have four and I would have lost this correspondence with my original Prague that's a great point of contact important because this is the way that you can swiftly go from a train model and a vectoriser hill process new data in the way that you expect for your model and get the desired results and again this was an area where my cold would contain mistakes before and now it just doesn't because of the Stick factorise free download under the hi this is what happened is what's happening as we take your feature functions and turn them into something that a machine learning model can cancer immaterial the next phase of this is I'm going to show you some hyperparameter exploration fire comparison to say that for next time because this is been a bunch of material and I think in reviewing this section you're now pretty well said up to start doing the homework if you want review that quickly and then will wrap up naproxen to the first homework in Bake Off focus on the centre at Stamford cemetery the snow book is and basslines mainly there I'm trying to document the interfaces for you about next class but I've shown you had a fit of softmax baseline classifier into some erinalice that might help you bootstrap to a better system questions on there just three the first to involve a bit more programming than the first one so they're there another worth a bit more your pattern of you develop your original system turn off system will be one that you enter into the second take off off itself we're going to focus on the ternary task as I said and basically you're just going to try to do as well as you possibly can on that task I don't have to impose very many rules in a before download external Factors in southworth but in this case I feel like we can just say tinkers best in terms of developing a good solution for this problem download pictures from the web that's fine download other people's code that's also good the 10 that I have add needs to be an original system that you enter so download someone's code and retraining entry meaning for addition or modification to that code except for the fact of course that again here now we are really on the Honor system for the first one I could withhold the testator the testator or just the test distribution in your data folder or red me on the Honor system just like we would be a for a publisher development on the dead set is the test for that very final phase when you actually submit your sister Airsoft next baseline is the one that I just showed you the experiment made everyday for develop set up your beautiful things show you there's a few little tweaks that you need to make to do in this framework but it's really easy so I shall that to you next time tools for air analysis a hummer prams the first one is like riding original when is a kind of transition into the world of deep learning good one is you original it's a bit early but I proposed that we stop here next time I'm going to finish this lecture and then I hope to leave time love your own hacking so that I'm sure that you leave your on Wednesday feeling like you can complete the homework the time window here is tighter so that's really important 