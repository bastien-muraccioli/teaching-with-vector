can I dive into the material in building a foundation for thinking about natural language understanding module no I want to do just a few logistical things because well frankly because they're not so intuitive so let me start with the least into it one of all play said last time we're going to be using canvas to do all the submission of work which basically means that you're going to use it to upload notebook that part is straightforward because they were going to take those notebooks can you eat them separately outside of the system so you don't have to deal with very much data entry do you have to confront if you want to work in group joining a group and that's the part on canvas that I find quite strange so let me just walk you through what life is like from my perspective in understanding canvas Amazon instructor get a feel for what you are see when I've choose the studio play the stunning view and this is what I hope happens for you if you want to say former group 4 assignment 1 and Bake-Off 1 people it's called people I guess groups are made of people can choose the groups tab it's going to do is load a tonne of hated groups listen to the part of offer me that you guys can't just create your own groups under the rubric of assignment one but rather that I have to create hundreds of empty groups for you and then you can join them see the people have done it so I'm reassured like for example this is a group that has currently one person it in this one has to can't verify that this works because it says group is not available for me play Panic Google around and I discovered that I think that's because test student who can only aspire to be a real student student can actually join a group show that a bunch of people have and so my assumption is like if you wanted to start your own group who is scroll this endless list found one that had the right name like a sign one big off wine resign three big off 3 in the future so you can all join and then you'll find lights out for every recognising that it's kind of strange just let us know if you see any unusual behaviour 4th done that reassured that join date went to the assignments tab trust me if I wanted to submit assignment one and it would do this morning like a just so you know the work you're about to submit is being submitted for your full group time to load a little bit nervous that lot of your downloading the data distribution file which case the entire internet open a mini case that's what would happen hope it works out and the other thing I don't wanna dimension is the reason that We Created that we want you to get different groups for the different assignments and then the final project is just that I couldn't tell from the system whether or not if you from the group of the start you could change it without having things go crazy and so I thought scenario people just reconstitute the same group for each assignment and then the final what's ability in it just means that it's some point you have to do a whole lot of scrolling give up on that but it's going ok created all of it so here's the main page for the core Google ncs2 24u Stanford nice addition we have a calendar now that shows all the office hours that's a more intuitive interface and it also is a reminder here you can see that we have a special session on Friday 3:15 refresher or an intro to python and Jupiter notes Christian Ashton to over teaching team are doing delivery of posting Lucy's stupider notebook tutorial here interact is it with them on Friday and then going forward has lots of great tips about how using up to see everyone's office hours including office hours on Saturday working over the weekend he's available in the in the one Auditorium based update so I didn't scroll through this last time you can kind of see our units were gonna start building a foundation for any of you today and then we can have branched out and explore some tasks largely in the service of giving you a sense for what different models you might use for your own Project building up some best practices changes I love you are probably thinking about going off in the industry and maybe doing nlu in industry schedule the day on May 20 to where I was going to have like a panel of people come in for people who doing Nou in industry interview then I get questions from you all about what their experiences are like to give you a sense for what's happening out there in the world record this please it's very hard to schedule people everyone is very busy and I think we're actually going to do is have come on April 24th Marta recasens who is the post ocular in beautiful work on kodi inform but also success One Engineering side great work and she's been at Google for a long time I'm kind of in and out of academia so I think she has a really interesting story April 24-in joined by Joe McGann Dr Who Was a master student industry doing things are you for healthcare I worked out quite closely with you is acid an interesting story to tell about why he decided to stick in industry as opposed to pursuing a PhD like about James profiles that he's been very helpful to me in producing lots of notebooks as you can see here the kind of show you how some of these interfaces work and so for example if you look at the tensorflow code that I distributed for the square have like shamelessly ripped off all of his best practices and tips and tricks for doing spell with these new estimated classes so I feeling better today enable 24 and then I think we will have a similar panel discussion in late May on the twenty second successfully Guildford bill into being one of those panel speakers bill has an incredibly interesting story that is a philosopher and it August stuff in finance and then do the PhD play The Essential II every will you can play Doing Things related to Nou and and maybe somebody else where about those things in the future and I think I'll be so silly questions from you all that we could a few other assignments announcements turn the set-up with the 1st materialista notebook here for doing play cure for posting a really detailed about how to get setup continue to do that kind of faq for the assignments other important aspects of the course O2 Brown lots of times in my life bright said this tune is the 12:00 asking the same question and then I can't find the 11 other posted that exactly that took it on PS and I feel sympathy for people to make French toast gather together all that information so that it's available to you I want to be the make it update the setup instructions for people who might have access to GPUs on their laptops like if you have a Linux play the primary advice is if you want help getting setup so that you could take advantage of your local GP ignacio office hours play help he said it and everybody going to be a working together about that I am working very hard shamelessly asking as many people as I can about getting you cloud credits for doing else to come on that play date for announcement Windsor comets before I diving detailed but the gist of it is R9 each one of them involves setting up some baseline systems for a test your own original sister to that system into the Bake Off you get an extra point for just enter extra credit if you're the top performing system in the back so it's a kind of little project the assignment plus the Bake Off is a kind of Willow Project examplify best practices as we do 4 chance of having a little cast of Radio 4 on YouTube aslake what I wanted to say what's the really important details I'm going to what about better comparison and reweighting today at the fast version screencast this like I've tried to distil it down and do some example calculation breakfast at the way I think about this unit here right now is we're on a Pro 3 reading word representation working with the slides today and next time and probably a little bit next week a switch that you could explore these notebook reinforced the material but the nice thing about them is they mix everything with co pensarn all the way through discount with Alexa and then you could reinforced out with the screen we have a lot of coverage for this first unit because I think that the backgrounds for you all are very different I think some of you were in like your phone set downlights basically new to the field way for us to kind of get everybody salad officially none of this is required just do what you can wear making a lot of materials available for you to build up that sound slides for the for today are posted here you should carry us through always next week as I said the reason you might want to download them is that I am going to encourage you at various points a coding on your own so if you do have the data distribution and you do have all the codes is Utah like open a terminal what if you were Eastern code and then maybe play around with the code because take me to New questions or give you a better feel for when I'm talking do a lot of that as part problem one generally thinking about let's begin with this contact so this is the unit on distributed word representation big slide show navigate it by clicking around up here if you have it locally and it's pretty intuitive this is our plot were going to talk about matrix designs comparison reweighting modelling and then move on to dimensionality reduction with cheers going to encompass 12 in words and other things people doing in that space unit design retrofitting where you might go behind just a curry more structured information into these represent that makes it easier to navigate what is a very large slideshow Canada plan here you can see it reflected in that plat on the big idea that you need to get used to if you haven't already ideas like more and sadolin interesting so you can always just continue to meditate on how and why it works play idea gather together into a matrix like this whole bunch of co-occurrence information about words from large collections of text resulting representation going to think of the most roads in these matrices representations you contain lots of important information about them with sticks some of you might already be familiar with that idea it sounds really strange I can still remember it sounding very strange to me and I'm gonna try to make it seem less strange but yeah this is a co-current matrix this is like our starting point for the whole lecture word by word matrix in the sense that it's just counting the cell values here by the number of times that does words occur with each other my pitch to you is that latent in there's a whole bunch of really interesting semantic information one other way to plant this idea little fart experiment for you place a Hopeless learning I have a little labelled dataset of words 04 that class value means a negative word positive sensible AutoTrader generalize that information to this dataset over here I haven't told you what the words are this is completely hopeless no matter what model you have there's just no way that you're going to be able to make predict animus new case out with this much more promising learning scenario so over on the left I have that same label dataset I've done is represent each word some numbers that represent the association of that word with two other words excellent and terrible flat for the courses I might have started with the colour current accounts and they done a bunch of massaging and stuff and gotten down to more interesting values done that it doesn't really matter what your learning model is you can just into it that like hey 0 class how terrible value all these values here negative excellent value and then when I switch to the positive ones it's the reverse right they tend to be strong positive negative Association association with Tara do that and you can easily imagine a machine learning model would see this more less instantly view this generalization problem assault one of the ways in which you can start to see that latent in that colour current information especially if I do some work important information about what's thinking in a deep way about how these factors actually include the semantic information what's going to build up some Foundation or Concepts that will be with us throughout this course that's going to be a useful foundation for the Deep learning models that we develop for you if you're maybe just thinking about word meaning what you doing with the stuff that I introduce now presentations are interesting from linguistic problems or social problems or whatever you decide to tackle treating them into other man starting point for the reason that I just showed you the end of encoding a whole lot of semantic information and your model starts in a really interesting materials which have kind of accumulated their 3-0 connect by this code modules that I'm going to encourage you to play rang off shadow leave sometime today to talk about homework one in Bake Off one kind of reinforcement connections and give you a feel for hard at work before their punches screencast for this music or readings we posted some other ones but ternion and tell us a great ideas and insights about his breakfast ace models Smith is a newer paper that skiving informal introduction along the lines that I just save you like why does any of this work I'm in Pennington it always big love Pete requirements tall is a paper and retrofitting which I think is a really inspiring experienced all of this hypothesis I guess I just feel obligated a somebody giving us letter to give this first quote at the top how many people have heard that before Bernard by now you should know a word by the company he keeps forecast lots of course life is the complete meaning of orders always contextual meaning of apart from context to be taken seriously quote from vicarstown the meaning of word is its use in the language but it sounds weird from Zoe Harris using American structural English strongly believed in this distribution hypothesis distributional statements can cover all of the material of a language without requiring support from other types of information patient and actually also BS48 ones just as an aside it's interesting because Ringwood play more associated with this tradition of nominal ISM which was kind of the view that you could only Trust things that were more less in the physical record time thing they start they could trust with the stuff that they would see in corporate which really comes down to just the distributional things that they can observe play dear what day with make of the models representing you today I have a feeling that I might be quite an ads with their philosophical position but at least superficially it sounds like they're on our side until really are you articulate the modern version of this hypothesis if the units of actors in a text frequency matrix they tend to have similar targeting idea for play aesthetic setting the stage and give you a sense for why this letter has the flat it does I just wanted to walk you through this over arching set of ideas here so turn off one of these models the first choice that you might make this design is going to be like do a few things I'll be working on the Rose suite B documents in the cell count would be the number of times of those words appeared in those play but incredibly wide to have a really big fart where is the one that I just showed you what's 4 million designs but you can also have a whole bunch of other notions of nature notions of context along those columns you very different results fundamental issues Singh's representations it really the first choice that you make because to build one of these matrices you make lots and lots of decisions about how your tokenize whether your annotate how your chunckapp units of time some feature selection for your vocabulary and on and on so he's there all the design choices that you have to me enter the Matrix design wanna do some reweighting because as you'll see today the rock out is representations for you'll have to do some massaging as I said best way to make massages doing a rewire amplify the important things and diminish the things that answer who's there I wanted to say if your experience in the space interesting thing that emerges from this whole unit star of our show is pointwise mutual information or PMI how often is the inside behind that reweighting scheme convergence in the model you might want to do some dimensionality reduction and again you have lots of options this is one that I'll show you but you might have heard of some of these are there is likely a light allocation or principal components analysis not so concerned about these acronyms I'm just playing in your head the idea that if you'd only one of these things you have lots of hops how do you have to decide what the better comparison method you use that's going to be like your fundamental notion of what it means to be similar and if you believe that Tony and can teleport that's pretty Central oceans of Africa Paris very different notions of what it means to be similar I'm in the space is that basically you can choose from any one of these columns and get some kind of model whole lot of guidance in the literature about what sensible in what places like looking at a methodological disasters alright because which guidance about what to do and there is untold number of things that you could try in the time that don't I have been teaching this course there have been there has been some real progress on this question I've kind of noted that here 12 in words attempt to unite take care of reweighting and dimensionality reduction even dictate what you're matrix design should be like like a way of saying that it's One Stop Shopping right if I choose glove that I don't have someone who designed choice is there if I choose word to back I don't have so many different apps actually some of them might even diminish the importance of wi that you use because of the scaling that they do on the value play some progress but still you find actually the Bake Off and homework one are trying to get you to confront stuff that you can try play feel like you're doing it kind of line that's kind of by way of introducing this stuff that's my framework for this me to tell you a few of these metrics designs is important as I sent so use that word by word I would say that it's most salient property is that is very dense if you have a large enough corpus most words will 10 20 co-occur with most other words and see you get 20min what is 0 cl in a lot in a real Matrix will be a substantial number of them will be like for dentist tomorrow document that's another common thing where is the longer Rose documents across the column that will be much faster course and if your documents are short will have an incredible number of 0 next underwear the last word what word play some multiplying version thereof depending on how you got the Matrix but yeah you could think of this one is kind of nice cars very rapidly even if you introduce more data the worst case scenario appears like carried by large bowel cancer like 100000 by 100000 but you might have underlying that a billion when is going to get big very fast this one will be sparse so you might have some interesting ways that you could represent it in a way that actually give you something play some that's a great question I want to return to that what you mean when you say switch the telly off you wanted to give you a centre for creative thinking around this issue so this is a word by discourse context matrix in this for dialogue at corpus you have acts of dialogue and they've been labelled with things like this is a question or this is an introduction introduction or this is a bad chain please funny symbols here create a Words by dialogue acts and that would give me a very interesting perspective on the usage patterns for words from up with so before because the notion of context this unusual and this one is left distribution also this one is cancel like this one I hope this is segments along the rows does a cymbals from the international phonetic alphabet are feature representations along the car let's do things like saying this segment is plus voicing or - voicing it so that would be a call turn the have lot of these I guess there's a 28 diff measure distributional it's more like I need a feature representation and here's a picture of it Visualized and you can see that's really good even if you don't know the SAP of that you can kind of see n-type things are up here different only by their Voice singing they've been costed together but otherwise they're very similar here all these rhodok sounds is transitional idea when I'm showing you care because what I showed you before it's all about currency large corpora this is more like a careful analysis of these phonological segment set a reminder that when you think about the vector space model doing something that's pervasive in all of science which is objects renting with a handful of features that you could make what are the examples here so I might just as somebody doing more handcrafted work say the movie was horrible is this vector represent counting some abstract properties of that free play like you might mad on human being turn your 24 145 and 12 a reminder that you might know that the first is an age and the second is away is that meaning only because you're in bedding it in a larger dataset where the first car and the second one is the way dance in which does numbers have any meaning in ask me the same when we think about these co-occurrence matrices the presentations acquire their meaning because their embedded in a larger Matrix and it's essentially about those comparisons along the collar coming out of it the really special thing about the models that were exploring is not there vectors the director's are coming from colour current accounts maybe that's the idea that you really need to get used to which is that somehow just from seeing all those associations in enough time that's what we think of as a semantic it's just a bunch of other design needs exhaustive but some of them are kind of unusual and again I'm just trying to hammer home the point thinking of building a social sciences project on top of these representations are you thinking about developing machine learning model first Choice really large impacts on the subsequent results the final thing our address just with this unit is the question that you raise before which is what we think of what we mean when we say colour curtains broken it down into two things window and scale play Breaking this concrete settings of the novel finnegans Wake which I chose because the first sentence is also the last I will begin with power crane abstract text and what I've done is picked to as our folk over Minecraft is the whole text so they are going to be folk over at some point we've holding on to number going out from there set a reminder is 3 hard window and will be staying at that point is that to colour her is to just be in that window different window sizes from tyre numbers you want to write a letter design choice choice that you might make is had a scale does colour current scan do you have collar crimes within the window flat scale in here then I would be saying that each one of these is a one standing for one colour currency what's the default idea also be something more interesting which is the scale goes down so I might say that where is to be more meaningful in terms of colour farther out does number should do strongly associate play nothing like 1 over and we're it is the position from the focal element just like really rapid drop off learning mixing and matching these ideas right if you set a really large window but you have a scaling property like this at a certain point it's going to be like you're not colouring even if you're in the window add scaling everything in the window count play now and then skip this positional as well before symmetric scale it differently right and left and it might be reflecting on linguistic intuition you have I'm after having significance downstream in how will you represent different different stations to offer here slider Windows will capture more semantic information like what you're doing there is just saying how you're in the same topical spaces is if you pick small more skilled windows what's Morrison tactic in car location information because you're saying like what I really care about is that you're in this local linguistic environment Tracy's one encoder lot of idiomatic information and a lot of stuff that just like how this adjective tends to modify this a different picture than the first one where you get almost none of that information because you were saying hey just being in this document with me is enough to count as a cold I want to say is even if you said all these questions you probably still have some design choices so you're going to have to impose some textual boundaries b a e paragraphs or documents are collections of documents are your basic unit interact with what you choose for the window rights if I was focused on swerve here they just get a very narrow window decided that my texture boundary wasn't that from rather like stretch back into the other part of the novel navigate different the oldest matters and one way that you could start to get a feel for how it matter bit of coding as I took from now on so I included this code snippet guess the mouth turn it to low let me just say that here is the way exposure to a bunch of different two fundamental dataset movie reviews you that's like user-supplied reviews in movie where is Newswire text very different in terms of the semantic content in you expect that to be reflected in the presentations that we develop put down this try to pick two extreme so for each one operation by the window size is 5-in the scaling is one overend said before that should be a lot of like collocation or synthetic infant I have one with the window sizes 20 feeling a splat learn about these generalizations that you would expect that's going to be a lot of Canada search for Giggle word and IMD play that objects are pandas dataframe my experience pandas is great it's fast it's really flexible but it does have a steep learning curve no box to show you can have interact with these data frame turn on Pirate rain maybe it'll come down you'll be able to interact with it example I could do the give me a Siri can you show me in serious form the entire row for the word happy a bit weird so you might say that actual representation festival form what is matrices have a word by word just 5000 by 5000 so that's a pretty small vocabulary I wanted to builder work with them pretty quickly and we can objects into pretty interesting vocabulary as meaning for spaces stop unity vector comparison your Design sorted bunch of counts what's a free now that it's worth by were about that core hypothesis that similarity in the space onto solarium meaning what does it mean to be similar that will turn on what factor comparison method that this is a running example this is also the one that that appears in the screencast there is a tiny World by document matrix over there could be word by word as well soap ladder down at 24 turn document accent document why consider this example is that two things are happening with those counts so first similar in the sense that cancel the kind of rescaled see that there is more why than the numbers are larger for wide in 4 that's the sense in which A and B are similar similar in the sense that their overall magnitudes intuitively or similar they both have pretty vodka is pretty small do that during the weather been plotted like a is kind of lonely down in the score you're up here pretty close distance measure Euclidean distance this is the standard metric that you might think of if you looked at exam ring just the shortest point between a and b in the play dimension here in this dimension some of the squares of all these differences âˆš it to rescale just reflecting what you might think from the picture which is that in Euclidean distance are very far apart you're very close it's already I'm in the heart of this is that Euclidean distance is favour that more abstract notion that a pitch to you before about a and b kind of being proportionally similar make you kind of unhappy as a link abstractly speaking kind of like for example superb and good is vastly less frequent than good b&c econolite good and bad terms of their polarity but in terms of their raw talking counts their very similar what is Borne out if you look at these matrices that just kind of having the same frequency is going to give you very similar Euclidean Shiraz with what you want from some 20 is correlated with meaning I think it's not an accident that's superb in terrible in freak free I probably primarily care about that polarity that Centre William distance looks like it's not my choice turn down a little bit 011 where you could work on there length normalization of the vector what works is you first calculate this quantity for the vector that I'm gonna call the L2 length there's lots of names for it's like you clearly Wikipedia tata hole punching population there it's the sum of the squares of all those values and then you take the square root deuter bank normalize the vector is defined divide each element in the vector by that normalization quantity and it gives you a new vector look at how that happened so if I start with that original Matrix this column vl2 links can you get the new matrix you just divide every other standing row PRINCE2 the space so that's the original one on the way it's normal eyes go up Arsenal Kieran this unit sphere now a really close together CR4 down with this L2 Norm here is kind of abstract away from a lot of the information about the overall magnet GMB together were seeing is much more like their proportional comparison distance the workhorse of this this is the distance measure that everybody uses if they don't mention which distance measure they use good argument for that because what cosine distance is doing seriously are Euclidean like comparison but in that legs normalized population hear the part after the -1 - is clarity regularised everything about this framework into distances so I do 1 - stepdad where is the dot product of the two vectors how many litre is the normalization factor in it's the product of the two L2 lights kind of like I'm doing this product comparison but I'm also controlling for the length of the vectors what the calculations are like can see you're sitting there in their original positions but when you walk through these calculations you find that play close together .0 BNC or pretty far apart sign-in one step it's kind of incorporating that like normalization you can see that there in the calculation and as a result it's favourite similarity that sentiment similarity that think about this is if you first do the L2 norm what sound does sensei get exactly the same calculations in the plane is just that you get exactly the same value first Tudor normalisation or not and that's because 14 alarm and then you do the famous musicals I'm here practice I meant to I think that Dr Rankin normalize then Euclidean distance will give you the same that's the sense in which like if you start a massage the space your distance measurement not matter because if I first normalized all these vector cosigner probably going to be approximately the same what I should check on the exact it's now relationship in the volume I'm making up for settlement part that's my just-so story about the things I think it's realest under the Rose not the documents sensitive about how A and B are similar and how being serious Ima how much the documents are there I think you could tell a similar story about and then it would be about 23 and then he only has articulated the only one where the left Ali was bigger than that overall Bali and then what I'm showing you here is kind of a bunch of ways that you could catch that out so one will be the L2 norm is a reflect that right so so transparent but once I've normalized in this way you can see this one is bigger than this one and those two were very similar in their proportional valve start of it call sign is a good default you a few more just because you might see them another and again there are some interesting things to say about them so another popular family comparison methods are called matching please coefficient is the one I've given the top there can you adjust something up all of the smaller of the two values doing an appointment comparison across the doctors that you want to compare matching coefficient and then jacquard dyes and overlap find in terms of that matching thing matching matching matching in the numerator can see that what they're doing is just normalizing the doctors in different please be careful about what it means to work well was to really capture a lot of the frequency values that it will be a poor choice it works well for Nou problems because primarily we care about when I'm calling the centre Minnesota how much care that superb is less frequent and how the relay doing co-sign your kind of home and riding on mentioning that there's a danger to abstracting away from frequency and you'll see that actually has me go especially for this wedding schemes important and also because a lot about datasets have mistakes in infrequent events 450 too much I don't know I think it depends on the problem tell me more about the next five what the Apple matching the song about the smaller of the values is beginning and end of it works 400 sentient you think about nurses that sometimes you see all of these metrics just to find for binary vectors for example what dice reduces to is the intersection over the uni giving you some abstract measure of overlap can see the in that context matching is like intersex stop the continuous values you can just do a straightforward set the Relic intersection and the closest you can come I live in continuous if I have a zero in a 1 and going to get 0 corresponds to the intersection idf I have two one I can do is there any other can anybody else help to substantial play is it a dimension that 0 contribute nothing there's no match play 0 contribute to the max say the previous life you showed distance between turn on the lights online impact volume cosine within without a first length normalisation get you to see that cosine is doing that like normal what is the nominator is doing and that's why it doesn't matter whether I first left or Eliza just skip that step building in Russian wire normalizing which you can see reflected here because matching issues that where I can pick one and has some kind of normalization that's kind of Life picking Euclidean for picking cosine actavis deeper issue of what am I doing when I am straight away from some of the information about the overall Bollywood news Fallout 4 about this later I mean you see them all over so presumably people have arguments for why they chose can you see dice in the context of binary vectors and I can kind of see why that is because went to the F1 score which is a very deep intuition about How We Do kind of Basin in NL structure in kind of the ability of your model to reproduce maybe some human behaviour in an exact way capturing both is a mistakes essentially surprise me that you said I sometimes but for the others I'm just not sure I do have some general information that I can offer that about Tamworth family that you that you'll encounter that are interesting to think about our kind of probability be the KL divergence this isn't Strictly speaking a Distance metric because you're comparing creation from the reference distribution p value that you get here how to say this can be a little bit fiddly there for example is 0 value becomes undefined to do a step for any real-world application of kind of adding some small value to all these things situations don't explode way in which kale is kind of fiddly and the other is just the fact that it's not symmetric so it matters whether you pick p as your reference distribution people have it happening and I have to remind you that because this is a probabilistic notion you have to all the vectors that is some of their values and then divide each value by that song proper distribution which imposes lots of other design considerations like for example this has to be a bunch of Toolstation step you have to be thinking I'm gonna use this only if it makes sense for me to think of the Valley you're in that kind of environment and this might be a good choice the calculations you I know they're small I think the fundamental thing to observe is that cosine normalization come out very close together and being so far apart Close of the probability abstract away from their over online turn the calculations to Elvis notation and self-worth if you want to check that out play barriers can you sing another little bit less fiddly so one of them would be symmetrical volume two minutes doesn't matter which you pick as your reference distribution that's kind of nice virgins with skew gives you a parameter that lets you control how much you trust the reference distribution vs the other one I have like pull them together listen Shannon distance is a proper distance metre define by this calculation which uses KL twice think about this is you don't have to worry about that smoothing or anything what's the metric at a proper distance metre do you like less fiddly than the other that's my answer to why you might pick one of these is just that free dealing with values that you think of is probably play natural what's up with a few relationships and generalizations jacquard and ice with rock Oz will favourite frequency over the distributional pattern positioned how do you say number two before you with L2 Norm vectors is equivalent to co-sign with regard to Ranking answer to your question I thought I knew that from somewhere I guess I've heard from any and sister what kind of nice cos then once you've normalize-space it doesn't matter whether you pick you pretty in your car turn down to cover with the guard turaki you can probably see that if you look at their two definitions they just anomaly how to norms in probability distributions can obscure differences in the amount of strength of Earth I have an effect on the reliability of coal weather in Enfield rescue with I showed you briefly is Kaya but with a staff that gives you let you give special credence to the ref play one what's the overall is there a default method you should use ask me a question play what to do with the fact that we know these matrices have some problems on I have some examples that he ran into this issue by erasing and I think it's not comparison also about what you doing to the Rock Oz play me some examples and then you could rewrite this question if it doesn't resolve can I hear the Harrison code snippets I guess but I hope you can read it locally so loaded this vs course repository is a bunch of functions that are useful for all the stuff that I'm talking about now actually this example is from The Notebook yeah this is ABC show me hairspray example vs and that Euclidean see you looking at a vector and the vector will give you their Euclidean this volume thanks Leigh Cineworld volume matching to car if you want to talk I didn't you ok I'll be if you're interested in chaos straightforward to implement oh this is Mrs Kenilworth substance set a cold snap it's at the top there I just reloaded for good measure that IMDb 5 Matrix the cosine distance of good and excellent it's cosine distance of good and bad and it's .94 not what I wanted I've been telling you that we want to capture the sentiments and learning spaces and I think we can what's two very similar words even with kosai then good and bad play you can see that the accounts are so great NBS and that neighbours a word please breakfast places as the secondary series that gives you the ranking of that word and Arts closest neighbour the closest neighbours in IMDb five guys taste and Guy validate something I've been seen before anyone want to say like you agree frustration between events what is the funny idea that punctuation could be important turn off the moon supermarket two things first punctuation could be super meaningful like exclamation mark vs period vs? a lot of models but also if you're right and the period shouldn't be in poor if somebody says you see lots of people with the star cordless with her filtering off lots of stuff that they regarded as an important apriori I say that's a fail you that your model should be able to pick up on whether or not all things are important and that's why I deliberately left in a bunch of stuff that you might think is John I say if it's Joe trailer test situation could be good but I just meant that I told you that Play-Doh with sterling with capture a lot of collocational information it doesn't surprise me that bad guys is a very Common by Graham in IMDb movie review turn off the happy picture of you and I did bad with jacquard and it's a totally different picture understanding set timer for you start looking so good reminder tell you one thing from this and then I want to talk a little bit about the homework as I might have lots of tools under big unit here trading schemes goals every waiting as I said before we went emplify the things that are important this is wrong for a question I got before for your question about idiosyncratic stuff the word for trustworthy started simple about trust deemphasize the mundane and also the Corky and problematic define objective function this is going to remain pretty fun Pretty Clear idea intuitive write counts have important information in numbers on a poor proxy for the things that we actually want to care find the relevant information of people volume up please basically wedding scheme SEO for the different properties and what I suggest is a framework for thinking about what they're doing is that you asked these questions sofas what's the reweighted set of values compared to the rockets if it was identical to the Rock counts would be not such a very interesting way is just a proportional rescaling of the car why bother is very different part of values from the rock counts then you might be on to something I wanna ask how does it compare to the word frequent coming back to the cinemas articulating before which is how much are these methods is just capturing the fact that words have different what is the overall distribution of value spices that the distribution of the Rock counts is going to be like this horrible zipfian drop off where a few words have very high used car dealer at all what happened intuition that that's kind of a terrible distribution for lots of different models you might want to do ask of your wedding scheme that it give you something better than that crazy wild off this kind of waiting in the air similar to good question when we did Alton probability distributions I think we were doing calculated this is a value before I don't want to do feature selection based on most frequent no you stop or dictionaries rather I want the models to know that it's not so interesting have used the words that's an important crop is a good way connect with your question you just asked so the most basic kind every waiting at we could do sing two ways of doing that before finding all the values in the row L2 length bloody distribution which is Justified all the values in the role by the sum of those value next training scheme and you can already think about how it's going to how it's going to be relevant here like you're gonna lose a lot of frequency information a really rich picture of how things before she went expected involves a lot of notation but I think it's a brilliant idea I just wanted to be precise so let me just use Rose some x i all the values in row r alarm sound play to be the sum of all the values going down that column the sum of all the values in the entire mean served over expected calculation just takes each value in your mate play this value of the expected value calculations intuitively the weather what what is the saying is cell value think about the probability of the column in the probability of the row give me a default expectation for what that song should be compare that kind of default no hypothesis expectation paul valery actual value is larger than I would expect giving us growing come and have a go I want to make it a phrase I gave you before like amplify the how do I find the things that are departing from my default expectation do that again and again weighting schemes and on through glove and word to vac in all officers based on the row in the column in a comparison with what you ask say something probability actually like a hand on this year but if you think about the songs that you're doing like I have play some SIA once calculations can you give me a probability Bell what is the joint the 4 probability for the whole time downfall of the same colour highlighting hair just to show you what quantities are involved song here is the actual account resume the return to this next time this is all really important information which I said is the hero of this whole unit just over expected in logs yeah Myers also drawing on the same side that I have a no hypothesis turn on the role in The column and then I can compare that to the actual value it just put them into logspace so that you see many more differences than you saw another route the imagine that kill divergences where does Kim I work share my very delighted to it's going to be finishing start a relationship question you both have the same intuition and I've given an example calculation here like this value so this is a 1 maybe maybe that's just a mistake in your corpus that's what I'm asking you to imagine see that this value if I compare it to its row and column values is going to work you another one joint probability table turn the column probability stop this version and not this at 17 I look how big that one has got Aldi's undervalue like a Stena property which I think you're looking into that often these log in log odds comparison values really amplify very small values that you cannot problem with BMI is that it does too much amplification of these very small values and you'll definitely see that until they consider the Laplace in something which she mentioned and they also consider a method of contextual discounting which is like a just in the rows in the columns a little bit think that a little bit you'll see that glass regularized reduced dimensional PMI oh well they just discovered PMI true because what club is doing is all that stuff that you just met hypothesis which I think is born out that it suffers less up here I want to take the last few minutes to just show you what the homework is again next time in little more detail gonna continue working through the slideshow go back on previous teams but this is a good moment to have a plant in your ideas that I think you now have is that you need to make progress on this home describe the task basically and then will wrap up and will return to this and the Bake Off the classic car is that 2 space models which is word similarity can you development phase data sets the famous datasets from the literature human curated so like human annotation measures 34 pairs of work list of two words and Anna score overall task for you is to develop a vector space model comparison between vector you get to directly related to the humans have provided that is that they reflect those similarity score will say turn off two notions at work here the first three people called as relatedness task name two they call similarities play such a big deal about this but you can imagine that the authors of these datasets do make a big deal out of to think for yourself about whether you want your model to key into one or another of these notes volume developer on these datasets some information about exactly the metrics involved Bake Off two new data 4 I have developed your system and you're simply Run that system on those 208 army Irish system here that you don't do subsequent to an end to these new datasets right foxes we trust you to run it one score should give you a good measure for your model generalizes to new notions of relating this endless look in beds all the readers that you need downloaded the data distribution then to fill with any of this you can just reading all these dataset looking at the sky just so that you know exactly what it's doing but basically it's just reading in these pairs of words with the scores readers there the middle of the snow book I did a bunch of stuff illustrate best practices your project you would want to understand these datasets and how are they related to each other and you would want that expiration to inform get your model and your results and I've just done a bunch of analysis the datasets relate to each other at a level of vocabulary what the scores in April love this notebook still around with this to get a free offer tomato chicken play at the bottom we get to the evaluation the main thing that you want used to have words similarity evaluation which you know basically a reader is a dataset dataframe that's the vector space model that you create option to change the distance function if you were is you a correlation coefficient evaluation which has a bunch of information I think you are ready for doing hair analysis which I recommend here's the full evaluation similarity evaluation if you just feed in the vector space model that you've built turn on all the dataset scores like this this is my Bassline and it's truly horrible temple I did was reading Giga 5 heavy stealing you actually have a negative correlation with symbol times are pretty dismal room for improvement overlap paste questions asked you to do is build up some interesting models so first of all just do positive pointwise mutual information odpm LSA with you next time going to different buyers of LSA maybe next week I'm not scheduled a bit of exploration of glove all this is just kind of coaxing you in directions that might be in little bit of code you waiting now that's not what I want to talk about in the lecture but that turns out to be a really powerful reweighting ski read it you'll see that it builds on this rok'alim intuition just the way PMI does and then finally The Originals all those ideas that you had before maybe pipeline home and should these models have you do something that I never even mention some crazy thing that you think will work Pamela way at those readers you can do as much evaluation as you want different datasets to test on but you know do as much development as you want get 9 of the 10 homework the submission is due those two datasets to do a data point is run the model that you developed on the status resulting no we want you to do is fill out these cells down here but pretty much to submit that the completed thing real work behind just you know you have to like a paste in some code see what works best and then one of the two ears are a pair of he is going to reflect back to you everything that we learn from looking at your systems and thinking about the results that we got in with turn on the TV have a fun competition but we also learn something about what works and what doesn't release Prague great start next time I'm not worry waiting 